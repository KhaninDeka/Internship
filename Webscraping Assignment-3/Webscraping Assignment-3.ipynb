{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8858e537",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import StaleElementReferenceException,WebDriverException, ElementClickInterceptedException, TimeoutException,ElementNotInteractableException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "import time\n",
    "\n",
    "from IPython.display import HTML\n",
    "import pyshorteners as short\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e5bee618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search in Amazon: TV\n"
     ]
    }
   ],
   "source": [
    "# Q1 Solution:\n",
    "\n",
    "# defining a function to visit amazon website and search for a product.\n",
    "def initiate_amazon(element):\n",
    "    \n",
    "    # mentioning the PIN Code of our location.\n",
    "    PIN= \"781028\"\n",
    "    # opening the target website.\n",
    "    driver.get(\"https://www.amazon.in/\")\n",
    "    # putting the program on hold for 2 seconds so that the website gets loaded properly.\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Using the explicit wait method till the location-button is loaded.\n",
    "    wait= WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[1]/div[2]/span/a/div[2]\")))\n",
    "    # finding the webelement for the location-button using absolute-xpath and clicking on it.\n",
    "    location_btn= driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[1]/div[2]/span/a/div[2]\").click()\n",
    "    \n",
    "    # putting the program on hold for 1 seconds so that the loation entry field is loaded properly.\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Using the explicit wait method till the PIN entry field is loaded.\n",
    "    wait= WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,\"//input[@id='GLUXZipUpdateInput']\")))\n",
    "    # finding the webelement for the PIN entry field using relative-xpath and sending the mentioned PIN.\n",
    "    send_pin= driver.find_element(By.XPATH,\"//input[@id='GLUXZipUpdateInput']\").send_keys(PIN)\n",
    "                   \n",
    "    # clicking the apply button.\n",
    "    apply_pin= driver.find_element(By.XPATH,\"/html/body/div[3]/div/div/div/div/div[2]/div[3]/div[2]/div/div[2]/span/span/input\").click()\n",
    "    \n",
    "    #putting the program on hold for 2 seconds\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Using the explicit wait method till the search field is loaded.\n",
    "    wait= WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")))\n",
    "    # finding the webelement for the search field using absolute-xpath and sending the user-input data.\n",
    "    srch= driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "    srch.send_keys(element)             \n",
    "    \n",
    "    # finding the webelement for the search button using absolute-xpath and clicking on it.\n",
    "    try: \n",
    "        srch_button= driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input\")\n",
    "        srch_button.click()\n",
    "    except WebDriverException:\n",
    "        pass\n",
    "\n",
    "# taking input from the user.\n",
    "element= input(\"Search in Amazon: \")\n",
    "\n",
    "# connecting to the webdriver.\n",
    "driver= webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "# calling the function above and sending the user-input as an arguement.\n",
    "initiate_amazon(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "68fbb361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page1...\n",
      "Processing page2...\n",
      "Processing page3...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Price(â‚¹)</th>\n",
       "      <th>Availability</th>\n",
       "      <th>Expected Delivery</th>\n",
       "      <th>Return Policy</th>\n",
       "      <th>Exchange</th>\n",
       "      <th>Product Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AmazonBasics</td>\n",
       "      <td>AmazonBasics 81 cm (32 inches) HD Ready Smart ...</td>\n",
       "      <td>13,999</td>\n",
       "      <td>Available</td>\n",
       "      <td>Wed, 3 Aug, 7:00 am - 9:00 pm</td>\n",
       "      <td>10 Days Replacement</td>\n",
       "      <td>Yes, Upto Rs.2,050.00 off</td>\n",
       "      <td>https://www.amazon.in/gp/slredirect/picassoRed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCL</td>\n",
       "      <td>TCL 100 cm (40 inches) Full HD Certified Andro...</td>\n",
       "      <td>19,990</td>\n",
       "      <td>Available</td>\n",
       "      <td>Wed, 3 Aug, 7:00 am - 9:00 pm</td>\n",
       "      <td>10 Days Replacement</td>\n",
       "      <td>Yes, Upto Rs.2,050.00 off</td>\n",
       "      <td>https://www.amazon.in/gp/slredirect/picassoRed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OnePlus</td>\n",
       "      <td>OnePlus 80 cm (32 inches) Y Series HD Ready LE...</td>\n",
       "      <td>14,999</td>\n",
       "      <td>Available</td>\n",
       "      <td>Wed, 3 Aug, 7:00 am - 9:00 pm</td>\n",
       "      <td>10 Days Replacement</td>\n",
       "      <td>Yes, Upto Rs.2,050.00 off</td>\n",
       "      <td>https://www.amazon.in/OnePlus-inches-Ready-And...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Redmi</td>\n",
       "      <td>Redmi 80 cm (32 inches) Android 11 Series HD R...</td>\n",
       "      <td>14,999</td>\n",
       "      <td>Available</td>\n",
       "      <td>Wed, 3 Aug, 7:00 am - 9:00 pm</td>\n",
       "      <td>10 Days Replacement</td>\n",
       "      <td>Yes, Upto Rs.2,050.00 off</td>\n",
       "      <td>https://www.amazon.in/Redmi-inches-Ready-L32M6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mi</td>\n",
       "      <td>Mi 80 cm (32 inches) 5A Series HD Ready Smart ...</td>\n",
       "      <td>15,499</td>\n",
       "      <td>Available</td>\n",
       "      <td>Wed, 3 Aug, 7:00 am - 9:00 pm</td>\n",
       "      <td>10 Days Replacement</td>\n",
       "      <td>Yes, Upto Rs.2,050.00 off</td>\n",
       "      <td>https://www.amazon.in/inches-Ready-Smart-Andro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>LG</td>\n",
       "      <td>LG 108 cm (43 inches) 4K Ultra HD Smart LED TV...</td>\n",
       "      <td>31,490</td>\n",
       "      <td>Available</td>\n",
       "      <td>Wed, 3 Aug, 7:00 am - 9:00 pm</td>\n",
       "      <td>10 Days Replacement</td>\n",
       "      <td>Yes, Upto Rs.2,050.00 off</td>\n",
       "      <td>https://www.amazon.in/LG-inches-Ultra-43UQ7500...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Vu</td>\n",
       "      <td>Vu 108 cm (43 Inches) Premium 4K Series Smart ...</td>\n",
       "      <td>25,999</td>\n",
       "      <td>Available</td>\n",
       "      <td>Wed, 3 Aug, 7:00 am - 9:00 pm</td>\n",
       "      <td>10 Days Replacement</td>\n",
       "      <td>Yes, Upto Rs.2,050.00 off</td>\n",
       "      <td>https://www.amazon.in/Inches-Premium-Smart-And...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Toshiba</td>\n",
       "      <td>Toshiba 80 cm (32 inches) V Series HD Ready Sm...</td>\n",
       "      <td>14,990</td>\n",
       "      <td>Available</td>\n",
       "      <td>Wed, 3 Aug, 7:00 am - 9:00 pm</td>\n",
       "      <td>10 Days Replacement</td>\n",
       "      <td>Yes, Upto Rs.2,050.00 off</td>\n",
       "      <td>https://www.amazon.in/Toshiba-inches-Android-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Hyundai</td>\n",
       "      <td>Hyundai 80 cm (32 inches) HD Ready Smart LED T...</td>\n",
       "      <td>13,490</td>\n",
       "      <td>Available</td>\n",
       "      <td>Wed, 3 Aug, 7:00 am - 9:00 pm</td>\n",
       "      <td>10 Days Replacement</td>\n",
       "      <td>Yes, Upto Rs.2,050.00 off</td>\n",
       "      <td>https://www.amazon.in/gp/slredirect/picassoRed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>AKAI</td>\n",
       "      <td>AKAI 80 cm (32 Inches) HD Ready Smart LED TV A...</td>\n",
       "      <td>13,999</td>\n",
       "      <td>Available</td>\n",
       "      <td>Wed, 3 Aug, 7:00 am - 9:00 pm</td>\n",
       "      <td>10 Days Replacement</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>https://www.amazon.in/gp/slredirect/picassoRed...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand                                       Product Name Price(â‚¹)  \\\n",
       "0   AmazonBasics  AmazonBasics 81 cm (32 inches) HD Ready Smart ...   13,999   \n",
       "1            TCL  TCL 100 cm (40 inches) Full HD Certified Andro...   19,990   \n",
       "2        OnePlus  OnePlus 80 cm (32 inches) Y Series HD Ready LE...   14,999   \n",
       "3          Redmi  Redmi 80 cm (32 inches) Android 11 Series HD R...   14,999   \n",
       "4             Mi  Mi 80 cm (32 inches) 5A Series HD Ready Smart ...   15,499   \n",
       "..           ...                                                ...      ...   \n",
       "61            LG  LG 108 cm (43 inches) 4K Ultra HD Smart LED TV...   31,490   \n",
       "62            Vu  Vu 108 cm (43 Inches) Premium 4K Series Smart ...   25,999   \n",
       "63       Toshiba  Toshiba 80 cm (32 inches) V Series HD Ready Sm...   14,990   \n",
       "64       Hyundai  Hyundai 80 cm (32 inches) HD Ready Smart LED T...   13,490   \n",
       "65          AKAI  AKAI 80 cm (32 Inches) HD Ready Smart LED TV A...   13,999   \n",
       "\n",
       "   Availability               Expected Delivery        Return Policy  \\\n",
       "0     Available   Wed, 3 Aug, 7:00 am - 9:00 pm  10 Days Replacement   \n",
       "1     Available   Wed, 3 Aug, 7:00 am - 9:00 pm  10 Days Replacement   \n",
       "2     Available   Wed, 3 Aug, 7:00 am - 9:00 pm  10 Days Replacement   \n",
       "3     Available   Wed, 3 Aug, 7:00 am - 9:00 pm  10 Days Replacement   \n",
       "4     Available   Wed, 3 Aug, 7:00 am - 9:00 pm  10 Days Replacement   \n",
       "..          ...                             ...                  ...   \n",
       "61    Available   Wed, 3 Aug, 7:00 am - 9:00 pm  10 Days Replacement   \n",
       "62    Available   Wed, 3 Aug, 7:00 am - 9:00 pm  10 Days Replacement   \n",
       "63    Available   Wed, 3 Aug, 7:00 am - 9:00 pm  10 Days Replacement   \n",
       "64    Available   Wed, 3 Aug, 7:00 am - 9:00 pm  10 Days Replacement   \n",
       "65    Available   Wed, 3 Aug, 7:00 am - 9:00 pm  10 Days Replacement   \n",
       "\n",
       "                     Exchange  \\\n",
       "0   Yes, Upto Rs.2,050.00 off   \n",
       "1   Yes, Upto Rs.2,050.00 off   \n",
       "2   Yes, Upto Rs.2,050.00 off   \n",
       "3   Yes, Upto Rs.2,050.00 off   \n",
       "4   Yes, Upto Rs.2,050.00 off   \n",
       "..                        ...   \n",
       "61  Yes, Upto Rs.2,050.00 off   \n",
       "62  Yes, Upto Rs.2,050.00 off   \n",
       "63  Yes, Upto Rs.2,050.00 off   \n",
       "64  Yes, Upto Rs.2,050.00 off   \n",
       "65             Not Applicable   \n",
       "\n",
       "                                          Product Url  \n",
       "0   https://www.amazon.in/gp/slredirect/picassoRed...  \n",
       "1   https://www.amazon.in/gp/slredirect/picassoRed...  \n",
       "2   https://www.amazon.in/OnePlus-inches-Ready-And...  \n",
       "3   https://www.amazon.in/Redmi-inches-Ready-L32M6...  \n",
       "4   https://www.amazon.in/inches-Ready-Smart-Andro...  \n",
       "..                                                ...  \n",
       "61  https://www.amazon.in/LG-inches-Ultra-43UQ7500...  \n",
       "62  https://www.amazon.in/Inches-Premium-Smart-And...  \n",
       "63  https://www.amazon.in/Toshiba-inches-Android-3...  \n",
       "64  https://www.amazon.in/gp/slredirect/picassoRed...  \n",
       "65  https://www.amazon.in/gp/slredirect/picassoRed...  \n",
       "\n",
       "[66 rows x 8 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2 Solution:\n",
    "\n",
    "# defining the lists to be used.\n",
    "brands=[]\n",
    "names=[]\n",
    "prices=[]\n",
    "exchange_check=[]\n",
    "return_duration=[]\n",
    "exp_delvry=[]\n",
    "availability=[]\n",
    "url=[]\n",
    "\n",
    "# defining a 'User-Agent' and 'Accept-Language' so that our requests don't get blocked.\n",
    "HEADERS = ({'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:102.0) Gecko/20100101 Firefox/102.0',\n",
    "            'Accept-Language': 'en-US, en;q=0.5'})\n",
    "\n",
    "# an alternate.\n",
    "# HEADERS = ({'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.5060.134 Safari/537.36',\n",
    "#            'Accept-Language': 'en-US, en;q=0.5'})\n",
    "\n",
    "\n",
    "# defining a function to get the price data.\n",
    "def get_price(components):\n",
    "    for j in components:\n",
    "        check= j.find(\"â‚¹\")\n",
    "        if check!=(-1):\n",
    "            prices.append(j.split(\"â‚¹\")[1])\n",
    "            break\n",
    "        elif j==components[-1]:\n",
    "            prices.append(\"-\")\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "# defining a function to get the availability data.\n",
    "# amazon by default only lists products which are available.\n",
    "# so we only get those which are in short supply and running out fast.\n",
    "def availability_checker(components):\n",
    "    availability_check= components.text.find(\"left in stock\")\n",
    "    if availability_check==(-1):\n",
    "        availability.append(\"Available\")\n",
    "    else:\n",
    "        availability.append(components.text.split(\"\\n\")[-1])\n",
    "\n",
    "# defining a function to get the expected delivery data.\n",
    "def delivery(components):\n",
    "    for j in components:\n",
    "        check1= j.find(\"Get it by\")\n",
    "        check2= j.find(\"FREE delivery by\")\n",
    "        if check1!=(-1): \n",
    "            exp_delvry.append(j.split(\"Get it by\")[-1])\n",
    "            return 1\n",
    "        elif check2!=(-1):\n",
    "            exp_delvry.append(j.split(\"FREE delivery by\")[-1])\n",
    "            return 1\n",
    "        elif j==components[-1]:\n",
    "            return 0\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "# defining a function to get the exchange, return and delivery(if delivery data is missing is search-results page) data.\n",
    "# It takes in two arguements. One is a link to a product and another is status of expected-delivery data.\n",
    "def check_return_exchange(link,status):\n",
    "    \n",
    "    # sending request to the target website.\n",
    "    r= requests.get(link,headers=HEADERS)\n",
    "    \n",
    "    # getting the content in the form of a beautifulsoup object from which we will extract our data. \n",
    "    soup= bs(r.content)\n",
    "    \n",
    "    # getting the exchange data using tag name and id. If the element is absent then exchange is \"Not Applicable\"\n",
    "    # if the element is present then either there is an exchange-deal or exchange is not avavilable at our geographical location.\n",
    "    # data is filled accordingly.\n",
    "    try:\n",
    "        exchange_data=soup.find(\"div\",id=\"buyBackAccordionRow\").text.strip()\n",
    "        check= exchange_data.find(\"Up to\")\n",
    "        if check!=(-1):\n",
    "            upto_value= exchange_data.split(\"off\")[0].strip().split(\" \")[-1]\n",
    "            exchange_check.append(f'Yes, Upto Rs.{upto_value} off')\n",
    "        else:\n",
    "            exchange_check.append(\"Not Available at your location\")\n",
    "    except AttributeError:\n",
    "        exchange_check.append(\"Not Applicable\")\n",
    "    \n",
    "    # getting the return-policy data using tag name and id. If the element is absent then it is \"Not Available\".\n",
    "    try:\n",
    "        return_data= soup.find(\"div\",id=\"RETURNS_POLICY\").text.strip()\n",
    "        return_duration.append(return_data)\n",
    "    except AttributeError:\n",
    "        return_duration.append(\"Not Available\")\n",
    "    \n",
    "    # status=0 if we didn't find our delivery data in product-listing page. Hence we extract it from the product page itself.\n",
    "    # If the data is absent here too then we append null.\n",
    "    try:\n",
    "        if status==0:\n",
    "            delivery_data= soup.find(\"div\",id='deliveryBlockMessage').text.strip()\n",
    "            exp_delvry.append(delivery_data.split(\"FREE delivery\")[1].strip().split(\".\")[0])\n",
    "        else:\n",
    "            pass           \n",
    "    except AttributeError:\n",
    "        exp_delvry.append(\"-\")\n",
    "    except IndexError:\n",
    "        exp_delvry.append(\"+\")\n",
    "\n",
    "        \n",
    "# the pages that shows the listing of products are basically of 3 types based on class values.\n",
    "# Hence defining functions for each of these types to get data.\n",
    "\n",
    "# defining a function to get the data from one type of product-listing page.\n",
    "def get_data_type1():\n",
    "    \n",
    "    # using the explicit wait method till the webelements we want gets loaded.\n",
    "    wait= WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,\"//div[@class='a-section a-spacing-base']\")))\n",
    "    # finding the webelements for the products listed on the page.\n",
    "    data=driver.find_elements(By.XPATH,\"//div[@class='a-section a-spacing-base']\")\n",
    "\n",
    "    # running a for loop to process each product data and extract the relevant information.\n",
    "    for i in data:\n",
    "        # pre-processing the text-data to remove some irrelevant data and get relevant ones in a list for further processing.\n",
    "        info= i.text.split(\"Sponsored\")[-1].strip().split(\"Amazon's Choice\")[-1].strip().split(\"Best seller\")[-1].strip()\n",
    "        if info==\"\":\n",
    "            continue\n",
    "        else:\n",
    "            elements= info.split(\"\\n\")\n",
    "            \n",
    "            if elements[0][0]==\"+\":\n",
    "                elements.pop(0)\n",
    "            else: \n",
    "                pass\n",
    "            \n",
    "            # extracting the relevant data into respective lists.\n",
    "            brands.append(elements[0].split(\" \")[0])\n",
    "            names.append(elements[0])\n",
    "            \n",
    "            get_price(elements)         # calling the \"get_price\" function to get the price data.\n",
    "            availability_checker(i)     # calling the \"availability_checker\" function to get the availability data.          \n",
    "            status=delivery(elements)   # the \"delivery\" function will return 0 if it can't find the expected-delivery data on the product listing page, otherwise it will return 1.\n",
    "            \n",
    "            # getting the link, saving it in a list and send the link to \"check_return_exchange\" function to be processed for further information.\n",
    "            link_data= i.find_element(By.XPATH,\".//a[@class='a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal']\")\n",
    "            link=link_data.get_attribute('href')\n",
    "            url.append(link)\n",
    "            check_return_exchange(link,status)\n",
    "\n",
    "# defining a function to get the data from another type of product-listing page.\n",
    "def get_data_type2():\n",
    "    \n",
    "    # using the explicit wait method till the webelements we want gets loaded.\n",
    "    wait= WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,\"//div[@class='a-section a-spacing-base a-text-center']\")))\n",
    "    # finding the webelements for the products listed on the page.\n",
    "    data=driver.find_elements(By.XPATH,\"//div[@class='a-section a-spacing-base a-text-center']\")\n",
    "    \n",
    "    # running a for loop to process each product data and extract the relevant information.\n",
    "    for i in data:\n",
    "        # pre-processing the text-data to remove some irrelevant data and get relevant ones in a list for further processing.\n",
    "        info= i.text.split(\"Sponsored\")[-1].strip().split(\"Amazon's Choice\")[-1].strip().split(\"Best seller\")[-1].strip()\n",
    "        if info==\"\":\n",
    "            continue\n",
    "        else:\n",
    "            elements= info.split(\"\\n\")\n",
    "            \n",
    "            if elements[0][0]==\"+\":\n",
    "                elements.pop(0)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            # extracting the relevant data into respective lists.\n",
    "            brands.append(elements[0])\n",
    "            names.append(elements[1])\n",
    "            \n",
    "            get_price(elements)            # calling the \"get_price\" function to get the price data.           \n",
    "            availability_checker(i)        # calling the \"availability_checker\" function to get the availability data.                           \n",
    "            status=delivery(elements)      # the \"delivery\" function will return 0 if it can't find the expected-delivery data on the product listing page, otherwise it will return 1.\n",
    "            \n",
    "            # getting the link, saving it in a list and send the link to \"check_return_exchange\" function to be processed for further information.\n",
    "            link_data= i.find_element(By.XPATH,\".//a[@class='a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal']\")\n",
    "            link=link_data.get_attribute('href')\n",
    "            url.append(link)\n",
    "            check_return_exchange(link,status)\n",
    "\n",
    "# defining a function to get the data from another type of product-listing page.\n",
    "def get_data_type3():\n",
    "    \n",
    "    # using the explicit wait method till the webelements we want gets loaded.\n",
    "    wait= WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,\"//div[@class='a-section']\")))\n",
    "    # finding the webelements for the products listed on the page.\n",
    "    data=driver.find_elements(By.XPATH,\"//div[@class='a-section']\")\n",
    "    \n",
    "    # running a for loop to process each product data and extract the relevant information.\n",
    "    for i in data:\n",
    "        # pre-processing the text-data to remove some irrelevant data and get relevant ones in a list for further processing.\n",
    "        info= i.text.split(\"Sponsored\")[-1].strip().split(\"Amazon's Choice\")[-1].strip().split(\"Best seller\")[-1].strip()\n",
    "        if (info==\"\")or(i==data[-1]):\n",
    "            continue\n",
    "        else:\n",
    "            elements= info.split(\"\\n\")\n",
    "            \n",
    "            if elements[0][0]==\"+\":\n",
    "                elements.pop(0)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            # extracting the relevant data into respective lists.\n",
    "            brands.append(elements[0].split(\" \")[0])\n",
    "            names.append(elements[0])\n",
    "            \n",
    "            get_price(elements)            # calling the \"get_price\" function to get the price data.               \n",
    "            availability_checker(i)        # calling the \"availability_checker\" function to get the availability data.          \n",
    "            status=delivery(elements)      # the \"delivery\" function will return 0 if it can't find the expected-delivery data on the product listing page, otherwise it will return 1. \n",
    "            \n",
    "            # getting the link, saving it in a list and send the link to \"check_return_exchange\" function to be processed for further information.\n",
    "            link_data= i.find_element(By.XPATH,\".//a[@class='a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal']\")\n",
    "            link=link_data.get_attribute('href')\n",
    "            url.append(link)\n",
    "            check_return_exchange(link,status)\n",
    "\n",
    "# defining the function to start the data-scraping process.            \n",
    "def amazon_scrapper():\n",
    "    \n",
    "    # putting the program on hold for 2 seconnds so that the search-results page gets loaded properly.\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # finding the webelements for the 3 types of product listings. \n",
    "    data_type1=driver.find_elements(By.XPATH,\"//div[@class='a-section a-spacing-base']\")\n",
    "    data_type2=driver.find_elements(By.XPATH,\"//div[@class='a-section a-spacing-base a-text-center']\")\n",
    "    data_type3=driver.find_elements(By.XPATH,\"//div[@class='a-section']\")\n",
    "    # saving the number of webelements found for each type in a list.\n",
    "    data_lengths=[len(data_type1),len(data_type2),len(data_type3)]\n",
    "\n",
    "    # getting the webelements for the page2 and 3 buttons and extracting the links into a list.\n",
    "    pages_btn_data= driver.find_elements(By.XPATH,\"//a[@class='s-pagination-item s-pagination-button']\")\n",
    "    pages=[]\n",
    "    for page in pages_btn_data:\n",
    "        pages.append(page.get_attribute('href'))\n",
    "    \n",
    "    # defining a variable to keep track of the page getting processed.\n",
    "    count=1\n",
    "    \n",
    "    # finding the webelements' type which have the highest count using if-else conditions. That is our product-listings of the page.\n",
    "    if (data_lengths[0]>data_lengths[1])&(data_lengths[0]>data_lengths[2]):\n",
    "        print(f'Processing page{count}...')\n",
    "        get_data_type1()         # calling the function to scrape type1 data.\n",
    "        for page in pages:\n",
    "            count+=1\n",
    "            print(f'Processing page{count}...')\n",
    "            driver.get(page)     # loading the next products-listing page.\n",
    "            time.sleep(1)            \n",
    "            get_data_type1()     # calling the function to scrape type1 data.\n",
    "\n",
    "    elif (data_lengths[1]>data_lengths[0])&(data_lengths[1]>data_lengths[2]):\n",
    "        print(f'Processing page{count}...')\n",
    "        get_data_type2()         # calling the function to scrape type2 data.\n",
    "        for page in pages:\n",
    "            count+=1\n",
    "            print(f'Processing page{count}...')\n",
    "            driver.get(page)     # loading the next products-listing page.  \n",
    "            time.sleep(1)            \n",
    "            get_data_type2()     # calling the function to scrape type2 data.\n",
    "            \n",
    "    elif (data_lengths[2]>data_lengths[0])&(data_lengths[2]>data_lengths[1]):\n",
    "        print(f'Processing page{count}...')\n",
    "        get_data_type3()         # calling the function to scrape type3 data.\n",
    "        for page in pages:\n",
    "            count+=1\n",
    "            print(f'Processing page{count}...')\n",
    "            driver.get(page)     # loading the next products-listing page.\n",
    "            time.sleep(1)            \n",
    "            get_data_type3()     # calling the function to scrape type3 data.\n",
    "\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    # preparing the final dataframe.\n",
    "    products= pd.DataFrame({\"Brand\":brands,\n",
    "                            \"Product Name\":names, \n",
    "                            \"Price(â‚¹)\":prices, \n",
    "                            \"Availability\":availability, \n",
    "                            \"Expected Delivery\":exp_delvry,\n",
    "                            \"Return Policy\":return_duration,\n",
    "                            \"Exchange\":exchange_check,\n",
    "                            \"Product Url\":url\n",
    "                            })\n",
    "    # returning the dataframe.\n",
    "    return products\n",
    "\n",
    "# calling the \"amazon_scrapper\" function to start the scraping process and save the result.\n",
    "products_df= amazon_scrapper()\n",
    "\n",
    "# closing the webdriver.\n",
    "driver.close()\n",
    "\n",
    "# saving the results in a csv file.\n",
    "products_df.to_csv(f'{element}_search_results.csv',header=True)\n",
    "products_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4bea59c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search in Google-Images: cakes\n"
     ]
    }
   ],
   "source": [
    "# Q3 Solution:\n",
    "\n",
    "# defining a function to scrap images from google-images.\n",
    "def google_image_scrapper(keyword):\n",
    "    \n",
    "    # connecting to the webdriver.\n",
    "    driver= webdriver.Chrome(\"chromedriver.exe\")\n",
    "    # opening the target website. \n",
    "    driver.get(\"https://images.google.com/\")\n",
    "    # maximizing the driver window.\n",
    "    driver.maximize_window()\n",
    "    # refreshing the website.\n",
    "    driver.refresh()\n",
    "    \n",
    "    # using the explicit wait method till the search field is loaded.\n",
    "    wait= WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,\"/html/body/div[1]/div[3]/form/div[1]/div[1]/div[1]/div/div[2]/input\")))\n",
    "    # finding the webelement for the search field using absolute-xpath and sending the required keys.\n",
    "    srch_bar= driver.find_element(By.XPATH,\"/html/body/div[1]/div[3]/form/div[1]/div[1]/div[1]/div/div[2]/input\")\n",
    "    srch_bar.send_keys(keyword)\n",
    "    \n",
    "    # finding the webelement for the search button using absolute-xpath and clicking on it.\n",
    "    srch_btn= driver.find_element(By.XPATH,\"/html/body/div[1]/div[3]/form/div[1]/div[1]/div[1]/button/div/span\").click()\n",
    "    \n",
    "    # putting the program on hold for 2 seconds so that the search is processed and the page is loaded properly.\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # running a for loop for each webelement of the images and taking a screenshot of them and saving them in a specific directory.\n",
    "    # the xpath of each of the images vary only by the value of X in \"//*[@id=\"islrg\"]/div[1]/div[X]/a[1]/div[1]/img\"\n",
    "    for i in range(1, 11):\n",
    "        try:\n",
    "            driver.find_element(By.XPATH,'//*[@id=\"islrg\"]/div[1]/div['+str(i)+']/a[1]/div[1]/img').screenshot(f'C:\\\\Users\\\\Asus\\Pictures\\\\Saved Pictures\\\\{keyword} ('+str(i)+').png')\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    # closing the webdriver\n",
    "    driver.close()\n",
    "    \n",
    "# taking input from the user.        \n",
    "keyword= input(\"Search in Google-Images: \")\n",
    "# calling the function and sending the user-input as an arguement.\n",
    "google_image_scrapper(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7cee3709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search a smartphone: asus zenfone\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Color</th>\n",
       "      <th>RAM</th>\n",
       "      <th>ROM</th>\n",
       "      <th>Primary Camera</th>\n",
       "      <th>Secondary Camera</th>\n",
       "      <th>Display</th>\n",
       "      <th>Battery</th>\n",
       "      <th>Price</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASUS</td>\n",
       "      <td>ASUS ZenFone Max M2</td>\n",
       "      <td>Black</td>\n",
       "      <td>3 GB RAM</td>\n",
       "      <td>32 GB ROM</td>\n",
       "      <td>13MP + 2MP</td>\n",
       "      <td>8MP Front Camera</td>\n",
       "      <td>15.9 cm (6.26 inch) HD+ Display</td>\n",
       "      <td>4000 mAh Battery</td>\n",
       "      <td>â‚¹12,549</td>\n",
       "      <td>https://www.flipkart.com/asus-zenfone-max-m2-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS</td>\n",
       "      <td>ASUS ZenFone Max Pro M2</td>\n",
       "      <td>Blue</td>\n",
       "      <td>3 GB RAM</td>\n",
       "      <td>32 GB ROM</td>\n",
       "      <td>12MP + 5MP</td>\n",
       "      <td>13MP Front Camera</td>\n",
       "      <td>15.9 cm (6.26 inch) Full HD+ Display</td>\n",
       "      <td>5000 mAh Battery</td>\n",
       "      <td>â‚¹15,999</td>\n",
       "      <td>https://www.flipkart.com/asus-zenfone-max-pro-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS</td>\n",
       "      <td>ASUS ZenFone Max M2</td>\n",
       "      <td>Black</td>\n",
       "      <td>4 GB RAM</td>\n",
       "      <td>64 GB ROM</td>\n",
       "      <td>13MP + 2MP</td>\n",
       "      <td>8MP Front Camera</td>\n",
       "      <td>15.9 cm (6.26 inch) HD+ Display</td>\n",
       "      <td>4000 mAh Battery</td>\n",
       "      <td>â‚¹14,999</td>\n",
       "      <td>https://www.flipkart.com/asus-zenfone-max-m2-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS</td>\n",
       "      <td>ASUS ZenFone 5Z</td>\n",
       "      <td>Meteor Silver</td>\n",
       "      <td>8 GB RAM</td>\n",
       "      <td>256 GB ROM</td>\n",
       "      <td>12MP + 8MP</td>\n",
       "      <td>8MP Front Camera</td>\n",
       "      <td>15.75 cm (6.2 inch) Full HD+ Display</td>\n",
       "      <td>3300 mAh Battery</td>\n",
       "      <td>â‚¹43,999</td>\n",
       "      <td>https://www.flipkart.com/asus-zenfone-5z-meteo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS</td>\n",
       "      <td>ASUS Zenfone 4 Selfie</td>\n",
       "      <td>Black</td>\n",
       "      <td>3 GB RAM</td>\n",
       "      <td>32 GB ROM</td>\n",
       "      <td>13MP Rear Camera</td>\n",
       "      <td>13MP Front Camera</td>\n",
       "      <td>13.97 cm (5.5 inch) HD Display</td>\n",
       "      <td>3000 mAh Battery</td>\n",
       "      <td>â‚¹10,999</td>\n",
       "      <td>https://www.flipkart.com/asus-zenfone-4-selfie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS</td>\n",
       "      <td>ASUS Zenfone Max Pro M1</td>\n",
       "      <td>Grey</td>\n",
       "      <td>6 GB RAM</td>\n",
       "      <td>64 GB ROM</td>\n",
       "      <td>16MP + 5MP</td>\n",
       "      <td>16MP Front Camera</td>\n",
       "      <td>15.21 cm (5.99 inch) Full HD+ Display</td>\n",
       "      <td>5000 mAh Battery</td>\n",
       "      <td>â‚¹17,999</td>\n",
       "      <td>https://www.flipkart.com/asus-zenfone-max-pro-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS</td>\n",
       "      <td>ASUS ZenFone Max M2</td>\n",
       "      <td>Blue</td>\n",
       "      <td>3 GB RAM</td>\n",
       "      <td>32 GB ROM</td>\n",
       "      <td>13MP + 2MP</td>\n",
       "      <td>8MP Front Camera</td>\n",
       "      <td>15.9 cm (6.26 inch) HD+ Display</td>\n",
       "      <td>4000 mAh Battery</td>\n",
       "      <td>â‚¹12,549</td>\n",
       "      <td>https://www.flipkart.com/asus-zenfone-max-m2-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ASUS</td>\n",
       "      <td>ASUS Zenfone Max Pro M1</td>\n",
       "      <td>Blue</td>\n",
       "      <td>4 GB RAM</td>\n",
       "      <td>64 GB ROM</td>\n",
       "      <td>13MP + 5MP</td>\n",
       "      <td>8MP Front Camera</td>\n",
       "      <td>15.21 cm (5.99 inch) Full HD+ Display</td>\n",
       "      <td>5000 mAh Battery</td>\n",
       "      <td>â‚¹15,599</td>\n",
       "      <td>https://www.flipkart.com/asus-zenfone-max-pro-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS</td>\n",
       "      <td>ASUS Zenfone Max Pro M1</td>\n",
       "      <td>Grey</td>\n",
       "      <td>4 GB RAM</td>\n",
       "      <td>64 GB ROM</td>\n",
       "      <td>13MP + 5MP</td>\n",
       "      <td>8MP Front Camera</td>\n",
       "      <td>15.21 cm (5.99 inch) Full HD+ Display</td>\n",
       "      <td>5000 mAh Battery</td>\n",
       "      <td>â‚¹15,599</td>\n",
       "      <td>https://www.flipkart.com/asus-zenfone-max-pro-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS</td>\n",
       "      <td>ASUS Zenfone Max Pro M1</td>\n",
       "      <td>Blue</td>\n",
       "      <td>6 GB RAM</td>\n",
       "      <td>64 GB ROM</td>\n",
       "      <td>16MP + 5MP</td>\n",
       "      <td>16MP Front Camera</td>\n",
       "      <td>15.21 cm (5.99 inch) Full HD+ Display</td>\n",
       "      <td>5000 mAh Battery</td>\n",
       "      <td>â‚¹17,999</td>\n",
       "      <td>https://www.flipkart.com/asus-zenfone-max-pro-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ASUS</td>\n",
       "      <td>ASUS Zenfone Max Pro M1</td>\n",
       "      <td>Blue</td>\n",
       "      <td>3 GB RAM</td>\n",
       "      <td>32 GB ROM</td>\n",
       "      <td>13MP + 5MP</td>\n",
       "      <td>8MP Front Camera</td>\n",
       "      <td>15.21 cm (5.99 inch) Full HD+ Display</td>\n",
       "      <td>5000 mAh Battery</td>\n",
       "      <td>â‚¹13,199</td>\n",
       "      <td>https://www.flipkart.com/asus-zenfone-max-pro-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ASUS</td>\n",
       "      <td>ASUS Zenfone Max Pro M1</td>\n",
       "      <td>Black</td>\n",
       "      <td>4 GB RAM</td>\n",
       "      <td>64 GB ROM</td>\n",
       "      <td>13MP + 5MP</td>\n",
       "      <td>8MP Front Camera</td>\n",
       "      <td>15.21 cm (5.99 inch) Full HD+ Display</td>\n",
       "      <td>5000 mAh Battery</td>\n",
       "      <td>â‚¹15,599</td>\n",
       "      <td>https://www.flipkart.com/asus-zenfone-max-pro-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ASUS</td>\n",
       "      <td>ASUS ZenFone 5Z</td>\n",
       "      <td>Midnight Blue</td>\n",
       "      <td>6 GB RAM</td>\n",
       "      <td>128 GB ROM</td>\n",
       "      <td>12MP + 8MP</td>\n",
       "      <td>8MP Front Camera</td>\n",
       "      <td>15.75 cm (6.2 inch) Full HD+ Display</td>\n",
       "      <td>3300 mAh Battery</td>\n",
       "      <td>â‚¹36,299</td>\n",
       "      <td>https://www.flipkart.com/asus-zenfone-5z-midni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ASUS</td>\n",
       "      <td>ASUS Zenfone Max Pro M1</td>\n",
       "      <td>Black</td>\n",
       "      <td>6 GB RAM</td>\n",
       "      <td>64 GB ROM</td>\n",
       "      <td>16MP + 5MP</td>\n",
       "      <td>16MP Front Camera</td>\n",
       "      <td>15.21 cm (5.99 inch) Full HD+ Display</td>\n",
       "      <td>5000 mAh Battery</td>\n",
       "      <td>â‚¹17,999</td>\n",
       "      <td>https://www.flipkart.com/asus-zenfone-max-pro-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ASUS</td>\n",
       "      <td>ASUS Zenfone Max Pro M1</td>\n",
       "      <td>Grey</td>\n",
       "      <td>3 GB RAM</td>\n",
       "      <td>32 GB ROM</td>\n",
       "      <td>13MP + 5MP</td>\n",
       "      <td>8MP Front Camera</td>\n",
       "      <td>15.21 cm (5.99 inch) Full HD+ Display</td>\n",
       "      <td>5000 mAh Battery</td>\n",
       "      <td>â‚¹13,199</td>\n",
       "      <td>https://www.flipkart.com/asus-zenfone-max-pro-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ASUS</td>\n",
       "      <td>ASUS Zenfone Max Pro M1</td>\n",
       "      <td>Black</td>\n",
       "      <td>3 GB RAM</td>\n",
       "      <td>32 GB ROM</td>\n",
       "      <td>13MP + 5MP</td>\n",
       "      <td>8MP Front Camera</td>\n",
       "      <td>15.21 cm (5.99 inch) Full HD+ Display</td>\n",
       "      <td>5000 mAh Battery</td>\n",
       "      <td>â‚¹13,199</td>\n",
       "      <td>https://www.flipkart.com/asus-zenfone-max-pro-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ASUS</td>\n",
       "      <td>ASUS ZenFone Max M1</td>\n",
       "      <td>Black</td>\n",
       "      <td>4 GB RAM</td>\n",
       "      <td>64 GB ROM</td>\n",
       "      <td>13MP Rear Camera</td>\n",
       "      <td>8MP Front Camera</td>\n",
       "      <td>13.84 cm (5.45 inch) HD+ Display</td>\n",
       "      <td>4000 mAh Battery</td>\n",
       "      <td>â‚¹9,599</td>\n",
       "      <td>https://www.flipkart.com/asus-zenfone-max-m1-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ASUS</td>\n",
       "      <td>ASUS ZenFone Lite L1</td>\n",
       "      <td>Black</td>\n",
       "      <td>2 GB RAM</td>\n",
       "      <td>16 GB ROM</td>\n",
       "      <td>13MP Rear Camera</td>\n",
       "      <td>5MP Front Camera</td>\n",
       "      <td>13.84 cm (5.45 inch) HD+ Display</td>\n",
       "      <td>3000 mAh Battery</td>\n",
       "      <td>â‚¹6,599</td>\n",
       "      <td>https://www.flipkart.com/asus-zenfone-lite-l1-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ASUS</td>\n",
       "      <td>ASUS ZenFone Max M1</td>\n",
       "      <td>Gold</td>\n",
       "      <td>3 GB RAM</td>\n",
       "      <td>32 GB ROM</td>\n",
       "      <td>13MP Rear Camera</td>\n",
       "      <td>8MP Front Camera</td>\n",
       "      <td>13.84 cm (5.45 inch) HD+ Display</td>\n",
       "      <td>4000 mAh Battery</td>\n",
       "      <td>â‚¹9,599</td>\n",
       "      <td>https://www.flipkart.com/asus-zenfone-max-m1-g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ASUS</td>\n",
       "      <td>ASUS ZenFone 5Z</td>\n",
       "      <td>Midnight Blue</td>\n",
       "      <td>8 GB RAM</td>\n",
       "      <td>256 GB ROM</td>\n",
       "      <td>12MP + 8MP</td>\n",
       "      <td>8MP Front Camera</td>\n",
       "      <td>15.75 cm (6.2 inch) Full HD+ Display</td>\n",
       "      <td>3300 mAh Battery</td>\n",
       "      <td>â‚¹43,999</td>\n",
       "      <td>https://www.flipkart.com/asus-zenfone-5z-midni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ASUS</td>\n",
       "      <td>ASUS ZenFone Max M2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>3 GB RAM</td>\n",
       "      <td>32 GB ROM</td>\n",
       "      <td>13MP + 2MP</td>\n",
       "      <td>8MP Front Camera</td>\n",
       "      <td>15.9 cm (6.26 inch) HD+ Display</td>\n",
       "      <td>4000 mAh Battery</td>\n",
       "      <td>â‚¹12,990</td>\n",
       "      <td>https://www.flipkart.com/asus-zenfone-max-m2-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ASUS</td>\n",
       "      <td>ASUS Zenfone 4 Selfie Dual Camera</td>\n",
       "      <td>Black</td>\n",
       "      <td>4 GB RAM</td>\n",
       "      <td>64 GB ROM</td>\n",
       "      <td>16MP Rear Camera</td>\n",
       "      <td>20MP + 8MP Dual Front Camera</td>\n",
       "      <td>13.97 cm (5.5 inch) HD Display</td>\n",
       "      <td>3000 mAh Battery</td>\n",
       "      <td>â‚¹15,999</td>\n",
       "      <td>https://www.flipkart.com/asus-zenfone-4-selfie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ASUS</td>\n",
       "      <td>ASUS Zenfone 3s Max</td>\n",
       "      <td>Black</td>\n",
       "      <td>3 GB RAM</td>\n",
       "      <td>32 GB ROM</td>\n",
       "      <td>13MP Rear Camera</td>\n",
       "      <td>8MP Front Camera</td>\n",
       "      <td>13.21 cm (5.2 inch) HD Display</td>\n",
       "      <td>5000 mAh Polymer Battery</td>\n",
       "      <td>â‚¹15,049</td>\n",
       "      <td>https://www.flipkart.com/asus-zenfone-3s-max-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ASUS</td>\n",
       "      <td>ASUS Zenfone 4 Selfie</td>\n",
       "      <td>Gold</td>\n",
       "      <td>3 GB RAM</td>\n",
       "      <td>32 GB ROM</td>\n",
       "      <td>13MP Rear Camera</td>\n",
       "      <td>13MP Front Camera</td>\n",
       "      <td>13.97 cm (5.5 inch) HD Display</td>\n",
       "      <td>3000 mAh Battery</td>\n",
       "      <td>â‚¹7,990</td>\n",
       "      <td>https://www.flipkart.com/asus-zenfone-4-selfie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Brand                        Product Name          Color        RAM  \\\n",
       "0   ASUS                ASUS ZenFone Max M2           Black  3 GB RAM    \n",
       "1   ASUS            ASUS ZenFone Max Pro M2            Blue  3 GB RAM    \n",
       "2   ASUS                ASUS ZenFone Max M2           Black  4 GB RAM    \n",
       "3   ASUS                    ASUS ZenFone 5Z   Meteor Silver  8 GB RAM    \n",
       "4   ASUS              ASUS Zenfone 4 Selfie           Black  3 GB RAM    \n",
       "5   ASUS            ASUS Zenfone Max Pro M1            Grey  6 GB RAM    \n",
       "6   ASUS                ASUS ZenFone Max M2            Blue  3 GB RAM    \n",
       "7   ASUS            ASUS Zenfone Max Pro M1            Blue  4 GB RAM    \n",
       "8   ASUS            ASUS Zenfone Max Pro M1            Grey  4 GB RAM    \n",
       "9   ASUS            ASUS Zenfone Max Pro M1            Blue  6 GB RAM    \n",
       "10  ASUS            ASUS Zenfone Max Pro M1            Blue  3 GB RAM    \n",
       "11  ASUS            ASUS Zenfone Max Pro M1           Black  4 GB RAM    \n",
       "12  ASUS                    ASUS ZenFone 5Z   Midnight Blue  6 GB RAM    \n",
       "13  ASUS            ASUS Zenfone Max Pro M1           Black  6 GB RAM    \n",
       "14  ASUS            ASUS Zenfone Max Pro M1            Grey  3 GB RAM    \n",
       "15  ASUS            ASUS Zenfone Max Pro M1           Black  3 GB RAM    \n",
       "16  ASUS                ASUS ZenFone Max M1           Black  4 GB RAM    \n",
       "17  ASUS               ASUS ZenFone Lite L1           Black  2 GB RAM    \n",
       "18  ASUS                ASUS ZenFone Max M1            Gold  3 GB RAM    \n",
       "19  ASUS                    ASUS ZenFone 5Z   Midnight Blue  8 GB RAM    \n",
       "20  ASUS                ASUS ZenFone Max M2          Silver  3 GB RAM    \n",
       "21  ASUS  ASUS Zenfone 4 Selfie Dual Camera           Black  4 GB RAM    \n",
       "22  ASUS                ASUS Zenfone 3s Max           Black  3 GB RAM    \n",
       "23  ASUS              ASUS Zenfone 4 Selfie            Gold  3 GB RAM    \n",
       "\n",
       "             ROM     Primary Camera               Secondary Camera  \\\n",
       "0     32 GB ROM         13MP + 2MP                8MP Front Camera   \n",
       "1     32 GB ROM         12MP + 5MP               13MP Front Camera   \n",
       "2     64 GB ROM         13MP + 2MP                8MP Front Camera   \n",
       "3    256 GB ROM         12MP + 8MP                8MP Front Camera   \n",
       "4     32 GB ROM   13MP Rear Camera               13MP Front Camera   \n",
       "5     64 GB ROM         16MP + 5MP               16MP Front Camera   \n",
       "6     32 GB ROM         13MP + 2MP                8MP Front Camera   \n",
       "7     64 GB ROM         13MP + 5MP                8MP Front Camera   \n",
       "8     64 GB ROM         13MP + 5MP                8MP Front Camera   \n",
       "9     64 GB ROM         16MP + 5MP               16MP Front Camera   \n",
       "10    32 GB ROM         13MP + 5MP                8MP Front Camera   \n",
       "11    64 GB ROM         13MP + 5MP                8MP Front Camera   \n",
       "12   128 GB ROM         12MP + 8MP                8MP Front Camera   \n",
       "13    64 GB ROM         16MP + 5MP               16MP Front Camera   \n",
       "14    32 GB ROM         13MP + 5MP                8MP Front Camera   \n",
       "15    32 GB ROM         13MP + 5MP                8MP Front Camera   \n",
       "16    64 GB ROM   13MP Rear Camera                8MP Front Camera   \n",
       "17    16 GB ROM   13MP Rear Camera                5MP Front Camera   \n",
       "18    32 GB ROM   13MP Rear Camera                8MP Front Camera   \n",
       "19   256 GB ROM         12MP + 8MP                8MP Front Camera   \n",
       "20    32 GB ROM         13MP + 2MP                8MP Front Camera   \n",
       "21    64 GB ROM   16MP Rear Camera    20MP + 8MP Dual Front Camera   \n",
       "22    32 GB ROM   13MP Rear Camera                8MP Front Camera   \n",
       "23    32 GB ROM   13MP Rear Camera               13MP Front Camera   \n",
       "\n",
       "                                  Display                   Battery    Price  \\\n",
       "0         15.9 cm (6.26 inch) HD+ Display          4000 mAh Battery  â‚¹12,549   \n",
       "1    15.9 cm (6.26 inch) Full HD+ Display          5000 mAh Battery  â‚¹15,999   \n",
       "2         15.9 cm (6.26 inch) HD+ Display          4000 mAh Battery  â‚¹14,999   \n",
       "3    15.75 cm (6.2 inch) Full HD+ Display          3300 mAh Battery  â‚¹43,999   \n",
       "4          13.97 cm (5.5 inch) HD Display          3000 mAh Battery  â‚¹10,999   \n",
       "5   15.21 cm (5.99 inch) Full HD+ Display          5000 mAh Battery  â‚¹17,999   \n",
       "6         15.9 cm (6.26 inch) HD+ Display          4000 mAh Battery  â‚¹12,549   \n",
       "7   15.21 cm (5.99 inch) Full HD+ Display          5000 mAh Battery  â‚¹15,599   \n",
       "8   15.21 cm (5.99 inch) Full HD+ Display          5000 mAh Battery  â‚¹15,599   \n",
       "9   15.21 cm (5.99 inch) Full HD+ Display          5000 mAh Battery  â‚¹17,999   \n",
       "10  15.21 cm (5.99 inch) Full HD+ Display          5000 mAh Battery  â‚¹13,199   \n",
       "11  15.21 cm (5.99 inch) Full HD+ Display          5000 mAh Battery  â‚¹15,599   \n",
       "12   15.75 cm (6.2 inch) Full HD+ Display          3300 mAh Battery  â‚¹36,299   \n",
       "13  15.21 cm (5.99 inch) Full HD+ Display          5000 mAh Battery  â‚¹17,999   \n",
       "14  15.21 cm (5.99 inch) Full HD+ Display          5000 mAh Battery  â‚¹13,199   \n",
       "15  15.21 cm (5.99 inch) Full HD+ Display          5000 mAh Battery  â‚¹13,199   \n",
       "16       13.84 cm (5.45 inch) HD+ Display          4000 mAh Battery   â‚¹9,599   \n",
       "17       13.84 cm (5.45 inch) HD+ Display          3000 mAh Battery   â‚¹6,599   \n",
       "18       13.84 cm (5.45 inch) HD+ Display          4000 mAh Battery   â‚¹9,599   \n",
       "19   15.75 cm (6.2 inch) Full HD+ Display          3300 mAh Battery  â‚¹43,999   \n",
       "20        15.9 cm (6.26 inch) HD+ Display          4000 mAh Battery  â‚¹12,990   \n",
       "21         13.97 cm (5.5 inch) HD Display          3000 mAh Battery  â‚¹15,999   \n",
       "22         13.21 cm (5.2 inch) HD Display  5000 mAh Polymer Battery  â‚¹15,049   \n",
       "23         13.97 cm (5.5 inch) HD Display          3000 mAh Battery   â‚¹7,990   \n",
       "\n",
       "                                                  url  \n",
       "0   https://www.flipkart.com/asus-zenfone-max-m2-b...  \n",
       "1   https://www.flipkart.com/asus-zenfone-max-pro-...  \n",
       "2   https://www.flipkart.com/asus-zenfone-max-m2-b...  \n",
       "3   https://www.flipkart.com/asus-zenfone-5z-meteo...  \n",
       "4   https://www.flipkart.com/asus-zenfone-4-selfie...  \n",
       "5   https://www.flipkart.com/asus-zenfone-max-pro-...  \n",
       "6   https://www.flipkart.com/asus-zenfone-max-m2-b...  \n",
       "7   https://www.flipkart.com/asus-zenfone-max-pro-...  \n",
       "8   https://www.flipkart.com/asus-zenfone-max-pro-...  \n",
       "9   https://www.flipkart.com/asus-zenfone-max-pro-...  \n",
       "10  https://www.flipkart.com/asus-zenfone-max-pro-...  \n",
       "11  https://www.flipkart.com/asus-zenfone-max-pro-...  \n",
       "12  https://www.flipkart.com/asus-zenfone-5z-midni...  \n",
       "13  https://www.flipkart.com/asus-zenfone-max-pro-...  \n",
       "14  https://www.flipkart.com/asus-zenfone-max-pro-...  \n",
       "15  https://www.flipkart.com/asus-zenfone-max-pro-...  \n",
       "16  https://www.flipkart.com/asus-zenfone-max-m1-b...  \n",
       "17  https://www.flipkart.com/asus-zenfone-lite-l1-...  \n",
       "18  https://www.flipkart.com/asus-zenfone-max-m1-g...  \n",
       "19  https://www.flipkart.com/asus-zenfone-5z-midni...  \n",
       "20  https://www.flipkart.com/asus-zenfone-max-m2-s...  \n",
       "21  https://www.flipkart.com/asus-zenfone-4-selfie...  \n",
       "22  https://www.flipkart.com/asus-zenfone-3s-max-b...  \n",
       "23  https://www.flipkart.com/asus-zenfone-4-selfie...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q4 Solution:\n",
    "\n",
    "# defining the lists to be used.\n",
    "brand=[]\n",
    "name=[]\n",
    "color=[]\n",
    "ram=[]\n",
    "rom=[]\n",
    "p_cam=[]\n",
    "s_cam=[]\n",
    "disp=[]\n",
    "battery=[]\n",
    "price=[]\n",
    "url=[]\n",
    "\n",
    "# defining the function for scraping smartphones from flipkart.com\n",
    "def flipkart_smartphone_scrapper(element):\n",
    "    \n",
    "    # connecting to the webdriver.\n",
    "    driver= webdriver.Chrome(\"chromedriver.exe\")\n",
    "    # opening the target website. \n",
    "    driver.get(\"https://www.flipkart.com\")\n",
    "    \n",
    "    # using the explicit wait method till the close-button in the login form is loaded.\n",
    "    wait= WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,\"/html/body/div[2]/div/div/button\")))\n",
    "    # finding the webelement for the close-button in the login form using absolute-xpath and clicking on it.\n",
    "    button= driver.find_element(By.XPATH,\"/html/body/div[2]/div/div/button\")\n",
    "    button.click()\n",
    "    \n",
    "    # using the explicit wait method till the search-field is loaded.\n",
    "    wait= WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")))\n",
    "    # finding the webelement for the search field using absolute-xpath and sending the required keys.\n",
    "    srch_sunglasses= driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "    srch_sunglasses.send_keys(element)\n",
    "\n",
    "    # finding the webelement for the search button using relative-xpath and clicking on it.\n",
    "    search_btn= driver.find_element(By.XPATH,\"//button[@class='L0Z3Pu']\")\n",
    "    search_btn.click()\n",
    "\n",
    "    # putting the program on hold for 5 seconds.\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Using the explicit wait method till the elements we want is loaded.\n",
    "    wait= WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,\"//div[@class='_4rR01T']\")))\n",
    "\n",
    "    # getting the webelements containing brand,product-name and color data using relative-xpath and then extract the text-data which is processed using split-method and then put them into corresponding lists. \n",
    "    brand_data= driver.find_elements(By.XPATH,\"//div[@class='_4rR01T']\")\n",
    "    for i in brand_data:\n",
    "        brand.append(i.text.split(\" \")[0])\n",
    "        name.append(i.text.split(\"(\")[0])\n",
    "        color.append(i.text.split(\"(\")[1].split(\",\")[0])\n",
    "\n",
    "    # getting the webelements containing specifications data using relative-xpath and then extract the text-data which is processed using split-method and then put them into corresponding lists. \n",
    "    spec_data= driver.find_elements(By.XPATH,\"//ul[@class='_1xgFaf']\")\n",
    "    for i in spec_data:\n",
    "        ram.append(i.text.split(\"\\n\")[0].split(\"|\")[0])\n",
    "        rom.append(i.text.split(\"\\n\")[0].split(\"|\")[1])\n",
    "        disp.append(i.text.split(\"\\n\")[1])\n",
    "        battery.append(i.text.split(\"\\n\")[3])\n",
    "\n",
    "        contents= i.text.split(\"\\n\")[2].split(\"|\")\n",
    "        if len(contents)==1:\n",
    "            p_cam.append(contents)\n",
    "            s_cam.append(\"-\")\n",
    "        else :\n",
    "            p_cam.append(contents[0])\n",
    "            s_cam.append(contents[1])\n",
    "\n",
    "    # getting the webelements containing url data using relative-xpath and then extract the links using the 'href' attribute into a list.\n",
    "    url_data= driver.find_elements(By.XPATH,\"//a[@class='_1fQZEK']\")\n",
    "    for i in url_data:\n",
    "        url.append(i.get_attribute('href'))\n",
    "\n",
    "    # getting the webelements containing price data using relative-xpath and then extract the text-data into a list.\n",
    "    price_data= driver.find_elements(By.XPATH,\"//div[@class='_30jeq3 _1_WHN1']\")\n",
    "    for i in price_data:\n",
    "        price.append(i.text)\n",
    "\n",
    "    # the final dataframe\n",
    "    results= pd.DataFrame({\"Brand\":brand,\n",
    "                           \"Product Name\":name, \n",
    "                           \"Color\":color, \n",
    "                           \"RAM\":ram, \n",
    "                           \"ROM\":rom, \n",
    "                           \"Primary Camera\":p_cam,\n",
    "                           \"Secondary Camera\":s_cam,\n",
    "                           \"Display\":disp,\n",
    "                           \"Battery\":battery,\n",
    "                           \"Price\":price,\n",
    "                           \"url\":url})\n",
    "    \n",
    "    # returning the final dataframe. \n",
    "    return results\n",
    "    # closing the webdriver.\n",
    "    driver.close()\n",
    "\n",
    "# taking input from the user.\n",
    "element= input(\"Search a smartphone: \")\n",
    "\n",
    "# calling the scrapper function and sending the user input as an arguement. \n",
    "results= flipkart_smartphone_scrapper(element)\n",
    "\n",
    "# exporting to a csv file in current directory.\n",
    "results.to_csv(f'{element} _search_results.csv',header=True,index=False)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d66019c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a city name: new delhi\n",
      "Geospatial coordinates:  28.527582 , 77.0688958\n"
     ]
    }
   ],
   "source": [
    "# Q5 solution:\n",
    "\n",
    "# defining a function to get the coordinates from google-maps.\n",
    "def city_coordinates(element):\n",
    "    # connecting to the webdriver.\n",
    "    driver= webdriver.Chrome(\"chromedriver.exe\")\n",
    "    # opening the target website. \n",
    "    driver.get(\"https://maps.google.com\")\n",
    "\n",
    "    # putting the program on hold for 3 seconds so that the page gets loaded.\n",
    "    time.sleep(3)\n",
    "    \n",
    "    wait= WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,\"/html/body/div[3]/div[9]/div[3]/div[1]/div[1]/div[1]/div[2]/form/div[2]/div[3]/div/input[1]\")))\n",
    "    # finding the webelement for the search field using absolute-xpath and sending the required keys.\n",
    "    srch_city= driver.find_element(By.XPATH,\"/html/body/div[3]/div[9]/div[3]/div[1]/div[1]/div[1]/div[2]/form/div[2]/div[3]/div/input[1]\")\n",
    "    srch_city.send_keys(element)\n",
    "\n",
    "    # finding the webelement for the search button using absolute-xpath and clicking on it.\n",
    "    srch_btn= driver.find_element(By.XPATH,\"/html/body/div[3]/div[9]/div[3]/div[1]/div[1]/div[1]/div[2]/div[1]/button\")\n",
    "    srch_btn.click()\n",
    "\n",
    "    # putting the program on hold for 4 seconds so that the page gets loaded.\n",
    "    time.sleep(4)\n",
    "\n",
    "    # getting the \"current-url\" text and extracting the coordinates values using split method.\n",
    "    contents= driver.current_url.split(\"@\")[1].split(\"/\")[0].split(\",\")\n",
    "\n",
    "    # print the coordinates.\n",
    "    print(\"Geospatial coordinates: \",contents[0],\",\",contents[1])\n",
    "\n",
    "    #closing the webdriver\n",
    "    driver.close()\n",
    "    \n",
    "# taking input from the user.\n",
    "element= input(\"Enter a city name: \")\n",
    "# calling the function and sending the user input as an arguement. \n",
    "city_coordinates(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "651047c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Startup Name</th>\n",
       "      <th>Industry/Vertical</th>\n",
       "      <th>Sub-Vertical</th>\n",
       "      <th>City/Location</th>\n",
       "      <th>Investor's Name</th>\n",
       "      <th>Investment Type</th>\n",
       "      <th>Amount(In USD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-04</td>\n",
       "      <td>DealShare</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Online shopping platform</td>\n",
       "      <td>Jaipur, Rajasthan</td>\n",
       "      <td>Innoven Capital</td>\n",
       "      <td>Debt Financing</td>\n",
       "      <td>250,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>Uniphore</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Conversational Service Automation (CSA)</td>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>Sorenson Capital Partners</td>\n",
       "      <td>Series D</td>\n",
       "      <td>140,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-30</td>\n",
       "      <td>Dunzo</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Hyper-local delivery app</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Krishtal Advisors Pte Ltd</td>\n",
       "      <td>Series E</td>\n",
       "      <td>8,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-30</td>\n",
       "      <td>BYJUâ€™S</td>\n",
       "      <td>Edu-tech</td>\n",
       "      <td>Online tutoring</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>MC Global Edtech, B Capital, Baron, others</td>\n",
       "      <td>Series F</td>\n",
       "      <td>460,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-23</td>\n",
       "      <td>SkilloVilla</td>\n",
       "      <td>Edu-tech</td>\n",
       "      <td>Career and job-oriented upskilling.</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Titan Capital, others</td>\n",
       "      <td>Seed</td>\n",
       "      <td>300,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-03-25</td>\n",
       "      <td>CityMall</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Social ecommerce and online grocery platform</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Accel Partners</td>\n",
       "      <td>Series A</td>\n",
       "      <td>11,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-03-26</td>\n",
       "      <td>DotPe</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Commerce and payments platform to offline ente...</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>PayU</td>\n",
       "      <td>Series A</td>\n",
       "      <td>27,500,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-02-11</td>\n",
       "      <td>Doubtnut</td>\n",
       "      <td>Edu Tech</td>\n",
       "      <td>E-Learning Platform</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>SIG Global, Sequoia Capital, WaterBridge Ventu...</td>\n",
       "      <td>Series B</td>\n",
       "      <td>2,500,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-02-22</td>\n",
       "      <td>Zomato</td>\n",
       "      <td>Hospitality</td>\n",
       "      <td>Online Food Delivery Platform</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Tiger Global, Kora</td>\n",
       "      <td>Venture</td>\n",
       "      <td>250,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-02-19</td>\n",
       "      <td>Fingerlix</td>\n",
       "      <td>Hospitality</td>\n",
       "      <td>Semi-cooked food delivery app</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Rhodium Trust, Accel Partners and Swiggy</td>\n",
       "      <td>Series C</td>\n",
       "      <td>2,747,045.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>Zolve</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Global Neobank Venture</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Accel Partners and Lightspeed Venture Partners</td>\n",
       "      <td>Seed</td>\n",
       "      <td>1,50,00,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021-02-15</td>\n",
       "      <td>KreditBee</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Digital lending platform</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Azim Premjiâ€™s PremjiInvest and South Koreaâ€™s M...</td>\n",
       "      <td>Series C</td>\n",
       "      <td>75,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>Pepperfry</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Multi-brand furniture brand</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>InnoVen Capital</td>\n",
       "      <td>Debt Financing</td>\n",
       "      <td>4,773,958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>Grofers</td>\n",
       "      <td>E-Commerce</td>\n",
       "      <td>Online supermarket</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>SoftBank Vision Fund (SVF)</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>55,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021-02-09</td>\n",
       "      <td>Nothing</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Consumer Technology Venture</td>\n",
       "      <td>London</td>\n",
       "      <td>GV</td>\n",
       "      <td>Series A</td>\n",
       "      <td>15,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021-02-09</td>\n",
       "      <td>SplashLearn</td>\n",
       "      <td>EdTech</td>\n",
       "      <td>Game-based learning programme</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Owl Ventures</td>\n",
       "      <td>Series C</td>\n",
       "      <td>18,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>Digit Insurance</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Insurance Services</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>A91 Partners, Faering Capital, TVS Capital Funds</td>\n",
       "      <td>Venture</td>\n",
       "      <td>1,80,00,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2021-01-28</td>\n",
       "      <td>Bombay Shaving Company</td>\n",
       "      <td>Consumer Goods Company</td>\n",
       "      <td>Shave care, beard care, and skincare products</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Reckitt Benckiser</td>\n",
       "      <td>Venture</td>\n",
       "      <td>6,172,258.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2021-01-19</td>\n",
       "      <td>DeHaat</td>\n",
       "      <td>AgriTech Startup</td>\n",
       "      <td>online marketplace for farm products and services</td>\n",
       "      <td>Patna</td>\n",
       "      <td>Prosus Ventures</td>\n",
       "      <td>Series C</td>\n",
       "      <td>30,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2021-01-19</td>\n",
       "      <td>Darwinbox</td>\n",
       "      <td>SaaS</td>\n",
       "      <td>HR Tech</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Salesforce Ventures</td>\n",
       "      <td>Seed</td>\n",
       "      <td>15,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>mfine</td>\n",
       "      <td>Health Tech Startup</td>\n",
       "      <td>AI-powered telemedicine mobile app</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Heritas Capital Management</td>\n",
       "      <td>Venture Round</td>\n",
       "      <td>16,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>Udayy</td>\n",
       "      <td>EdTech</td>\n",
       "      <td>Online learning platform for kids in class 1-5</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Sequoia Capital</td>\n",
       "      <td>Seed Funding</td>\n",
       "      <td>15,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2021-01-11</td>\n",
       "      <td>True Elements</td>\n",
       "      <td>Food Startup</td>\n",
       "      <td>Whole Food plant based Nashta</td>\n",
       "      <td>Pune</td>\n",
       "      <td>SIDBI Venture Capital</td>\n",
       "      <td>Series</td>\n",
       "      <td>100,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2021-01-13</td>\n",
       "      <td>Saveo</td>\n",
       "      <td>B2B E-commerce</td>\n",
       "      <td>Pharmacies</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Matrix Partners India, RTP Global, others</td>\n",
       "      <td>Seed</td>\n",
       "      <td>4,000,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date            Startup Name       Industry/Vertical  \\\n",
       "0  2021-03-04               DealShare              E-commerce   \n",
       "1  2021-03-31                Uniphore              Technology   \n",
       "2  2021-03-30                   Dunzo              E-commerce   \n",
       "3  2021-03-30                  BYJUâ€™S                Edu-tech   \n",
       "4  2021-03-23             SkilloVilla                Edu-tech   \n",
       "5  2021-03-25                CityMall              E-commerce   \n",
       "6  2021-03-26                   DotPe                 FinTech   \n",
       "7  2021-02-11                Doubtnut                Edu Tech   \n",
       "8  2021-02-22                  Zomato             Hospitality   \n",
       "9  2021-02-19               Fingerlix             Hospitality   \n",
       "10 2021-02-17                   Zolve                 FinTech   \n",
       "11 2021-02-15               KreditBee                 Finance   \n",
       "12 2021-02-12               Pepperfry              E-commerce   \n",
       "13 2021-02-12                 Grofers              E-Commerce   \n",
       "14 2021-02-09                 Nothing              Technology   \n",
       "15 2021-02-09             SplashLearn                  EdTech   \n",
       "16 2021-01-15         Digit Insurance      Financial Services   \n",
       "17 2021-01-28  Bombay Shaving Company  Consumer Goods Company   \n",
       "18 2021-01-19                  DeHaat        AgriTech Startup   \n",
       "19 2021-01-19               Darwinbox                    SaaS   \n",
       "20 2021-01-18                   mfine     Health Tech Startup   \n",
       "21 2021-01-18                   Udayy                  EdTech   \n",
       "22 2021-01-11           True Elements            Food Startup   \n",
       "23 2021-01-13                   Saveo          B2B E-commerce   \n",
       "\n",
       "                                         Sub-Vertical      City/Location  \\\n",
       "0                            Online shopping platform  Jaipur, Rajasthan   \n",
       "1             Conversational Service Automation (CSA)          Palo Alto   \n",
       "2                            Hyper-local delivery app          Bengaluru   \n",
       "3                                     Online tutoring          Bengaluru   \n",
       "4                 Career and job-oriented upskilling.          Bengaluru   \n",
       "5        Social ecommerce and online grocery platform            Gurgaon   \n",
       "6   Commerce and payments platform to offline ente...            Gurgaon   \n",
       "7                                 E-Learning Platform            Gurgaon   \n",
       "8                       Online Food Delivery Platform            Gurgaon   \n",
       "9                       Semi-cooked food delivery app             Mumbai   \n",
       "10                             Global Neobank Venture             Mumbai   \n",
       "11                           Digital lending platform          Bengaluru   \n",
       "12                        Multi-brand furniture brand             Mumbai   \n",
       "13                                 Online supermarket            Gurgaon   \n",
       "14                        Consumer Technology Venture             London   \n",
       "15                      Game-based learning programme            Gurgaon   \n",
       "16                                 Insurance Services          Bengaluru   \n",
       "17      Shave care, beard care, and skincare products          New Delhi   \n",
       "18  online marketplace for farm products and services              Patna   \n",
       "19                                            HR Tech             Mumbai   \n",
       "20                 AI-powered telemedicine mobile app          Bengaluru   \n",
       "21     Online learning platform for kids in class 1-5            Gurgaon   \n",
       "22                      Whole Food plant based Nashta               Pune   \n",
       "23                                         Pharmacies          Bengaluru   \n",
       "\n",
       "                                      Investor's Name Investment Type  \\\n",
       "0                                     Innoven Capital  Debt Financing   \n",
       "1                           Sorenson Capital Partners        Series D   \n",
       "2                           Krishtal Advisors Pte Ltd        Series E   \n",
       "3          MC Global Edtech, B Capital, Baron, others        Series F   \n",
       "4                               Titan Capital, others            Seed   \n",
       "5                                      Accel Partners        Series A   \n",
       "6                                                PayU        Series A   \n",
       "7   SIG Global, Sequoia Capital, WaterBridge Ventu...        Series B   \n",
       "8                                  Tiger Global, Kora         Venture   \n",
       "9            Rhodium Trust, Accel Partners and Swiggy        Series C   \n",
       "10     Accel Partners and Lightspeed Venture Partners            Seed   \n",
       "11  Azim Premjiâ€™s PremjiInvest and South Koreaâ€™s M...        Series C   \n",
       "12                                    InnoVen Capital  Debt Financing   \n",
       "13                         SoftBank Vision Fund (SVF)     Unspecified   \n",
       "14                                                 GV        Series A   \n",
       "15                                       Owl Ventures        Series C   \n",
       "16   A91 Partners, Faering Capital, TVS Capital Funds         Venture   \n",
       "17                                  Reckitt Benckiser         Venture   \n",
       "18                                    Prosus Ventures        Series C   \n",
       "19                                Salesforce Ventures            Seed   \n",
       "20                         Heritas Capital Management   Venture Round   \n",
       "21                                   Sequoia Capital     Seed Funding   \n",
       "22                              SIDBI Venture Capital          Series   \n",
       "23          Matrix Partners India, RTP Global, others            Seed   \n",
       "\n",
       "   Amount(In USD)  \n",
       "0     250,000,000  \n",
       "1     140,000,000  \n",
       "2       8,000,000  \n",
       "3     460,000,000  \n",
       "4     300,000,000  \n",
       "5      11,000,000  \n",
       "6      27,500,000  \n",
       "7       2,500,000  \n",
       "8     250,000,000  \n",
       "9    2,747,045.20  \n",
       "10    1,50,00,000  \n",
       "11     75,000,000  \n",
       "12      4,773,958  \n",
       "13     55,000,000  \n",
       "14     15,000,000  \n",
       "15     18,000,000  \n",
       "16   1,80,00,000   \n",
       "17   6,172,258.50  \n",
       "18     30,000,000  \n",
       "19     15,000,000  \n",
       "20     16,000,000  \n",
       "21     15,000,000  \n",
       "22    100,000,000  \n",
       "23     4,000,000   "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q6 solution:\n",
    "\n",
    "# defining a list of lists to be used.\n",
    "lists=[[],[],[],[],[],[],[],[]]\n",
    "\n",
    "# defining a function which takes 3 arguements- column-number, a list and a beautifulsoup object.\n",
    "# this function will extract the text data in the column to a list.\n",
    "def get_data(column_number,list_object,soup):\n",
    "    data= soup.find_all(\"td\",class_=f'column-{column_number}')\n",
    "    for j in data:\n",
    "        list_object.append(j.text)\n",
    "        \n",
    "# defining a function to scrap data from the website.\n",
    "def scrap_trak(url):\n",
    "    # sending request to the target website.\n",
    "    r= requests.get(url)\n",
    "    # getting the parsed content from which we will extract our data. \n",
    "    soup= bs(r.content)  \n",
    "\n",
    "    # using a variable named \"count\" to send the correct column-number to the function defined above.\n",
    "    count=2\n",
    "\n",
    "    # filling each list in the lists.\n",
    "    for i in lists:\n",
    "        get_data(count,i,soup)\n",
    "        count+=1\n",
    "\n",
    "    # making a dataframe from the list of lists.\n",
    "    x= pd.DataFrame(lists)\n",
    "    # taking a transpose of the dataframe since our desired columns are the rows in our dataframe.\n",
    "    df= x.T  \n",
    "\n",
    "    # naming the columns.\n",
    "    df.columns=[\"Date\",\"Startup Name\",\"Industry/Vertical\",\"Sub-Vertical\",\"City/Location\",\"Investor's Name\",\"Investment Type\",\"Amount(In USD)\"]  \n",
    "\n",
    "    # cleaning an entry so that \"to-datetime\" method can be applied on the \"Date\" column.\n",
    "    df[\"Date\"].replace(\"05/072018\",\"05/07/2018\", inplace=True)\n",
    "\n",
    "    # using the pandas \"to_datetime\" method to convert the text data in \"Date\" column to Date-Time format.\n",
    "    df[\"Date\"]= pd.to_datetime(df[\"Date\"], dayfirst=True)\n",
    "    \n",
    "    #returning the resultant dataframe.\n",
    "    return df\n",
    "\n",
    "# the url from which we will scrap the data.\n",
    "url= \"https://trak.in/india-startup-funding-investment-2015/\"\n",
    "\n",
    "# calling the \"scrap_trak\" function with the url as arguement.\n",
    "df= scrap_trak(url)\n",
    "\n",
    "# extracting the data for Jan 2021 â€“ March 2021.\n",
    "final_df= df[(df['Date'] >= '2021-01-01') & (df['Date'] <= '2021-03-31')]\n",
    "# reset the index of final dataframe.\n",
    "final_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8a955ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Processor</th>\n",
       "      <th>Display</th>\n",
       "      <th>OS</th>\n",
       "      <th>Memory</th>\n",
       "      <th>Graphics</th>\n",
       "      <th>Body</th>\n",
       "      <th>Price(â‚¹)</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSI TITAN GT77-12UHS</td>\n",
       "      <td>12th Gen Intel Core i9-12900HX 16 core processor</td>\n",
       "      <td>17.3â€³  (3840 x 2160) screen, 120 Hz refresh rate</td>\n",
       "      <td>Windows 11 Home</td>\n",
       "      <td>64 GB DDR5 RAM &amp; 2 TB SSD</td>\n",
       "      <td>16 GB DDR6 NVIDIA GeForce RTX 3080 Ti Graphics...</td>\n",
       "      <td>397 x 330 x 23 mm dimension &amp; 3.3 kg weight</td>\n",
       "      <td>--</td>\n",
       "      <td>https://www.digit.in/laptops/msi-titan-gt77-12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALIENWARE X17 R2</td>\n",
       "      <td>12th Gen Intel Core i9-12900HK 14 core process...</td>\n",
       "      <td>17.3â€³  (1920x1080) screen, 360 Hz refresh rate</td>\n",
       "      <td>Windows 11 Home</td>\n",
       "      <td>32 GB DDR5 RAM &amp; 1 TB SSD</td>\n",
       "      <td>16 GB DDR6 NVIDIA GeForce RTX 3080 Ti, Graphic...</td>\n",
       "      <td>399.23 x 299.57 x 14.75 mm dimension &amp; 3.02 kg...</td>\n",
       "      <td>389,990</td>\n",
       "      <td>https://www.digit.in/laptops/alienware-x17-r2-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACER PREDATOR TRITON 500 SE PT516-52S</td>\n",
       "      <td>12th Gen Intel Core i7-12700H 14 core processo...</td>\n",
       "      <td>16â€³  (2560 x 1600) screen, 240 Hz refresh rate</td>\n",
       "      <td>Windows 11 Home</td>\n",
       "      <td>32 GB DDR5 RAM &amp; 2 TB SSD</td>\n",
       "      <td>8 GB DDR6 NVIDIA GeForce RTXTM 3070 Ti Graphic...</td>\n",
       "      <td>358 x 262 x 19.9 mm dimension &amp; 2.4 kg weight</td>\n",
       "      <td>300,000</td>\n",
       "      <td>https://www.digit.in/laptops/acer-predator-tri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OMEN BY HP (16-B1371TX)</td>\n",
       "      <td>12th Gen Intel Core i7-12700H 14 core processo...</td>\n",
       "      <td>16.1â€³  (2560 x 1440) screen</td>\n",
       "      <td>Windows 11 Home</td>\n",
       "      <td>8 GB DDR5 RAM &amp; 1 TB SSD</td>\n",
       "      <td>8 GB GDDR6 NVIDIA GeForce RTX 3070 Graphics card</td>\n",
       "      <td>369 x 248 x 23 mm dimension &amp; 2.32 kg weight</td>\n",
       "      <td>195,600</td>\n",
       "      <td>https://www.digit.in/laptops/omen-by-hp-16-b13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACER PREDATOR HELIOS 300 AN515-45 (NH.QBRSI.0</td>\n",
       "      <td>AMD Ryzen 9-5900HX 8 core processor</td>\n",
       "      <td>15.6â€³  (2560 x 1440) screen, 165 Hz refresh rate</td>\n",
       "      <td>Windows 11 Home</td>\n",
       "      <td>16 GB DDR4 RAM &amp; 512 GB SSD</td>\n",
       "      <td>8 GB DDR6 NVIDIA GeForce RTX 3070 Graphics card</td>\n",
       "      <td>363 x 255 x 23.9 mm dimension &amp; 2.4 kg weight</td>\n",
       "      <td>172,999</td>\n",
       "      <td>https://www.digit.in/laptops/acer-nitro-5-an51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MSI DELTA 15 (A5EFK-083IN)</td>\n",
       "      <td>AMD 5th Gen Ryzen 9-5900HX 8 core processor wi...</td>\n",
       "      <td>15.6â€³  (1920 x 1080) screen, 240Hz refresh rate</td>\n",
       "      <td>Windows 11 Home</td>\n",
       "      <td>16 GB DDR4 RAM &amp; 1 TB SSD</td>\n",
       "      <td>10 GB DDR6 AMD Radeon RX 6700M Graphics card</td>\n",
       "      <td>357 x 247 x 19 mm dimension &amp; 1.9 kg weight</td>\n",
       "      <td>188,990</td>\n",
       "      <td>https://www.digit.in/laptops/msi-delta-15-5th-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OMEN BY HP (16-C0141AX)</td>\n",
       "      <td>AMD Ryzenâ„¢ 9 5900HX 8 core processor with 3.3 ...</td>\n",
       "      <td>16.1â€³  (2560 x 1440) screen</td>\n",
       "      <td>Windows 11 Home</td>\n",
       "      <td>16 GB â€ŽDDR4 RAM &amp; 1 TB NVMe</td>\n",
       "      <td>8 GB GDDR6 AMD Radeonâ„¢ RX 6600M Graphics card</td>\n",
       "      <td>36.92 x 24.8 x 2.3 mm dimension &amp; 2.3 kg weight</td>\n",
       "      <td>129,899</td>\n",
       "      <td>https://www.digit.in/laptops/hp-omen-16-c0141a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LENOVO LEGION 5I PRO (82RF00MGIN)</td>\n",
       "      <td>12th Gen Intel Core i7-12700H 14 core processo...</td>\n",
       "      <td>16â€³  (2560 x 1600) screen, 165 Hz refresh rate</td>\n",
       "      <td>Windows 11 Home</td>\n",
       "      <td>16 GB DDR5 RAM &amp; 1 TB SSD</td>\n",
       "      <td>6 GB DDR6 NVIDIA GeForce RTX 3060 Graphics card</td>\n",
       "      <td>359.9 x 264.4 x 19.9 mm dimension &amp; 2.5 kg weight</td>\n",
       "      <td>230,890</td>\n",
       "      <td>https://www.digit.in/laptops/lenovo-legion-5i-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ALIENWARE M15 R5 RYZEN EDITION ICC-C780001WIN</td>\n",
       "      <td>AMD Ryzen R7-5800H 8 core processor with 4.40 ...</td>\n",
       "      <td>15.6â€³  (1920 x 1080) screen, 165Hz refresh rate</td>\n",
       "      <td>Windows 11 Home</td>\n",
       "      <td>16 GB DDR4 RAM &amp; 512 GB SSD</td>\n",
       "      <td>6 GB DDR6 NVIDIA GeForce RTX 3060 Graphics card</td>\n",
       "      <td>356.2 x 272.5 x 22.85 mm dimension &amp; 2.69 kg w...</td>\n",
       "      <td>140,999</td>\n",
       "      <td>https://www.digit.in/laptops/dell-alienware-m1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LENOVO SLIM 7 GEN 6 (82K8002JIN)</td>\n",
       "      <td>Lenovo Ryzen 7-5800H processor with 3.2 GHz cl...</td>\n",
       "      <td>15.6â€³  screen, 165 Hz refresh rate</td>\n",
       "      <td>Windows 11 Home</td>\n",
       "      <td>16 GB DDR4 RAM &amp; 1 TB SSD</td>\n",
       "      <td>6 GB DDR6 NVIDIA GeForce 3060 Max-Q Graphics card</td>\n",
       "      <td>356 x 252 x 16 mm dimension &amp; 1.9 kg weight</td>\n",
       "      <td>135,490</td>\n",
       "      <td>https://www.digit.in/laptops/lenovo-legion-s7-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Product Name  \\\n",
       "0                           MSI TITAN GT77-12UHS   \n",
       "1                               ALIENWARE X17 R2   \n",
       "2          ACER PREDATOR TRITON 500 SE PT516-52S   \n",
       "3                        OMEN BY HP (16-B1371TX)   \n",
       "4  ACER PREDATOR HELIOS 300 AN515-45 (NH.QBRSI.0   \n",
       "5                     MSI DELTA 15 (A5EFK-083IN)   \n",
       "6                        OMEN BY HP (16-C0141AX)   \n",
       "7              LENOVO LEGION 5I PRO (82RF00MGIN)   \n",
       "8  ALIENWARE M15 R5 RYZEN EDITION ICC-C780001WIN   \n",
       "9               LENOVO SLIM 7 GEN 6 (82K8002JIN)   \n",
       "\n",
       "                                           Processor  \\\n",
       "0   12th Gen Intel Core i9-12900HX 16 core processor   \n",
       "1  12th Gen Intel Core i9-12900HK 14 core process...   \n",
       "2  12th Gen Intel Core i7-12700H 14 core processo...   \n",
       "3  12th Gen Intel Core i7-12700H 14 core processo...   \n",
       "4                AMD Ryzen 9-5900HX 8 core processor   \n",
       "5  AMD 5th Gen Ryzen 9-5900HX 8 core processor wi...   \n",
       "6  AMD Ryzenâ„¢ 9 5900HX 8 core processor with 3.3 ...   \n",
       "7  12th Gen Intel Core i7-12700H 14 core processo...   \n",
       "8  AMD Ryzen R7-5800H 8 core processor with 4.40 ...   \n",
       "9  Lenovo Ryzen 7-5800H processor with 3.2 GHz cl...   \n",
       "\n",
       "                                            Display               OS  \\\n",
       "0  17.3â€³  (3840 x 2160) screen, 120 Hz refresh rate  Windows 11 Home   \n",
       "1    17.3â€³  (1920x1080) screen, 360 Hz refresh rate  Windows 11 Home   \n",
       "2    16â€³  (2560 x 1600) screen, 240 Hz refresh rate  Windows 11 Home   \n",
       "3                       16.1â€³  (2560 x 1440) screen  Windows 11 Home   \n",
       "4  15.6â€³  (2560 x 1440) screen, 165 Hz refresh rate  Windows 11 Home   \n",
       "5   15.6â€³  (1920 x 1080) screen, 240Hz refresh rate  Windows 11 Home   \n",
       "6                       16.1â€³  (2560 x 1440) screen  Windows 11 Home   \n",
       "7    16â€³  (2560 x 1600) screen, 165 Hz refresh rate  Windows 11 Home   \n",
       "8   15.6â€³  (1920 x 1080) screen, 165Hz refresh rate  Windows 11 Home   \n",
       "9                15.6â€³  screen, 165 Hz refresh rate  Windows 11 Home   \n",
       "\n",
       "                        Memory  \\\n",
       "0    64 GB DDR5 RAM & 2 TB SSD   \n",
       "1    32 GB DDR5 RAM & 1 TB SSD   \n",
       "2    32 GB DDR5 RAM & 2 TB SSD   \n",
       "3     8 GB DDR5 RAM & 1 TB SSD   \n",
       "4  16 GB DDR4 RAM & 512 GB SSD   \n",
       "5    16 GB DDR4 RAM & 1 TB SSD   \n",
       "6  16 GB â€ŽDDR4 RAM & 1 TB NVMe   \n",
       "7    16 GB DDR5 RAM & 1 TB SSD   \n",
       "8  16 GB DDR4 RAM & 512 GB SSD   \n",
       "9    16 GB DDR4 RAM & 1 TB SSD   \n",
       "\n",
       "                                            Graphics  \\\n",
       "0  16 GB DDR6 NVIDIA GeForce RTX 3080 Ti Graphics...   \n",
       "1  16 GB DDR6 NVIDIA GeForce RTX 3080 Ti, Graphic...   \n",
       "2  8 GB DDR6 NVIDIA GeForce RTXTM 3070 Ti Graphic...   \n",
       "3   8 GB GDDR6 NVIDIA GeForce RTX 3070 Graphics card   \n",
       "4    8 GB DDR6 NVIDIA GeForce RTX 3070 Graphics card   \n",
       "5       10 GB DDR6 AMD Radeon RX 6700M Graphics card   \n",
       "6      8 GB GDDR6 AMD Radeonâ„¢ RX 6600M Graphics card   \n",
       "7    6 GB DDR6 NVIDIA GeForce RTX 3060 Graphics card   \n",
       "8    6 GB DDR6 NVIDIA GeForce RTX 3060 Graphics card   \n",
       "9  6 GB DDR6 NVIDIA GeForce 3060 Max-Q Graphics card   \n",
       "\n",
       "                                                Body Price(â‚¹)  \\\n",
       "0        397 x 330 x 23 mm dimension & 3.3 kg weight       --   \n",
       "1  399.23 x 299.57 x 14.75 mm dimension & 3.02 kg...  389,990   \n",
       "2      358 x 262 x 19.9 mm dimension & 2.4 kg weight  300,000   \n",
       "3       369 x 248 x 23 mm dimension & 2.32 kg weight  195,600   \n",
       "4      363 x 255 x 23.9 mm dimension & 2.4 kg weight  172,999   \n",
       "5        357 x 247 x 19 mm dimension & 1.9 kg weight  188,990   \n",
       "6    36.92 x 24.8 x 2.3 mm dimension & 2.3 kg weight  129,899   \n",
       "7  359.9 x 264.4 x 19.9 mm dimension & 2.5 kg weight  230,890   \n",
       "8  356.2 x 272.5 x 22.85 mm dimension & 2.69 kg w...  140,999   \n",
       "9        356 x 252 x 16 mm dimension & 1.9 kg weight  135,490   \n",
       "\n",
       "                                                Link  \n",
       "0  https://www.digit.in/laptops/msi-titan-gt77-12...  \n",
       "1  https://www.digit.in/laptops/alienware-x17-r2-...  \n",
       "2  https://www.digit.in/laptops/acer-predator-tri...  \n",
       "3  https://www.digit.in/laptops/omen-by-hp-16-b13...  \n",
       "4  https://www.digit.in/laptops/acer-nitro-5-an51...  \n",
       "5  https://www.digit.in/laptops/msi-delta-15-5th-...  \n",
       "6  https://www.digit.in/laptops/hp-omen-16-c0141a...  \n",
       "7  https://www.digit.in/laptops/lenovo-legion-5i-...  \n",
       "8  https://www.digit.in/laptops/dell-alienware-m1...  \n",
       "9  https://www.digit.in/laptops/lenovo-legion-s7-...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q7 Solution:\n",
    "\n",
    "# defining the lists to be used.\n",
    "names=[]\n",
    "processor=[]\n",
    "display=[]\n",
    "os=[]\n",
    "memory=[]\n",
    "graphics=[]\n",
    "body=[]\n",
    "prices=[]\n",
    "links=[]\n",
    "\n",
    "# defining a function to scrap gaming-laptops data from digit.in\n",
    "def gaming_laptops(url):\n",
    "    \n",
    "    # sending request to the target website.\n",
    "    r= requests.get(url)\n",
    "    # getting the parsed content from which we will extract our data. \n",
    "    soup= bs(r.content)\n",
    "\n",
    "    # getting the elements having the names and extracting the text into a list. \n",
    "    data= soup.find_all(\"h3\")\n",
    "    for i in data:\n",
    "        names.append(i.text)\n",
    "\n",
    "    # getting the elements having the links to each product and extracting them into a list.   \n",
    "    data=soup.find_all(\"div\",id=[\"toptenIdevent1\",\"toptenIdevent2\",\"toptenIdevent3\",\"toptenIdevent4\",\"toptenIdevent5\",\"toptenIdevent6\",\"toptenIdevent7\",\"toptenIdevent8\",\"toptenIdevent9\",\"toptenIdevent10\"])\n",
    "    for i in data:\n",
    "        link= i.find(\"a\",href=True)\n",
    "        links.append(link['href'])\n",
    "\n",
    "    # getting the elements having the specifications and price data and extracting the relevant text into the corresponding lists. \n",
    "    data= soup.find_all(\"div\",class_=\"Section-center\")\n",
    "    count=0\n",
    "    for i in data:\n",
    "        spec_data=i.find(\"div\",class_=\"Spcs-details\")\n",
    "        x= spec_data.text.strip().split(\"\\n\")\n",
    "        processor.append(x[4])\n",
    "        display.append(x[9])\n",
    "        os.append(x[14])\n",
    "        memory.append(x[19])\n",
    "        graphics.append(x[24])\n",
    "        body.append(x[29])\n",
    "\n",
    "        price_data= i.find(\"div\",class_=\"merchantdatalist1 merchantdatalist2\").text.strip()\n",
    "        if price_data==\"\":\n",
    "            # the price is not mentioned in the main page for some products. Hence extracting that info from that product page.\n",
    "            r_= requests.get(links[count])\n",
    "            soup_=bs(r_.content)\n",
    "            content=soup_.find(\"div\",class_=\"price\").text.strip().split(\"\\t\")\n",
    "            if content[-1]==\"\":\n",
    "                prices.append(\"--\")\n",
    "            else:\n",
    "                prices.append(content[-1])\n",
    "        else:\n",
    "            prices.append(price_data.split(\"â‚¹\")[1].strip().split(\" \")[0])\n",
    "        count+=1  \n",
    "\n",
    "    # the final dataframe\n",
    "    gmng_laptops= pd.DataFrame({\"Product Name\":names,\n",
    "                                \"Processor\":processor,\n",
    "                                \"Display\":display, \n",
    "                                \"OS\":os, \n",
    "                                \"Memory\":memory, \n",
    "                                \"Graphics\":graphics, \n",
    "                                \"Body\":body,\n",
    "                                \"Price(â‚¹)\":prices,\n",
    "                                \"Link\": links                        \n",
    "                                })\n",
    "    # returning the final dataframe.\n",
    "    return gmng_laptops\n",
    "\n",
    "# the url from which we will scrap the data.\n",
    "url= \"https://www.digit.in/top-products/best-gaming-laptops-40.html\"\n",
    "\n",
    "# calling the \"gaming_laptops\" function with the url as arguement and saving the result.\n",
    "df= gaming_laptops(url)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3e9d954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Net Worth</th>\n",
       "      <th>Age</th>\n",
       "      <th>Citizenship</th>\n",
       "      <th>Source</th>\n",
       "      <th>Industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>$219 B</td>\n",
       "      <td>50</td>\n",
       "      <td>United States</td>\n",
       "      <td>Tesla, SpaceX</td>\n",
       "      <td>Automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>Jeff Bezos</td>\n",
       "      <td>$171 B</td>\n",
       "      <td>58</td>\n",
       "      <td>United States</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Bernard Arnault &amp; family</td>\n",
       "      <td>$158 B</td>\n",
       "      <td>73</td>\n",
       "      <td>France</td>\n",
       "      <td>LVMH</td>\n",
       "      <td>Fashion &amp; Retail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>Bill Gates</td>\n",
       "      <td>$129 B</td>\n",
       "      <td>66</td>\n",
       "      <td>United States</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>Warren Buffett</td>\n",
       "      <td>$118 B</td>\n",
       "      <td>91</td>\n",
       "      <td>United States</td>\n",
       "      <td>Berkshire Hathaway</td>\n",
       "      <td>Finance &amp; Investments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2663</th>\n",
       "      <td>2578.</td>\n",
       "      <td>Zhang Yuqiang</td>\n",
       "      <td>$1 B</td>\n",
       "      <td>66</td>\n",
       "      <td>China</td>\n",
       "      <td>Fiberglass</td>\n",
       "      <td>Manufacturing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2664</th>\n",
       "      <td>2578.</td>\n",
       "      <td>Zhou Ruxin</td>\n",
       "      <td>$1 B</td>\n",
       "      <td>59</td>\n",
       "      <td>China</td>\n",
       "      <td>Navigation</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2665</th>\n",
       "      <td>2578.</td>\n",
       "      <td>Wen Zhou &amp; family</td>\n",
       "      <td>$1 B</td>\n",
       "      <td>57</td>\n",
       "      <td>China</td>\n",
       "      <td>chemicals</td>\n",
       "      <td>Manufacturing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2666</th>\n",
       "      <td>2578.</td>\n",
       "      <td>Zhou Yifeng &amp; family</td>\n",
       "      <td>$1 B</td>\n",
       "      <td>43</td>\n",
       "      <td>China</td>\n",
       "      <td>liquefied petroleum gas</td>\n",
       "      <td>Energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2667</th>\n",
       "      <td>2578.</td>\n",
       "      <td>Zhuang Kuilong &amp; family</td>\n",
       "      <td>$1 B</td>\n",
       "      <td>59</td>\n",
       "      <td>China</td>\n",
       "      <td>polyester</td>\n",
       "      <td>Manufacturing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2668 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Rank                      Name Net Worth Age    Citizenship  \\\n",
       "0        1.                 Elon Musk    $219 B  50  United States   \n",
       "1        2.                Jeff Bezos    $171 B  58  United States   \n",
       "2        3.  Bernard Arnault & family    $158 B  73         France   \n",
       "3        4.                Bill Gates    $129 B  66  United States   \n",
       "4        5.            Warren Buffett    $118 B  91  United States   \n",
       "...     ...                       ...       ...  ..            ...   \n",
       "2663  2578.             Zhang Yuqiang      $1 B  66          China   \n",
       "2664  2578.                Zhou Ruxin      $1 B  59          China   \n",
       "2665  2578.         Wen Zhou & family      $1 B  57          China   \n",
       "2666  2578.      Zhou Yifeng & family      $1 B  43          China   \n",
       "2667  2578.   Zhuang Kuilong & family      $1 B  59          China   \n",
       "\n",
       "                       Source               Industry  \n",
       "0               Tesla, SpaceX             Automotive  \n",
       "1                      Amazon             Technology  \n",
       "2                        LVMH       Fashion & Retail  \n",
       "3                   Microsoft             Technology  \n",
       "4          Berkshire Hathaway  Finance & Investments  \n",
       "...                       ...                    ...  \n",
       "2663               Fiberglass          Manufacturing  \n",
       "2664               Navigation             Technology  \n",
       "2665                chemicals          Manufacturing  \n",
       "2666  liquefied petroleum gas                 Energy  \n",
       "2667                polyester          Manufacturing  \n",
       "\n",
       "[2668 rows x 7 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q8 Solution:\n",
    "\n",
    "# defining the lists to be used.\n",
    "ranks=[]\n",
    "names=[]\n",
    "net_wrth=[]\n",
    "age=[]\n",
    "ctznsp=[]\n",
    "source=[]\n",
    "industry=[]\n",
    "count=0\n",
    "\n",
    "# defining a function to append data into our lists.\n",
    "def fill_data(content):\n",
    "    ranks.append(content[0])\n",
    "    names.append(content[1])\n",
    "    net_wrth.append(content[2])\n",
    "    age.append(content[3])\n",
    "    ctznsp.append(content[4])\n",
    "    source.append(content[5])\n",
    "    industry.append(content[6])\n",
    "\n",
    "# defining a function to append null values incase we face \"WebDriverException\".\n",
    "# the \"count\" variable can be used to check if we had any missing entries.\n",
    "def fill_na():\n",
    "    ranks.append(\"-\")\n",
    "    names.append(\"-\")\n",
    "    net_wrth.append(\"-\")\n",
    "    age.append(\"-\")\n",
    "    ctznsp.append(\"-\")\n",
    "    source.append(\"-\")\n",
    "    industry.append(\"-\")\n",
    "    count+=1\n",
    "    \n",
    "# defining a function to scrap data.\n",
    "def billionaires_data(url):\n",
    "    # connecting to the webdriver.\n",
    "    driver= webdriver.Chrome(\"chromedriver.exe\")\n",
    "    # opening the target website.\n",
    "    driver.get(url)\n",
    "\n",
    "    # putting the program on hold for 5 seconds so that the website gets loaded properly.\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # using the explicit wait method till the menu button(three-dash button) gets loaded.\n",
    "    wait= WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,\"/html/body/div[1]/header/nav/div[1]/button[1]\")))\n",
    "    # finding the webelement for the menu button using absolute x-path and clicking on it.\n",
    "    menu_btn= driver.find_element(By.XPATH,\"/html/body/div[1]/header/nav/div[1]/button[1]\").click()\n",
    "    \n",
    "    # using the explicit wait method till the element we want gets loaded.\n",
    "    wait= WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,\"/html/body/div[1]/header/nav/div[3]/ul/li[1]/div[2]/ul/li[2]/a\")))\n",
    "    # finding the webelement for the \"World's Billionaires\" option using absolute x-path and getting the link from it using the \"href\" attrubute.\n",
    "    all_billnrs= driver.find_element(By.XPATH,\"/html/body/div[1]/header/nav/div[3]/ul/li[1]/div[2]/ul/li[2]/a\")\n",
    "    link= all_billnrs.get_attribute(\"href\")\n",
    "\n",
    "    # opening the \"World's Billionaires\" webpage.\n",
    "    driver.get(link)\n",
    "    # Using the explicit wait method till the element we want is loaded.\n",
    "    wait= WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,\"//button[@class='goto-page__btn']\")))\n",
    "    # finding the webelements for the buttons to different pages having the list of billionaires.\n",
    "    btns= driver.find_elements(By.XPATH,\"//button[@class='goto-page__btn']\")\n",
    "\n",
    "    # using a for loop to go through each page.\n",
    "    for page in btns[1:]:\n",
    "        # using the explicit wait method till the element we want is loaded.\n",
    "        wait= WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,\"/html/body/div[1]/div[1]/div/div/div[3]/div[2]/div[2]/div[2]/div[1]/div[2]/div[1]\")))\n",
    "\n",
    "        # finding the webelement for the first entry in a page using absolute x-path and then processing it and extracting the text data.\n",
    "        # If we face \"WebDriverException\" error then we just add \"-\" as the entry.\n",
    "        list_top_data= driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div/div/div[3]/div[2]/div[2]/div[2]/div[1]/div[2]/div[1]\")\n",
    "        try:\n",
    "            content=list_top_data.text.strip().split(\"\\n\")\n",
    "            fill_data(content)\n",
    "        except WebDriverException:\n",
    "            fill_na()\n",
    "\n",
    "        # finding the webelements for all the entries in a page(except the first entry) using relative x-path and then processing it and extracting the text data.\n",
    "        # If we face \"WebDriverException\" error then we just add \"-\" as the entry.\n",
    "        data= driver.find_elements(By.XPATH,\"//div[@class='table-row ']\")\n",
    "        for i in data:\n",
    "            try:\n",
    "                content=i.text.strip().split(\"\\n\")\n",
    "                fill_data(content)\n",
    "            except WebDriverException:\n",
    "                fill_na()\n",
    "\n",
    "        # clicking the button for next page and put the program on hold for 2 seconds so that the page gets loaded properly.\n",
    "        page.click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        # collecting the data for the last page.\n",
    "        if page== btns[-1]:        \n",
    "            list_top_data= driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div/div/div[3]/div[2]/div[2]/div[2]/div[1]/div[2]/div[1]\")\n",
    "            try:\n",
    "                content=list_top_data.text.strip().split(\"\\n\")\n",
    "                fill_data(content)\n",
    "            except WebDriverException:\n",
    "                fill_na()\n",
    "\n",
    "            data= driver.find_elements(By.XPATH,\"//div[@class='table-row ']\")\n",
    "            for i in data:\n",
    "                try:\n",
    "                    content=i.text.strip().split(\"\\n\")\n",
    "                    fill_data(content)\n",
    "                except WebDriverException:\n",
    "                    fill_na()\n",
    "\n",
    "        else:\n",
    "            continue \n",
    "\n",
    "    # the final dataframe\n",
    "    billionaires= pd.DataFrame({\"Rank\":ranks,\n",
    "                                \"Name\":names,\n",
    "                                \"Net Worth\":net_wrth, \n",
    "                                \"Age\":age, \n",
    "                                \"Citizenship\":ctznsp, \n",
    "                                \"Source\":source, \n",
    "                                \"Industry\":industry                       \n",
    "                               })\n",
    "    # closing the webdriver\n",
    "    driver.close()\n",
    "    #returning the dataframe.\n",
    "    return billionaires\n",
    "\n",
    "# the url from which we will scrap the data.\n",
    "url= \"https://www.forbes.com/\"\n",
    "\n",
    "# calling the \"billionaires_data\" function with the url as arguement.\n",
    "df= billionaires_data(url)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7a482929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Posted</th>\n",
       "      <th>Upvotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lets be honest here, this guy owned the world ...</td>\n",
       "      <td>2 years ago (edited)</td>\n",
       "      <td>142K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This guy appeared out of nowhere, and everyone...</td>\n",
       "      <td>2 years ago</td>\n",
       "      <td>50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Exatamente 10 anos dessa mÃºsica. Lembro quando...</td>\n",
       "      <td>2 weeks ago</td>\n",
       "      <td>3.8K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can't believe it's been 10 years since PSY inv...</td>\n",
       "      <td>2 weeks ago</td>\n",
       "      <td>909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Saudades dessa Ã©poca! Aeee cadÃª os BR??? ðŸ‡§ðŸ‡·ðŸ‡§ðŸ‡·ðŸ‡§ðŸ‡·</td>\n",
       "      <td>2 years ago</td>\n",
       "      <td>27K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>Hace exactamente 10 aÃ±os de esta gran canciÃ³n</td>\n",
       "      <td>2 weeks ago</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>10 aÃ±os de esta canciÃ³n.. una locura.. recuerd...</td>\n",
       "      <td>2 weeks ago</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>Meu pai toda hora canta essa mÃºsica por isso c...</td>\n",
       "      <td>2 weeks ago</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>Despues de 10 aÃ±os, lo vuelvo a escuchar esta ...</td>\n",
       "      <td>2 weeks ago</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>Dez anos de pura nostalgia</td>\n",
       "      <td>2 weeks ago</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>580 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Comment                Posted  \\\n",
       "0    Lets be honest here, this guy owned the world ...  2 years ago (edited)   \n",
       "1    This guy appeared out of nowhere, and everyone...           2 years ago   \n",
       "2    Exatamente 10 anos dessa mÃºsica. Lembro quando...           2 weeks ago   \n",
       "3    Can't believe it's been 10 years since PSY inv...           2 weeks ago   \n",
       "4      Saudades dessa Ã©poca! Aeee cadÃª os BR??? ðŸ‡§ðŸ‡·ðŸ‡§ðŸ‡·ðŸ‡§ðŸ‡·           2 years ago   \n",
       "..                                                 ...                   ...   \n",
       "575     Hace exactamente 10 aÃ±os de esta gran canciÃ³n            2 weeks ago   \n",
       "576  10 aÃ±os de esta canciÃ³n.. una locura.. recuerd...           2 weeks ago   \n",
       "577  Meu pai toda hora canta essa mÃºsica por isso c...           2 weeks ago   \n",
       "578  Despues de 10 aÃ±os, lo vuelvo a escuchar esta ...           2 weeks ago   \n",
       "579                         Dez anos de pura nostalgia           2 weeks ago   \n",
       "\n",
       "    Upvotes  \n",
       "0      142K  \n",
       "1       50K  \n",
       "2      3.8K  \n",
       "3       909  \n",
       "4       27K  \n",
       "..      ...  \n",
       "575       0  \n",
       "576      12  \n",
       "577       8  \n",
       "578       5  \n",
       "579       0  \n",
       "\n",
       "[580 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q9 Solution:\n",
    "\n",
    "# defining a function to scrap youtube comments.\n",
    "def youtube_comments(url):\n",
    "    \n",
    "    # connecting to the webdriver.\n",
    "    driver= webdriver.Chrome(\"chromedriver.exe\")\n",
    "    # opening the target website.\n",
    "    driver.get(url)\n",
    "    # putting the program on hold for 5 seconds so that the webpage gets loaded properly.\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # we can use the \"page-up\",\"page-down\",\"end\",etc keyboard keys by using the \"send_keys\" method and \"Keys\" class of selenium.\n",
    "    # since we have to scrap hundreds of comments hence running a loop of going to page-end with 3 seconds gap.\n",
    "    html = driver.find_element(By.TAG_NAME,'html')\n",
    "    for i in range(0,30):    \n",
    "        html.send_keys(Keys.END)\n",
    "        time.sleep(3)\n",
    "    \n",
    "    # Using the explicit wait method till the comments data is loaded.\n",
    "    wait= WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,\"//ytd-comment-renderer[@class='style-scope ytd-comment-thread-renderer']\")))\n",
    "    # finding the webelements having the comments data.\n",
    "    data= driver.find_elements(By.XPATH,\"//ytd-comment-renderer[@class='style-scope ytd-comment-thread-renderer']\")\n",
    "    \n",
    "    #defining the lists to be used.\n",
    "    comments=[]\n",
    "    time_ago=[]\n",
    "    upvotes=[]\n",
    "    \n",
    "    # running a for loop for each comment webelement and extracting the text data into corresponding lists.\n",
    "    for i in data:\n",
    "        content=i.text.strip().split(\"\\n\")\n",
    "        upvote= i.text.split(\"REPLY\")[0].strip().split(\"\\n\")[-1]\n",
    "        comments.append(content[2])\n",
    "        time_ago.append(content[1])\n",
    "\n",
    "        if len(upvote)<=4:\n",
    "            upvotes.append(upvote)\n",
    "        else:\n",
    "            upvotes.append(0)\n",
    "    \n",
    "    # the final dataframe.\n",
    "    yt_comments= pd.DataFrame({\"Comment\":comments,\n",
    "                                \"Posted\":time_ago,\n",
    "                                \"Upvotes\":upvotes                        \n",
    "                               })\n",
    "    # returning the dataframe.\n",
    "    return yt_comments\n",
    "\n",
    "# the youtube url from which we want to scrap the comments data.\n",
    "url= \"https://www.youtube.com/watch?v=9bZkp7q19f0\"\n",
    "\n",
    "# calling the \"youtube_comments\" function with the url as arguement.\n",
    "df= youtube_comments(url)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e60c5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Page1...\n",
      "Processing Page2...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Distance from City-Center</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Dorms from Price(â‚¹)</th>\n",
       "      <th>Privates from Price(â‚¹)</th>\n",
       "      <th>Overall Review</th>\n",
       "      <th>Total Reviews</th>\n",
       "      <th>Facilities</th>\n",
       "      <th>Property Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>St Christopher's Village</td>\n",
       "      <td>1.8km</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1724</td>\n",
       "      <td>No Privates Available</td>\n",
       "      <td>Fabulous</td>\n",
       "      <td>11400 Total Reviews</td>\n",
       "      <td>linenincluded  freecitymaps  free wifi  freein...</td>\n",
       "      <td>COVID 19 Policy Update.\\nIn response to Coro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Selina Camden</td>\n",
       "      <td>5.5km</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8500</td>\n",
       "      <td>27466</td>\n",
       "      <td>Fabulous</td>\n",
       "      <td>34 Total Reviews</td>\n",
       "      <td>linenincluded  towelsincluded  free wifi   loc...</td>\n",
       "      <td>Among underground music venues, innovative m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wombat's City Hostel London</td>\n",
       "      <td>3.6km</td>\n",
       "      <td>9.1</td>\n",
       "      <td>2857</td>\n",
       "      <td>18617</td>\n",
       "      <td>Superb</td>\n",
       "      <td>13875 Total Reviews</td>\n",
       "      <td>linenincluded  freecitymaps  free wifi  freein...</td>\n",
       "      <td>A safe haven in the middle of the metropolis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Generator London</td>\n",
       "      <td>3km</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2394</td>\n",
       "      <td>8808</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>7067 Total Reviews</td>\n",
       "      <td>linenincluded  freecitymaps  free wifi  freein...</td>\n",
       "      <td>Generator London is a design hotel-hostel lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Urbany Hostel London</td>\n",
       "      <td>5.4km</td>\n",
       "      <td>9.3</td>\n",
       "      <td>3830</td>\n",
       "      <td>14365</td>\n",
       "      <td>Superb</td>\n",
       "      <td>419 Total Reviews</td>\n",
       "      <td>linenincluded  free wifi   lockers  microwave ...</td>\n",
       "      <td>Welcome to Urbany Hostel London, our first i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Safestay London Elephant &amp; Castle</td>\n",
       "      <td>1.7km</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1596</td>\n",
       "      <td>15959</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>4412 Total Reviews</td>\n",
       "      <td>linenincluded  freecitymaps  free wifi   locke...</td>\n",
       "      <td>Safestay at Elephant &amp; Castle is ideal if yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>No.8 Willesden Hostel London</td>\n",
       "      <td>10km</td>\n",
       "      <td>6.8</td>\n",
       "      <td>995</td>\n",
       "      <td>No Privates Available</td>\n",
       "      <td>Good</td>\n",
       "      <td>4805 Total Reviews</td>\n",
       "      <td>linenincluded  free wifi   lockers  keycardacc...</td>\n",
       "      <td>At No.8 we take pride in our Customer Servic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>No.8 Seven Sisters</td>\n",
       "      <td>9km</td>\n",
       "      <td>6.2</td>\n",
       "      <td>946</td>\n",
       "      <td>No Privates Available</td>\n",
       "      <td>Good</td>\n",
       "      <td>3824 Total Reviews</td>\n",
       "      <td>linenincluded  free wifi   lockers  keycardacc...</td>\n",
       "      <td>For Great Facilities, Comfort &amp; Affordabilit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>London Backpackers</td>\n",
       "      <td>11.9km</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1596</td>\n",
       "      <td>No Privates Available</td>\n",
       "      <td>Fabulous</td>\n",
       "      <td>4294 Total Reviews</td>\n",
       "      <td>linenincluded  freecitymaps  free wifi  freein...</td>\n",
       "      <td>show more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Barmy Badger Backpackers</td>\n",
       "      <td>5.5km</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2869</td>\n",
       "      <td>8414</td>\n",
       "      <td>Superb</td>\n",
       "      <td>1793 Total Reviews</td>\n",
       "      <td>breakfastincluded  linenincluded  freecitymaps...</td>\n",
       "      <td>The Badger is unique for London in that we h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Safestay London Kensington Holland Park</td>\n",
       "      <td>5.9km</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1480</td>\n",
       "      <td>No Privates Available</td>\n",
       "      <td>Good</td>\n",
       "      <td>1273 Total Reviews</td>\n",
       "      <td>linenincluded  free wifi   lockers  keycardacc...</td>\n",
       "      <td>Safestay Holland Park\\n\\nSafestay Holland Pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>St Christopher's Inn - London Bridge</td>\n",
       "      <td>1.8km</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2889</td>\n",
       "      <td>No Privates Available</td>\n",
       "      <td>Fabulous</td>\n",
       "      <td>3336 Total Reviews</td>\n",
       "      <td>linenincluded  freecitymaps  free wifi  freein...</td>\n",
       "      <td>COVID 19 Policy Update.\\nIn response to Coro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Phoenix Hostel</td>\n",
       "      <td>4.2km</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1915</td>\n",
       "      <td>No Privates Available</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>3684 Total Reviews</td>\n",
       "      <td>linenincluded  freecitymaps  free wifi  freein...</td>\n",
       "      <td>*Please note we are operating on LIMITED rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Smart Hyde Park View Hostel</td>\n",
       "      <td>5km</td>\n",
       "      <td>8.1</td>\n",
       "      <td>3714</td>\n",
       "      <td>No Privates Available</td>\n",
       "      <td>Fabulous</td>\n",
       "      <td>4578 Total Reviews</td>\n",
       "      <td>linenincluded  freecitymaps  free wifi   locke...</td>\n",
       "      <td>Our Hyde Park View Hostel is in a superb loc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NX London Hostel</td>\n",
       "      <td>6.1km</td>\n",
       "      <td>7.3</td>\n",
       "      <td>No Dorms Available</td>\n",
       "      <td>6871</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>1181 Total Reviews</td>\n",
       "      <td>breakfastincluded  linenincluded  freeparking ...</td>\n",
       "      <td>Welcome to NX London Hostel!\\n\\nA Friendly b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Hostel One Notting Hill</td>\n",
       "      <td>5.5km</td>\n",
       "      <td>9.2</td>\n",
       "      <td>3230</td>\n",
       "      <td>15888</td>\n",
       "      <td>Superb</td>\n",
       "      <td>1437 Total Reviews</td>\n",
       "      <td>linenincluded  free wifi  freeinternetaccess  ...</td>\n",
       "      <td>The perfect place for solo travelers to conn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>St Christopher's Hammersmith</td>\n",
       "      <td>7.5km</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1923</td>\n",
       "      <td>No Privates Available</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>4076 Total Reviews</td>\n",
       "      <td>linenincluded  freecitymaps  free wifi  freein...</td>\n",
       "      <td>In response to Coronavirus (COVID-19), addit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>St Christopher's Camden</td>\n",
       "      <td>4.3km</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2341</td>\n",
       "      <td>No Privates Available</td>\n",
       "      <td>Fabulous</td>\n",
       "      <td>3813 Total Reviews</td>\n",
       "      <td>linenincluded  freecitymaps  free wifi  freein...</td>\n",
       "      <td>COVID 19 Policy Update.\\nIn response to Coro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>St Christopher's Inn - Liverpool Street</td>\n",
       "      <td>3.2km</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3340</td>\n",
       "      <td>No Privates Available</td>\n",
       "      <td>Fabulous</td>\n",
       "      <td>422 Total Reviews</td>\n",
       "      <td>linenincluded  freecitymaps  free wifi   locke...</td>\n",
       "      <td>COVID 19 Policy Update.\\nIn response to Coro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>St Christopher's Oasis-Female Only</td>\n",
       "      <td>1.8km</td>\n",
       "      <td>8.3</td>\n",
       "      <td>No Dorms Available</td>\n",
       "      <td>9468</td>\n",
       "      <td>Fabulous</td>\n",
       "      <td>670 Total Reviews</td>\n",
       "      <td>linenincluded  freecitymaps  towelsincluded  f...</td>\n",
       "      <td>COVID 19 Policy Update.\\nIn response to Coro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>London Waterloo Hostel</td>\n",
       "      <td>0.7km</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2350</td>\n",
       "      <td>No Privates Available</td>\n",
       "      <td>Good</td>\n",
       "      <td>2508 Total Reviews</td>\n",
       "      <td>linenincluded  freecitymaps  free wifi  freein...</td>\n",
       "      <td>Note: 18-40 yrs old only.. All guest receive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Palmers Lodge - Swiss Cottage</td>\n",
       "      <td>6.5km</td>\n",
       "      <td>8.8</td>\n",
       "      <td>2153</td>\n",
       "      <td>No Privates Available</td>\n",
       "      <td>Fabulous</td>\n",
       "      <td>15494 Total Reviews</td>\n",
       "      <td>linenincluded  freecitymaps  free wifi  freein...</td>\n",
       "      <td>Whether you're a backpacker, flash-packer or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PubLove @ The White Ferry, Victoria</td>\n",
       "      <td>2.4km</td>\n",
       "      <td>8.1</td>\n",
       "      <td>3482</td>\n",
       "      <td>No Privates Available</td>\n",
       "      <td>Fabulous</td>\n",
       "      <td>274 Total Reviews</td>\n",
       "      <td>linenincluded  freecitymaps  free wifi   locke...</td>\n",
       "      <td>Walk to the river, turn left, and just keep ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Clink261</td>\n",
       "      <td>3.2km</td>\n",
       "      <td>7.8</td>\n",
       "      <td>2072</td>\n",
       "      <td>No Privates Available</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>114 Total Reviews</td>\n",
       "      <td>linenincluded  freecitymaps  free wifi   keyca...</td>\n",
       "      <td>Welcome to Clink261!\\n\\nClink261 is a comfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>St Christopher's Greenwich</td>\n",
       "      <td>7.6km</td>\n",
       "      <td>6.8</td>\n",
       "      <td>1569</td>\n",
       "      <td>No Privates Available</td>\n",
       "      <td>Good</td>\n",
       "      <td>3223 Total Reviews</td>\n",
       "      <td>linenincluded  freecitymaps  free wifi  freein...</td>\n",
       "      <td>COVID 19 Policy Update.\\nIn response to Coro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PubLove @ The Steam Engine, Waterloo</td>\n",
       "      <td>0.5km</td>\n",
       "      <td>8.4</td>\n",
       "      <td>5029</td>\n",
       "      <td>No Privates Available</td>\n",
       "      <td>Fabulous</td>\n",
       "      <td>296 Total Reviews</td>\n",
       "      <td>linenincluded  freecitymaps  free wifi   locke...</td>\n",
       "      <td>The heart &amp; soul of London backpacking\\nPull...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>St Christopher's Shepherds Bush</td>\n",
       "      <td>7km</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2470</td>\n",
       "      <td>No Privates Available</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>702 Total Reviews</td>\n",
       "      <td>linenincluded  freecitymaps  free wifi   locke...</td>\n",
       "      <td>COVID 19 Policy Update.\\nIn response to Coro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>PubLove @ The Rose &amp; Crown</td>\n",
       "      <td>1.6km</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4545</td>\n",
       "      <td>No Privates Available</td>\n",
       "      <td>Fabulous</td>\n",
       "      <td>141 Total Reviews</td>\n",
       "      <td>linenincluded  freecitymaps  free wifi   locke...</td>\n",
       "      <td>Food &amp; culture lovers, assemble!\\nThe Rose &amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>PubLove @ The Exmouth Arms, Euston</td>\n",
       "      <td>3.4km</td>\n",
       "      <td>7.1</td>\n",
       "      <td>3224</td>\n",
       "      <td>No Privates Available</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>1037 Total Reviews</td>\n",
       "      <td>linenincluded  freecitymaps  free wifi   locke...</td>\n",
       "      <td>Do Camden by day and curb side beers by nigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>PubLove @ The Crown, Battersea</td>\n",
       "      <td>4.7km</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2643</td>\n",
       "      <td>25532</td>\n",
       "      <td>Good</td>\n",
       "      <td>255 Total Reviews</td>\n",
       "      <td>linenincluded  freecitymaps  free wifi   locke...</td>\n",
       "      <td>Do London like a local.\\nStay just outside t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Park Villa</td>\n",
       "      <td>6.3km</td>\n",
       "      <td>7.9</td>\n",
       "      <td>4645</td>\n",
       "      <td>No Privates Available</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>873 Total Reviews</td>\n",
       "      <td>linenincluded  free wifi  freeinternetaccess  ...</td>\n",
       "      <td>Park Villa is a new boutique hostel in the h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Saint James Backpackers</td>\n",
       "      <td>5.5km</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2297</td>\n",
       "      <td>No Privates Available</td>\n",
       "      <td>Good</td>\n",
       "      <td>1815 Total Reviews</td>\n",
       "      <td>breakfastincluded  linenincluded  freecitymaps...</td>\n",
       "      <td>We are located in central London - just 5 mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Kensal Green Backpackers</td>\n",
       "      <td>8.2km</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1612</td>\n",
       "      <td>No Privates Available</td>\n",
       "      <td>-</td>\n",
       "      <td>3640 Total Reviews</td>\n",
       "      <td>linenincluded  freecitymaps   commonroom  brea...</td>\n",
       "      <td>Kensal Green Backpackers is a legendary host...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>PubLove @ The Green Man, Paddington</td>\n",
       "      <td>4.3km</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2805</td>\n",
       "      <td>No Privates Available</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>418 Total Reviews</td>\n",
       "      <td>linenincluded  freecitymaps  free wifi   locke...</td>\n",
       "      <td>Where it all began - PubLove was born here i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Book a Bed Hostels</td>\n",
       "      <td>6.9km</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2087</td>\n",
       "      <td>7050</td>\n",
       "      <td>Good</td>\n",
       "      <td>1201 Total Reviews</td>\n",
       "      <td>linenincluded  freecitymaps  free wifi  freein...</td>\n",
       "      <td>Welcome to Venture Hostel.Venture Hostel is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Britannia Inn Hotel</td>\n",
       "      <td>14.5km</td>\n",
       "      <td>8.2</td>\n",
       "      <td>No Dorms Available</td>\n",
       "      <td>10799</td>\n",
       "      <td>Fabulous</td>\n",
       "      <td>22 Total Reviews</td>\n",
       "      <td>breakfastincluded  freeparking  freeinternetac...</td>\n",
       "      <td>The Britannia Inn Hotel is situated near the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>The Backpackshack</td>\n",
       "      <td>10.9km</td>\n",
       "      <td>8.7</td>\n",
       "      <td>No Dorms Available</td>\n",
       "      <td>4836</td>\n",
       "      <td>Fabulous</td>\n",
       "      <td>734 Total Reviews</td>\n",
       "      <td>linenincluded  freeparking  towelsincluded  fr...</td>\n",
       "      <td>Our hostel is located inside a traditional E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>London House Hotel</td>\n",
       "      <td>5.3km</td>\n",
       "      <td>8.8</td>\n",
       "      <td>No Dorms Available</td>\n",
       "      <td>18441</td>\n",
       "      <td>Fabulous</td>\n",
       "      <td>1382 Total Reviews</td>\n",
       "      <td>freecitymaps  free wifi   keycardaccess  eleva...</td>\n",
       "      <td>Our lovely boutique hotel is conveniently lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Elmwood Hotel</td>\n",
       "      <td>3.2km</td>\n",
       "      <td>6.1</td>\n",
       "      <td>No Dorms Available</td>\n",
       "      <td>11928</td>\n",
       "      <td>Good</td>\n",
       "      <td>116 Total Reviews</td>\n",
       "      <td>freeinternetaccess   hairdryers  safedepositbo...</td>\n",
       "      <td>This central London hotel just 2-minutes fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Kip Hotel</td>\n",
       "      <td>6.8km</td>\n",
       "      <td>6.6</td>\n",
       "      <td>No Dorms Available</td>\n",
       "      <td>8865</td>\n",
       "      <td>Good</td>\n",
       "      <td>54 Total Reviews</td>\n",
       "      <td>towelsincluded  free wifi   keycardaccess  bre...</td>\n",
       "      <td>Kip is on a mission to bring the world style...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>The London Home Hostel</td>\n",
       "      <td>8.2km</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2418</td>\n",
       "      <td>6093</td>\n",
       "      <td>-</td>\n",
       "      <td>258 Total Reviews</td>\n",
       "      <td>linenincluded  free wifi  freeinternetaccess  ...</td>\n",
       "      <td>If you are looking to meet and socialise wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>The W14 Hotel &amp; Bar</td>\n",
       "      <td>6.5km</td>\n",
       "      <td>8.6</td>\n",
       "      <td>No Dorms Available</td>\n",
       "      <td>16248</td>\n",
       "      <td>Fabulous</td>\n",
       "      <td>280 Total Reviews</td>\n",
       "      <td>breakfastincluded  linenincluded  freecitymaps...</td>\n",
       "      <td>The W14 Hotel London is a 3 star Superior  B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Cranbrook Hotel</td>\n",
       "      <td>14.8km</td>\n",
       "      <td>-</td>\n",
       "      <td>No Dorms Available</td>\n",
       "      <td>8349</td>\n",
       "      <td>-</td>\n",
       "      <td>0 Total Reviews</td>\n",
       "      <td>breakfastincluded  freeparking   hotshowers  p...</td>\n",
       "      <td>We are located about twenty minutes by tube ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Colliers Hotel</td>\n",
       "      <td>2.1km</td>\n",
       "      <td>6.6</td>\n",
       "      <td>No Dorms Available</td>\n",
       "      <td>9671</td>\n",
       "      <td>Good</td>\n",
       "      <td>8 Total Reviews</td>\n",
       "      <td>keycardaccess  adaptors  hairdryers  ironironi...</td>\n",
       "      <td>Colliers Hotel offers basic budget accommoda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>City Hotel Carlton</td>\n",
       "      <td>1.8km</td>\n",
       "      <td>6.7</td>\n",
       "      <td>No Dorms Available</td>\n",
       "      <td>8897</td>\n",
       "      <td>Good</td>\n",
       "      <td>40 Total Reviews</td>\n",
       "      <td>freeinternetaccess   swimmingpool  parking  sa...</td>\n",
       "      <td>Carlton hotel is conveniently situated withi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Hotel Shepherds Bush London</td>\n",
       "      <td>7.6km</td>\n",
       "      <td>-</td>\n",
       "      <td>No Dorms Available</td>\n",
       "      <td>16231</td>\n",
       "      <td>-</td>\n",
       "      <td>0 Total Reviews</td>\n",
       "      <td>linenincluded  freecitymaps  towelsincluded  f...</td>\n",
       "      <td>Hotel Shepherds Bush London provide 4 star h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Tony's House Hotel</td>\n",
       "      <td>4.3km</td>\n",
       "      <td>-</td>\n",
       "      <td>No Dorms Available</td>\n",
       "      <td>5319</td>\n",
       "      <td>-</td>\n",
       "      <td>0 Total Reviews</td>\n",
       "      <td>breakfastincluded  freeinternetaccess   hairdr...</td>\n",
       "      <td>Central London Hotel Accommodation situated ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Aron Guest House</td>\n",
       "      <td>13.1km</td>\n",
       "      <td>-</td>\n",
       "      <td>No Dorms Available</td>\n",
       "      <td>10155</td>\n",
       "      <td>-</td>\n",
       "      <td>0 Total Reviews</td>\n",
       "      <td>freeparking  towelsincluded  free wifi   parki...</td>\n",
       "      <td>Aron Guest House provides an excellent base,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Beaconsfield</td>\n",
       "      <td>8.6km</td>\n",
       "      <td>-</td>\n",
       "      <td>No Dorms Available</td>\n",
       "      <td>8607</td>\n",
       "      <td>-</td>\n",
       "      <td>0 Total Reviews</td>\n",
       "      <td>free wifi   bar  teacoffeemakingfacilities</td>\n",
       "      <td>Beaconsfield  is a basic, budget hotel, situ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Park Hotel Essex</td>\n",
       "      <td>24.1km</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No Dorms Available</td>\n",
       "      <td>24661</td>\n",
       "      <td>Fabulous</td>\n",
       "      <td>109 Total Reviews</td>\n",
       "      <td>breakfastincluded  freeparking   parking  sani...</td>\n",
       "      <td>This Hotel is the right choice for visitors ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wellesley Hotel</td>\n",
       "      <td>14.7km</td>\n",
       "      <td>-</td>\n",
       "      <td>No Dorms Available</td>\n",
       "      <td>9865</td>\n",
       "      <td>-</td>\n",
       "      <td>0 Total Reviews</td>\n",
       "      <td>linenincluded  towelsincluded  free wifi  free...</td>\n",
       "      <td>In the Heart of Ilford, Greater London regio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Destinations Hostels @ The Gallery</td>\n",
       "      <td>1.7km</td>\n",
       "      <td>-</td>\n",
       "      <td>4352</td>\n",
       "      <td>No Privates Available</td>\n",
       "      <td>-</td>\n",
       "      <td>0 Total Reviews</td>\n",
       "      <td>breakfastincluded  linenincluded  freecitymaps...</td>\n",
       "      <td>We are back, we previously operated near Lon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>YHA London St Pauls</td>\n",
       "      <td>1.9km</td>\n",
       "      <td>-</td>\n",
       "      <td>No Dorms Available</td>\n",
       "      <td>4836</td>\n",
       "      <td>-</td>\n",
       "      <td>0 Total Reviews</td>\n",
       "      <td>linenincluded  freecitymaps  free wifi   locke...</td>\n",
       "      <td>YHA London St Paul's is temporarily unavaila...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Park Hotel</td>\n",
       "      <td>4.9km</td>\n",
       "      <td>-</td>\n",
       "      <td>No Dorms Available</td>\n",
       "      <td>13540</td>\n",
       "      <td>-</td>\n",
       "      <td>0 Total Reviews</td>\n",
       "      <td>linenincluded  towelsincluded  free wifi   bre...</td>\n",
       "      <td>A friendly, family run hotel offering comfor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Name Distance from City-Center Rating  \\\n",
       "0                  St Christopher's Village                     1.8km   8.1    \n",
       "1                             Selina Camden                     5.5km   8.5    \n",
       "2               Wombat's City Hostel London                     3.6km   9.1    \n",
       "3                          Generator London                       3km   7.7    \n",
       "4                      Urbany Hostel London                     5.4km   9.3    \n",
       "5         Safestay London Elephant & Castle                     1.7km   7.0    \n",
       "6              No.8 Willesden Hostel London                      10km   6.8    \n",
       "7                        No.8 Seven Sisters                       9km   6.2    \n",
       "8                        London Backpackers                    11.9km   8.1    \n",
       "9                  Barmy Badger Backpackers                     5.5km   9.0    \n",
       "10  Safestay London Kensington Holland Park                     5.9km   6.5    \n",
       "11     St Christopher's Inn - London Bridge                     1.8km   8.3    \n",
       "12                           Phoenix Hostel                     4.2km   7.5    \n",
       "13              Smart Hyde Park View Hostel                       5km   8.1    \n",
       "14                         NX London Hostel                     6.1km   7.3    \n",
       "15                  Hostel One Notting Hill                     5.5km   9.2    \n",
       "16             St Christopher's Hammersmith                     7.5km   7.9    \n",
       "17                  St Christopher's Camden                     4.3km   8.4    \n",
       "18  St Christopher's Inn - Liverpool Street                     3.2km   8.8    \n",
       "19       St Christopher's Oasis-Female Only                     1.8km   8.3    \n",
       "20                   London Waterloo Hostel                     0.7km   6.3    \n",
       "21            Palmers Lodge - Swiss Cottage                     6.5km   8.8    \n",
       "22      PubLove @ The White Ferry, Victoria                     2.4km   8.1    \n",
       "23                                 Clink261                     3.2km   7.8    \n",
       "24               St Christopher's Greenwich                     7.6km   6.8    \n",
       "25     PubLove @ The Steam Engine, Waterloo                     0.5km   8.4    \n",
       "26          St Christopher's Shepherds Bush                       7km   7.4    \n",
       "27               PubLove @ The Rose & Crown                     1.6km   8.0    \n",
       "28       PubLove @ The Exmouth Arms, Euston                     3.4km   7.1    \n",
       "29           PubLove @ The Crown, Battersea                     4.7km   6.5    \n",
       "30                               Park Villa                     6.3km   7.9    \n",
       "31                  Saint James Backpackers                     5.5km   6.6    \n",
       "32                 Kensal Green Backpackers                     8.2km   4.4    \n",
       "33      PubLove @ The Green Man, Paddington                     4.3km   7.7    \n",
       "34                       Book a Bed Hostels                     6.9km   6.8    \n",
       "35                      Britannia Inn Hotel                    14.5km   8.2    \n",
       "36                        The Backpackshack                    10.9km   8.7    \n",
       "37                       London House Hotel                     5.3km   8.8    \n",
       "38                            Elmwood Hotel                     3.2km   6.1    \n",
       "39                                Kip Hotel                     6.8km   6.6    \n",
       "40                   The London Home Hostel                     8.2km   3.8    \n",
       "41                      The W14 Hotel & Bar                     6.5km   8.6    \n",
       "42                          Cranbrook Hotel                    14.8km      -   \n",
       "43                           Colliers Hotel                     2.1km   6.6    \n",
       "44                       City Hotel Carlton                     1.8km   6.7    \n",
       "45              Hotel Shepherds Bush London                     7.6km      -   \n",
       "46                       Tony's House Hotel                     4.3km      -   \n",
       "47                         Aron Guest House                    13.1km      -   \n",
       "48                             Beaconsfield                     8.6km      -   \n",
       "49                         Park Hotel Essex                    24.1km   8.0    \n",
       "50                          Wellesley Hotel                    14.7km      -   \n",
       "51       Destinations Hostels @ The Gallery                     1.7km      -   \n",
       "52                      YHA London St Pauls                     1.9km      -   \n",
       "53                               Park Hotel                     4.9km      -   \n",
       "\n",
       "   Dorms from Price(â‚¹) Privates from Price(â‚¹) Overall Review  \\\n",
       "0                 1724  No Privates Available       Fabulous   \n",
       "1                 8500                  27466       Fabulous   \n",
       "2                 2857                  18617         Superb   \n",
       "3                 2394                   8808      Very Good   \n",
       "4                 3830                  14365         Superb   \n",
       "5                 1596                  15959      Very Good   \n",
       "6                  995  No Privates Available           Good   \n",
       "7                  946  No Privates Available           Good   \n",
       "8                 1596  No Privates Available       Fabulous   \n",
       "9                 2869                   8414         Superb   \n",
       "10                1480  No Privates Available           Good   \n",
       "11                2889  No Privates Available       Fabulous   \n",
       "12                1915  No Privates Available      Very Good   \n",
       "13                3714  No Privates Available       Fabulous   \n",
       "14  No Dorms Available                   6871      Very Good   \n",
       "15                3230                  15888         Superb   \n",
       "16                1923  No Privates Available      Very Good   \n",
       "17                2341  No Privates Available       Fabulous   \n",
       "18                3340  No Privates Available       Fabulous   \n",
       "19  No Dorms Available                   9468       Fabulous   \n",
       "20                2350  No Privates Available           Good   \n",
       "21                2153  No Privates Available       Fabulous   \n",
       "22                3482  No Privates Available       Fabulous   \n",
       "23                2072  No Privates Available      Very Good   \n",
       "24                1569  No Privates Available           Good   \n",
       "25                5029  No Privates Available       Fabulous   \n",
       "26                2470  No Privates Available      Very Good   \n",
       "27                4545  No Privates Available       Fabulous   \n",
       "28                3224  No Privates Available      Very Good   \n",
       "29                2643                  25532           Good   \n",
       "30                4645  No Privates Available      Very Good   \n",
       "31                2297  No Privates Available           Good   \n",
       "32                1612  No Privates Available              -   \n",
       "33                2805  No Privates Available      Very Good   \n",
       "34                2087                   7050           Good   \n",
       "35  No Dorms Available                  10799       Fabulous   \n",
       "36  No Dorms Available                   4836       Fabulous   \n",
       "37  No Dorms Available                  18441       Fabulous   \n",
       "38  No Dorms Available                  11928           Good   \n",
       "39  No Dorms Available                   8865           Good   \n",
       "40                2418                   6093              -   \n",
       "41  No Dorms Available                  16248       Fabulous   \n",
       "42  No Dorms Available                   8349              -   \n",
       "43  No Dorms Available                   9671           Good   \n",
       "44  No Dorms Available                   8897           Good   \n",
       "45  No Dorms Available                  16231              -   \n",
       "46  No Dorms Available                   5319              -   \n",
       "47  No Dorms Available                  10155              -   \n",
       "48  No Dorms Available                   8607              -   \n",
       "49  No Dorms Available                  24661       Fabulous   \n",
       "50  No Dorms Available                   9865              -   \n",
       "51                4352  No Privates Available              -   \n",
       "52  No Dorms Available                   4836              -   \n",
       "53  No Dorms Available                  13540              -   \n",
       "\n",
       "          Total Reviews                                         Facilities  \\\n",
       "0   11400 Total Reviews  linenincluded  freecitymaps  free wifi  freein...   \n",
       "1      34 Total Reviews  linenincluded  towelsincluded  free wifi   loc...   \n",
       "2   13875 Total Reviews  linenincluded  freecitymaps  free wifi  freein...   \n",
       "3    7067 Total Reviews  linenincluded  freecitymaps  free wifi  freein...   \n",
       "4     419 Total Reviews  linenincluded  free wifi   lockers  microwave ...   \n",
       "5    4412 Total Reviews  linenincluded  freecitymaps  free wifi   locke...   \n",
       "6    4805 Total Reviews  linenincluded  free wifi   lockers  keycardacc...   \n",
       "7    3824 Total Reviews  linenincluded  free wifi   lockers  keycardacc...   \n",
       "8    4294 Total Reviews  linenincluded  freecitymaps  free wifi  freein...   \n",
       "9    1793 Total Reviews  breakfastincluded  linenincluded  freecitymaps...   \n",
       "10   1273 Total Reviews  linenincluded  free wifi   lockers  keycardacc...   \n",
       "11   3336 Total Reviews  linenincluded  freecitymaps  free wifi  freein...   \n",
       "12   3684 Total Reviews  linenincluded  freecitymaps  free wifi  freein...   \n",
       "13   4578 Total Reviews  linenincluded  freecitymaps  free wifi   locke...   \n",
       "14   1181 Total Reviews  breakfastincluded  linenincluded  freeparking ...   \n",
       "15   1437 Total Reviews  linenincluded  free wifi  freeinternetaccess  ...   \n",
       "16   4076 Total Reviews  linenincluded  freecitymaps  free wifi  freein...   \n",
       "17   3813 Total Reviews  linenincluded  freecitymaps  free wifi  freein...   \n",
       "18    422 Total Reviews  linenincluded  freecitymaps  free wifi   locke...   \n",
       "19    670 Total Reviews  linenincluded  freecitymaps  towelsincluded  f...   \n",
       "20   2508 Total Reviews  linenincluded  freecitymaps  free wifi  freein...   \n",
       "21  15494 Total Reviews  linenincluded  freecitymaps  free wifi  freein...   \n",
       "22    274 Total Reviews  linenincluded  freecitymaps  free wifi   locke...   \n",
       "23    114 Total Reviews  linenincluded  freecitymaps  free wifi   keyca...   \n",
       "24   3223 Total Reviews  linenincluded  freecitymaps  free wifi  freein...   \n",
       "25    296 Total Reviews  linenincluded  freecitymaps  free wifi   locke...   \n",
       "26    702 Total Reviews  linenincluded  freecitymaps  free wifi   locke...   \n",
       "27    141 Total Reviews  linenincluded  freecitymaps  free wifi   locke...   \n",
       "28   1037 Total Reviews  linenincluded  freecitymaps  free wifi   locke...   \n",
       "29    255 Total Reviews  linenincluded  freecitymaps  free wifi   locke...   \n",
       "30    873 Total Reviews  linenincluded  free wifi  freeinternetaccess  ...   \n",
       "31   1815 Total Reviews  breakfastincluded  linenincluded  freecitymaps...   \n",
       "32   3640 Total Reviews  linenincluded  freecitymaps   commonroom  brea...   \n",
       "33    418 Total Reviews  linenincluded  freecitymaps  free wifi   locke...   \n",
       "34   1201 Total Reviews  linenincluded  freecitymaps  free wifi  freein...   \n",
       "35     22 Total Reviews  breakfastincluded  freeparking  freeinternetac...   \n",
       "36    734 Total Reviews  linenincluded  freeparking  towelsincluded  fr...   \n",
       "37   1382 Total Reviews  freecitymaps  free wifi   keycardaccess  eleva...   \n",
       "38    116 Total Reviews  freeinternetaccess   hairdryers  safedepositbo...   \n",
       "39     54 Total Reviews  towelsincluded  free wifi   keycardaccess  bre...   \n",
       "40    258 Total Reviews  linenincluded  free wifi  freeinternetaccess  ...   \n",
       "41    280 Total Reviews  breakfastincluded  linenincluded  freecitymaps...   \n",
       "42      0 Total Reviews  breakfastincluded  freeparking   hotshowers  p...   \n",
       "43      8 Total Reviews  keycardaccess  adaptors  hairdryers  ironironi...   \n",
       "44     40 Total Reviews  freeinternetaccess   swimmingpool  parking  sa...   \n",
       "45      0 Total Reviews  linenincluded  freecitymaps  towelsincluded  f...   \n",
       "46      0 Total Reviews  breakfastincluded  freeinternetaccess   hairdr...   \n",
       "47      0 Total Reviews  freeparking  towelsincluded  free wifi   parki...   \n",
       "48      0 Total Reviews         free wifi   bar  teacoffeemakingfacilities   \n",
       "49    109 Total Reviews  breakfastincluded  freeparking   parking  sani...   \n",
       "50      0 Total Reviews  linenincluded  towelsincluded  free wifi  free...   \n",
       "51      0 Total Reviews  breakfastincluded  linenincluded  freecitymaps...   \n",
       "52      0 Total Reviews  linenincluded  freecitymaps  free wifi   locke...   \n",
       "53      0 Total Reviews  linenincluded  towelsincluded  free wifi   bre...   \n",
       "\n",
       "                                 Property Description  \n",
       "0     COVID 19 Policy Update.\\nIn response to Coro...  \n",
       "1     Among underground music venues, innovative m...  \n",
       "2     A safe haven in the middle of the metropolis...  \n",
       "3     Generator London is a design hotel-hostel lo...  \n",
       "4     Welcome to Urbany Hostel London, our first i...  \n",
       "5     Safestay at Elephant & Castle is ideal if yo...  \n",
       "6     At No.8 we take pride in our Customer Servic...  \n",
       "7     For Great Facilities, Comfort & Affordabilit...  \n",
       "8                                           show more  \n",
       "9     The Badger is unique for London in that we h...  \n",
       "10    Safestay Holland Park\\n\\nSafestay Holland Pa...  \n",
       "11    COVID 19 Policy Update.\\nIn response to Coro...  \n",
       "12    *Please note we are operating on LIMITED rec...  \n",
       "13    Our Hyde Park View Hostel is in a superb loc...  \n",
       "14    Welcome to NX London Hostel!\\n\\nA Friendly b...  \n",
       "15    The perfect place for solo travelers to conn...  \n",
       "16    In response to Coronavirus (COVID-19), addit...  \n",
       "17    COVID 19 Policy Update.\\nIn response to Coro...  \n",
       "18    COVID 19 Policy Update.\\nIn response to Coro...  \n",
       "19    COVID 19 Policy Update.\\nIn response to Coro...  \n",
       "20    Note: 18-40 yrs old only.. All guest receive...  \n",
       "21    Whether you're a backpacker, flash-packer or...  \n",
       "22    Walk to the river, turn left, and just keep ...  \n",
       "23    Welcome to Clink261!\\n\\nClink261 is a comfor...  \n",
       "24    COVID 19 Policy Update.\\nIn response to Coro...  \n",
       "25    The heart & soul of London backpacking\\nPull...  \n",
       "26    COVID 19 Policy Update.\\nIn response to Coro...  \n",
       "27    Food & culture lovers, assemble!\\nThe Rose &...  \n",
       "28    Do Camden by day and curb side beers by nigh...  \n",
       "29    Do London like a local.\\nStay just outside t...  \n",
       "30    Park Villa is a new boutique hostel in the h...  \n",
       "31    We are located in central London - just 5 mi...  \n",
       "32    Kensal Green Backpackers is a legendary host...  \n",
       "33    Where it all began - PubLove was born here i...  \n",
       "34    Welcome to Venture Hostel.Venture Hostel is ...  \n",
       "35    The Britannia Inn Hotel is situated near the...  \n",
       "36    Our hostel is located inside a traditional E...  \n",
       "37    Our lovely boutique hotel is conveniently lo...  \n",
       "38    This central London hotel just 2-minutes fro...  \n",
       "39    Kip is on a mission to bring the world style...  \n",
       "40    If you are looking to meet and socialise wit...  \n",
       "41    The W14 Hotel London is a 3 star Superior  B...  \n",
       "42    We are located about twenty minutes by tube ...  \n",
       "43    Colliers Hotel offers basic budget accommoda...  \n",
       "44    Carlton hotel is conveniently situated withi...  \n",
       "45    Hotel Shepherds Bush London provide 4 star h...  \n",
       "46    Central London Hotel Accommodation situated ...  \n",
       "47    Aron Guest House provides an excellent base,...  \n",
       "48    Beaconsfield  is a basic, budget hotel, situ...  \n",
       "49    This Hotel is the right choice for visitors ...  \n",
       "50    In the Heart of Ilford, Greater London regio...  \n",
       "51    We are back, we previously operated near Lon...  \n",
       "52    YHA London St Paul's is temporarily unavaila...  \n",
       "53    A friendly, family run hotel offering comfor...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q10 Solution:\n",
    "\n",
    "# defining a 'User-Agent' and 'Accept-Language' so that our requests don't get blocked.\n",
    "HEADERS = ({'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.5060.134 Safari/537.36',\n",
    "            'Accept-Language': 'en-US, en;q=0.5'})\n",
    "# defining the lists to be used.\n",
    "names=[]\n",
    "dist_cc=[]\n",
    "ratings=[]\n",
    "total_reviews=[]\n",
    "overall_reviews=[]\n",
    "pvt_prices=[]\n",
    "dorm_prices=[]\n",
    "facilities=[]\n",
    "prop_des=[]\n",
    "\n",
    "# defining a function to get the data from a hostel-listings page.\n",
    "def get_data():\n",
    "    \n",
    "    # putting the program on hold for 2 seconds so that the search results gets loaded properly.\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # finding the webelements for the hostels shown.\n",
    "    try:\n",
    "        wait= WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,\"//div[@class='title-row']\")))\n",
    "        data= driver.find_elements(By.XPATH,\"//div[@class='title-row']\")\n",
    "    except TimeoutException:\n",
    "        time.sleep(5)\n",
    "        wait= WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,\"//div[@class='title-row']\")))\n",
    "        data= driver.find_elements(By.XPATH,\"//div[@class='title-row']\")\n",
    "    \n",
    "    # checking the length of the data found and if there are \"featured\" properties(shown at top) listed then they are removed.\n",
    "    # they are removed since \"featured properties\" are also listed in the all properties.\n",
    "    if len(data)==33:\n",
    "        data=data[3:]\n",
    "    elif len(data)==32:\n",
    "        data=data[2:]\n",
    "    elif len(data)==31:\n",
    "        data=data[1:]\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    # getting the name and distance from city center data into a list.\n",
    "    for i in data:\n",
    "        names.append(i.text.split(\"\\n\")[0])\n",
    "        dist_cc.append(i.text.split(\"\\n\")[1].split(\"-\")[1].strip().split(\" \")[0])\n",
    "        \n",
    "    # getting the dorm and privates prices data and appending them to respective lists.\n",
    "    wait= WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,\"//div[@class='price-col']\")))\n",
    "    data= driver.find_elements(By.XPATH,\"//div[@class='price-col']\")\n",
    "    for i in data[1::2]:\n",
    "        dorm_prices.append(i.text.split(\"Rs\")[-1])\n",
    "    for i in data[0::2]:\n",
    "        pvt_prices.append(i.text.split(\"Rs\")[-1])\n",
    "\n",
    "    # getting the links data and extracting the links to a list. \n",
    "    wait= WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,\"//a[@class='view-button']\")))\n",
    "    data= driver.find_elements(By.XPATH,\"//a[@class='view-button']\")\n",
    "    links=[]\n",
    "    for i in data:\n",
    "        links.append(i.get_attribute(\"href\"))\n",
    "    \n",
    "    # sending requests to each property link and getting the required info from them.\n",
    "    for i in links:\n",
    "        r=requests.get(i,headers=HEADERS)\n",
    "        soup=bs(r.content)\n",
    "        \n",
    "        # getting the ratings, overall review and total-reviews data. In case of missing data \"-\" is appended to the respective list.\n",
    "        try:\n",
    "            ratings.append(soup.find(\"div\",class_=\"score orange big\").text)\n",
    "            overall_reviews.append(soup.find(\"div\",class_=\"keyword\").text)\n",
    "            total_reviews.append(soup.find(\"div\",class_=\"reviews\").text)\n",
    "        except AttributeError:\n",
    "            try:        \n",
    "                ratings.append(soup.find(\"div\",class_=\"score gray big\").text)\n",
    "                overall_reviews.append(\"-\")\n",
    "                total_reviews.append(soup.find(\"div\",class_=\"reviews\").text)\n",
    "            except AttributeError:\n",
    "                ratings.append(\"-\")\n",
    "                overall_reviews.append(\"-\")\n",
    "                try:              \n",
    "                    total_reviews.append(soup.find(\"div\",class_=\"reviews\").text)\n",
    "                except AttributeError:\n",
    "                    total_reviews.append(\"-\")\n",
    "        \n",
    "        # getting the property description data and extracting the text into a list.\n",
    "        # incase of missing data \"-\" is appended.\n",
    "        prop_data= soup.find_all(\"div\",class_=\"description-container\")\n",
    "        try:\n",
    "            if len(prop_data)==1:\n",
    "                prop_des.append(prop_data[0].text.strip().split(\"Property Description\")[1])\n",
    "            elif len(prop_data)==0:\n",
    "                prop_des.append('-')\n",
    "            else:\n",
    "                prop_des.append(prop_data[1].text.strip().split(\"Property Description\")[1])\n",
    "        except AttributeError:\n",
    "            prop_des.append(\"-\") \n",
    "        except IndexError:\n",
    "            prop_des.append(\"-\")\n",
    "                    \n",
    "        # getting the facilities data and extracting the text into a list. Incase of missing data \"-\" is appended.        \n",
    "        try:\n",
    "            facilities_data= soup.find(\"ul\",class_='facility-sections')\n",
    "            facilities.append(facilities_data.text.strip().replace(\"t_\",\"\").lower().replace(\"facilitycategoryfree   \",\"\").replace(\"facilitycategorygeneral   \",\"\").replace(\"facilitycategoryservices   \",\"\").replace(\"facilitycategoryfoodanddrink   \",\"\").replace(\"facilitycategoryentertainment   \",\"\").strip())\n",
    "        except AttributeError:\n",
    "            facilities.append(\"-\")\n",
    "\n",
    "\n",
    "def scrap_hostel_world(url):\n",
    "    \n",
    "    # opening the target website.\n",
    "    driver.get(url)\n",
    "    # putting the program on hold for 3 seconds so that the page gets loaded properly.\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # using the explicit wait method till the search field is loaded.\n",
    "    wait= WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,\"/html/body/div[3]/div/div/div[1]/div[1]/div/div/div[4]/div/div[2]/div/div[1]/div\")))\n",
    "    # finding the webelement of the search field and clicking on in so that it gets activated for input.\n",
    "    srch_activate= driver.find_element(By.XPATH, \"/html/body/div[3]/div/div/div[1]/div[1]/div/div/div[4]/div/div[2]/div/div[1]/div\").click()\n",
    "    \n",
    "    # using the explicit wait method till the activated-search-field is loaded.\n",
    "    wait= WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,\"/html/body/div[3]/div/div/div[1]/div[1]/div/div/div[4]/div/div[2]/div/div[1]/div/div/div/input\")))\n",
    "    # finding the webelement for the activated-search-field and sending the required keys.\n",
    "    srch= driver.find_element(By.XPATH,\"/html/body/div[3]/div/div/div[1]/div[1]/div/div/div[4]/div/div[2]/div/div[1]/div/div/div/input\")\n",
    "    srch.send_keys(\"London\")\n",
    "\n",
    "    try:\n",
    "        # using the explicit wait method till the \"London\" result is loaded in recommended results.\n",
    "        wait= WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,\"/html/body/div[3]/div/div/div[1]/div[1]/div/div/div[4]/div/div[2]/div/div[1]/div/div/ul/li[2]/div\")))\n",
    "        # finding the webelement for the first result and clicking on it.\n",
    "        driver.find_element(By.XPATH,\"/html/body/div[3]/div/div/div[1]/div[1]/div/div/div[4]/div/div[2]/div/div[1]/div/div/ul/li[2]/div\").click()\n",
    "        # finding the webelement for the search button and clicking on it.\n",
    "        btn= driver.find_element(By.XPATH,\"/html/body/div[3]/div/div/div[1]/div[1]/div/div/div[4]/div/div[2]/div/div[5]/button\").click()\n",
    "    except TimeoutException:\n",
    "        # if no reults are loaded in recommended results then print a message and return the function.\n",
    "        print(\"No Results Found!!!\")\n",
    "        return\n",
    "    \n",
    "    # defining a variable to keep track of the page it is processing.\n",
    "    count=1\n",
    "    print(f'Processing Page{count}...')\n",
    "    # calling the function \"get_data\" to scrap the first page results.\n",
    "    get_data()\n",
    "    \n",
    "    #running a for loop for subsequent pages where we keep clicking on the next-page button till the button becomes disabled and we face timeout-exception. Then we break the loop.\n",
    "    for i in range(5):\n",
    "        try:\n",
    "            wait= WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,\"//div[@class='pagination-item pagination-next']\")))\n",
    "            driver.execute_script(\"arguments[0].click();\", driver.find_element(By.XPATH,\"//div[@class='pagination-item pagination-next']\"))\n",
    "            count+=1\n",
    "        except TimeoutException:\n",
    "            break        \n",
    "        time.sleep(1)\n",
    "        print(f'Processing Page{count}...')\n",
    "        get_data()\n",
    "    \n",
    "    # the final dataframe.\n",
    "    hostels= pd.DataFrame({ \"Name\":names,\n",
    "                            \"Distance from City-Center\":dist_cc,\n",
    "                            \"Rating\":ratings, \n",
    "                            \"Dorms from Price(â‚¹)\":dorm_prices, \n",
    "                            \"Privates from Price(â‚¹)\":pvt_prices,\n",
    "                            \"Overall Review\":overall_reviews,\n",
    "                            \"Total Reviews\":total_reviews,\n",
    "                            \"Facilities\":facilities, \n",
    "                            \"Property Description\": prop_des                        \n",
    "                           })\n",
    "    # returning the dataframe.\n",
    "    return hostels\n",
    "\n",
    "# connecting to the webdriver.\n",
    "driver= webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "# mentioning the target website.\n",
    "url= \"https://www.hostelworld.com/\"\n",
    "\n",
    "# calling the scraping function and saving the results.\n",
    "df= scrap_hostel_world(url)\n",
    "\n",
    "#closing the webdriver.\n",
    "driver.close()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2788becd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
