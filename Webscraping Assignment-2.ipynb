{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cabef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7a9e6588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sr.Business Data Analyst</td>\n",
       "      <td>Collabera</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, karnataka\\n(WFH during Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sr Data Analyst</td>\n",
       "      <td>Thomson Reuters</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Analysis Analyst</td>\n",
       "      <td>Capco</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Job opportunity For Data Analyst at Trellance ...</td>\n",
       "      <td>CURise Analytics Pvt. Ltd.</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Thomson Reuters</td>\n",
       "      <td>2-3 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>KrazyBee</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru(Old Madras Road)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Associate Data Analyst</td>\n",
       "      <td>Optum</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Associate Data Analyst</td>\n",
       "      <td>Optum</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst/Senior Data Analyst</td>\n",
       "      <td>Meesho</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                           Sr.Business Data Analyst   \n",
       "1                                    Sr Data Analyst   \n",
       "2                       Senior Data Analysis Analyst   \n",
       "3  Job opportunity For Data Analyst at Trellance ...   \n",
       "4                                       Data Analyst   \n",
       "5                                Senior Data Analyst   \n",
       "6                                       Data Analyst   \n",
       "7                             Associate Data Analyst   \n",
       "8                             Associate Data Analyst   \n",
       "9                   Data Analyst/Senior Data Analyst   \n",
       "\n",
       "                      Company Experience  \\\n",
       "0                   Collabera   6-11 Yrs   \n",
       "1             Thomson Reuters    5-8 Yrs   \n",
       "2                       Capco   7-12 Yrs   \n",
       "3  CURise Analytics Pvt. Ltd.    0-2 Yrs   \n",
       "4             Thomson Reuters    2-3 Yrs   \n",
       "5                    KrazyBee    3-6 Yrs   \n",
       "6                       Wipro    4-9 Yrs   \n",
       "7                       Optum    2-7 Yrs   \n",
       "8                       Optum    1-4 Yrs   \n",
       "9                      Meesho    3-6 Yrs   \n",
       "\n",
       "                                            Location  \n",
       "0  Bangalore/Bengaluru, karnataka\\n(WFH during Co...  \n",
       "1                                Bangalore/Bengaluru  \n",
       "2                 Bangalore/Bengaluru, Pune, Chennai  \n",
       "3                     Bangalore/Bengaluru, Ahmedabad  \n",
       "4                                Bangalore/Bengaluru  \n",
       "5               Bangalore/Bengaluru(Old Madras Road)  \n",
       "6  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...  \n",
       "7                                Bangalore/Bengaluru  \n",
       "8                                Bangalore/Bengaluru  \n",
       "9                                Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1 Solution:\n",
    "\n",
    "# connecting to the webdriver\n",
    "driver= webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "# opening the target website\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "\n",
    "# finding the webelement for the “Skill, Designations, Companies\" field using class-name and sending the required keys\n",
    "search_job= driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "search_job.send_keys(\"Data Analyst\")\n",
    "\n",
    "# finding the webelement for the “Location\" field using absolute-xpath and sending the required keys\n",
    "location= driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[3]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys(\"Bangalore\")\n",
    "\n",
    "# finding the webelement for the \"search\" button using absolute-xpath and clicking it\n",
    "search_btn= driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[3]/div/div/div[6]\")\n",
    "search_btn.click()\n",
    "\n",
    "# getting the we belements for job-titles using relative-xpath and then extract the text-data into a list.\n",
    "# since only 10 elements required hence limiting the for loop to 10 iterations.\n",
    "title_data= driver.find_elements(By.XPATH,\"//a[@class='title fw500 ellipsis']\")\n",
    "job_titles= []\n",
    "for i in title_data[:10]:\n",
    "    job_titles.append(i.text)\n",
    "    \n",
    "# getting the webelements for company names using relative-xpath and then extract the text-data into a list.\n",
    "# since only 10 elements required hence limiting the for loop to 10 iterations.\n",
    "company_data= driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "companies= []\n",
    "for i in company_data[:10]: \n",
    "    companies.append(i.text)\n",
    "     \n",
    "# getting the webelements for experience using relative-xpath and then extract the text-data into a list.\n",
    "# since only 10 elements required hence limiting the for loop to 10 iterations.\n",
    "exp_data= driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "exp= []\n",
    "for i in exp_data[:10]:\n",
    "    exp.append(i.text) \n",
    "    \n",
    "# getting the webelements for location-data using relative-xpath and then extract the text-data into a list.\n",
    "# since only 10 elements required hence limiting the for loop to 10 iterations.\n",
    "location_data= driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "location= []\n",
    "for i in location_data[:10]:\n",
    "    location.append(i.text) \n",
    "\n",
    "# the final dataframe\n",
    "jobs= pd.DataFrame({\"Job Title\":job_titles, \"Company\":companies, \"Experience\":exp, \"Location\":location})\n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aa541822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist/ Senior Data Scientist</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Gurgaon/Gurugram, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Urgent Job Opening For AI Practitioner - Data ...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>Bangalore/Bengaluru, Kochi/Cochin, New Delhi, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hiring For Senior Data Scientist</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "      <td>Bangalore/Bengaluru, Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dataiku Consultant</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data &amp; Analytics Tech - Informatica Cloud- Sen...</td>\n",
       "      <td>PwC</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>IBM</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Research Scientist</td>\n",
       "      <td>IBM</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Principal - Data Scientist</td>\n",
       "      <td>Schneider Electric</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Research and Development -AI/ML -(PhD )</td>\n",
       "      <td>EXL</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0              Data Scientist/ Senior Data Scientist   \n",
       "1  Urgent Job Opening For AI Practitioner - Data ...   \n",
       "2                   Hiring For Senior Data Scientist   \n",
       "3                                 Dataiku Consultant   \n",
       "4                                     Data Scientist   \n",
       "5  Data & Analytics Tech - Informatica Cloud- Sen...   \n",
       "6                 Data Scientist: Advanced Analytics   \n",
       "7                                 Research Scientist   \n",
       "8                         Principal - Data Scientist   \n",
       "9            Research and Development -AI/ML -(PhD )   \n",
       "\n",
       "                           Company  \\\n",
       "0                Fractal Analytics   \n",
       "1                            Wipro   \n",
       "2  TATA CONSULTANCY SERVICES (TCS)   \n",
       "3                            Wipro   \n",
       "4                Applied Materials   \n",
       "5                              PwC   \n",
       "6                              IBM   \n",
       "7                              IBM   \n",
       "8               Schneider Electric   \n",
       "9                              EXL   \n",
       "\n",
       "                                            Location  \n",
       "0  Bangalore/Bengaluru, Pune, Gurgaon/Gurugram, C...  \n",
       "1  Bangalore/Bengaluru, Kochi/Cochin, New Delhi, ...  \n",
       "2                          Bangalore/Bengaluru, Pune  \n",
       "3                 Bangalore/Bengaluru, Pune, Chennai  \n",
       "4                                Bangalore/Bengaluru  \n",
       "5                                Bangalore/Bengaluru  \n",
       "6                                Bangalore/Bengaluru  \n",
       "7                                Bangalore/Bengaluru  \n",
       "8                                Bangalore/Bengaluru  \n",
       "9  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2 Solution:\n",
    "\n",
    "# connecting to the webdriver\n",
    "driver= webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "# opening the target website\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "\n",
    "# finding the webelement for the “Skill, Designations, Companies\" field using class-name and sending the required keys\n",
    "search_job= driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "\n",
    "# finding the webelement for the “Location\" field using absolute-xpath and sending the required keys\n",
    "location= driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[3]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys(\"Bangalore\")\n",
    "\n",
    "# finding the webelement for the \"search\" button using absolute-xpath and clicking it\n",
    "search_btn= driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[3]/div/div/div[6]\")\n",
    "search_btn.click()\n",
    "\n",
    "# getting the webelements for job-titles using relative-xpath and then extract the text-data into a list.\n",
    "# since only 10 elements required hence limiting the for loop to 10 iterations.\n",
    "title_data= driver.find_elements(By.XPATH,\"//a[@class='title fw500 ellipsis']\")\n",
    "job_titles= []\n",
    "for i in title_data[:10]:\n",
    "    job_titles.append(i.text)\n",
    "\n",
    "# getting the webelements for company names using relative-xpath and then extract the text-data into a list.\n",
    "# since only 10 elements required hence limiting the for loop to 10 iterations.\n",
    "company_data= driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "companies= []\n",
    "for i in company_data[:10]: \n",
    "    companies.append(i.text)\n",
    "    \n",
    "# getting the webelements for location-data using relative-xpath and then extract the text-data into a list.\n",
    "# since only 10 elements required hence limiting the for loop to 10 iterations.\n",
    "location_data= driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "location= []\n",
    "for i in location_data[:10]:\n",
    "    location.append(i.text) \n",
    "\n",
    "# the final dataframe\n",
    "jobs= pd.DataFrame({\"Job Title\":job_titles, \"Company\":companies, \"Location\":location})\n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "def61ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DigitalBCG GAMMA Data Scientist</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Associate - Data Science</td>\n",
       "      <td>Black Turtle</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Gurgaon/Gurugr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Noida/Bangalore</td>\n",
       "      <td>EXL</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist For Healthcare Product team</td>\n",
       "      <td>8KMiles Software Services</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Delhi / NCR, Chennai, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist For Healthcare Product team</td>\n",
       "      <td>8KMiles Software Services</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Delhi / NCR, Chennai, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Machine learning AI</td>\n",
       "      <td>Teq Analytics</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Delhi / NCR, Bangalore/Bengaluru, Mumbai (All ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - MIND Infotech</td>\n",
       "      <td>MOTHERSONSUMI INFOTECH &amp; DESIGNS LIMITED</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Engine Algorithm</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Knowledge/Data Scientist</td>\n",
       "      <td>BOLD Technology Systems</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Delhi / NCR, Pune, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Job Title  \\\n",
       "0             DigitalBCG GAMMA Data Scientist   \n",
       "1             Senior Associate - Data Science   \n",
       "2            Data Scientist - Noida/Bangalore   \n",
       "3  Data Scientist For Healthcare Product team   \n",
       "4  Data Scientist For Healthcare Product team   \n",
       "5        Data Scientist - Machine learning AI   \n",
       "6              Data Scientist - MIND Infotech   \n",
       "7           Data Scientist - Engine Algorithm   \n",
       "8                    Knowledge/Data Scientist   \n",
       "9                              Data Scientist   \n",
       "\n",
       "                                    Company Experience  \\\n",
       "0                   Boston Consulting Group    2-5 Yrs   \n",
       "1                              Black Turtle    4-7 Yrs   \n",
       "2                                       EXL   5-10 Yrs   \n",
       "3                 8KMiles Software Services    2-7 Yrs   \n",
       "4                 8KMiles Software Services    2-7 Yrs   \n",
       "5                             Teq Analytics    3-8 Yrs   \n",
       "6  MOTHERSONSUMI INFOTECH & DESIGNS LIMITED    4-8 Yrs   \n",
       "7                              Primo Hiring    1-3 Yrs   \n",
       "8                   BOLD Technology Systems    3-6 Yrs   \n",
       "9   Mount Talent Consulting Private Limited    2-4 Yrs   \n",
       "\n",
       "                                            Location  \n",
       "0                     New Delhi, Bangalore/Bengaluru  \n",
       "1  Mumbai, Hyderabad/Secunderabad, Gurgaon/Gurugr...  \n",
       "2                         Noida, Bangalore/Bengaluru  \n",
       "3          Delhi / NCR, Chennai, Bangalore/Bengaluru  \n",
       "4          Delhi / NCR, Chennai, Bangalore/Bengaluru  \n",
       "5  Delhi / NCR, Bangalore/Bengaluru, Mumbai (All ...  \n",
       "6                                              Noida  \n",
       "7  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...  \n",
       "8                                        Delhi / NCR  \n",
       "9             Delhi / NCR, Pune, Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3 Solution:\n",
    "\n",
    "# connecting to the webdriver.\n",
    "driver= webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "# opening the target website.\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "\n",
    "# finding the webelement for the “Skill, Designations, Companies\" field using class-name and sending the required keys.\n",
    "search_job= driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "\n",
    "# finding the webelement for the \"search\" button using absolute-xpath and clicking it.\n",
    "search_btn= driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[3]/div/div/div[6]\")\n",
    "search_btn.click()\n",
    "\n",
    "# Using the explicit wait method till the element we want is loaded\n",
    "wait = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[5]/div[2]/div[3]/label/i\")))\n",
    "# finding the webelement for \"location-filter\" using absolute-xpath and clicking it.\n",
    "location_filter= driver.find_element(By.XPATH,\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[5]/div[2]/div[3]/label/i\")\n",
    "location_filter.click()\n",
    "\n",
    "# Using the explicit wait method till the element we want is loaded\n",
    "wait = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[6]/div[2]/div[2]/label/i\")))\n",
    "\n",
    "# finding the webelement for \"salary-filter\" using absolute-xpath and clicking it.\n",
    "salary_filter= driver.find_element(By.XPATH,\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[6]/div[2]/div[2]/label/i\")\n",
    "salary_filter.click()\n",
    "\n",
    "# Using the explicit wait method till the webpage is loaded with the webelements we want.\n",
    "wait = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"/html/body/div[1]/div[3]/div[2]/section[2]/div[2]/article[1]/div[1]/div[1]/a\")))\n",
    "\n",
    "# getting the webelements for job-titles using relative-xpath and then extract the text-data into a list.\n",
    "# since only 10 elements required hence limiting the for loop to 10 iterations.\n",
    "title_data= driver.find_elements(By.XPATH,\"//a[@class='title fw500 ellipsis']\")\n",
    "job_titles= []\n",
    "for i in title_data[:10]:\n",
    "    job_titles.append(i.text)\n",
    "    \n",
    "# getting the webelements for company names using relative-xpath and then extract the text-data into a list.\n",
    "# since only 10 elements required hence limiting the for loop to 10 iterations.\n",
    "company_data= driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "companies= []\n",
    "for i in company_data[:10]: \n",
    "    companies.append(i.text)\n",
    "\n",
    "# getting the webelements for experience data using relative-xpath and then extract the text-data into a list.\n",
    "# since only 10 elements required hence limiting the for loop to 10 iterations.\n",
    "exp_data= driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "exp= []\n",
    "for i in exp_data[:10]:\n",
    "    exp.append(i.text) \n",
    "\n",
    "# getting the webelements for location data using relative-xpath and then extract the text-data into a list.\n",
    "# since only 10 elements required hence limiting the for loop to 10 iterations.\n",
    "location_data= driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "location= []\n",
    "for i in location_data[:10]:\n",
    "    location.append(i.text)\n",
    "\n",
    "# the final dataframe\n",
    "jobs= pd.DataFrame({\"Job Title\":job_titles, \"Company\":companies, \"Experience\":exp, \"Location\":location})\n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "91cb2ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>₹314</td>\n",
       "      <td>84% off</td>\n",
       "      <td>UV Protection, Night Vision, Riding Glasses Av...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>₹749</td>\n",
       "      <td>62% off</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Rectangul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DAHAAZIL</td>\n",
       "      <td>₹177</td>\n",
       "      <td>82% off</td>\n",
       "      <td>UV Protection, Night Vision, Riding Glasses Wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New Specs</td>\n",
       "      <td>₹264</td>\n",
       "      <td>89% off</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹639</td>\n",
       "      <td>20% off</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>₹616</td>\n",
       "      <td>69% off</td>\n",
       "      <td>Polarized, UV Protection Retro Square Sunglass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>₹1,099</td>\n",
       "      <td>45% off</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (51)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>₹314</td>\n",
       "      <td>84% off</td>\n",
       "      <td>UV Protection, Riding Glasses Aviator Sunglass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>₹299</td>\n",
       "      <td>85% off</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (53)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>₹664</td>\n",
       "      <td>66% off</td>\n",
       "      <td>Polarized, UV Protection Wayfarer, Retro Squar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand   Price Discount  \\\n",
       "0           GANSTA    ₹314  84% off   \n",
       "1    VINCENT CHASE    ₹749  62% off   \n",
       "2         DAHAAZIL    ₹177  82% off   \n",
       "3        New Specs    ₹264  89% off   \n",
       "4         Fastrack    ₹639  20% off   \n",
       "..             ...     ...      ...   \n",
       "95       ROYAL SON    ₹616  69% off   \n",
       "96   VINCENT CHASE  ₹1,099  45% off   \n",
       "97          GANSTA    ₹314  84% off   \n",
       "98  kingsunglasses    ₹299  85% off   \n",
       "99       ROYAL SON    ₹664  66% off   \n",
       "\n",
       "                                          Description  \n",
       "0   UV Protection, Night Vision, Riding Glasses Av...  \n",
       "1   by Lenskart Polarized, UV Protection Rectangul...  \n",
       "2   UV Protection, Night Vision, Riding Glasses Wa...  \n",
       "3    UV Protection Rectangular Sunglasses (Free Size)  \n",
       "4    UV Protection Rectangular Sunglasses (Free Size)  \n",
       "..                                                ...  \n",
       "95  Polarized, UV Protection Retro Square Sunglass...  \n",
       "96     Polarized, UV Protection Round Sunglasses (51)  \n",
       "97  UV Protection, Riding Glasses Aviator Sunglass...  \n",
       "98   Mirrored, UV Protection Wayfarer Sunglasses (53)  \n",
       "99  Polarized, UV Protection Wayfarer, Retro Squar...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q4 Solution:\n",
    "\n",
    "# defining a function to collect the necessary webelements and making the respective lists out of them.\n",
    "def datacollect():\n",
    "    data= driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "    for i in data:\n",
    "        brands.append(i.text)\n",
    "\n",
    "    data= driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\")\n",
    "    for i in data:\n",
    "        descriptions.append(i.text)\n",
    "\n",
    "    data= driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "    for i in data:\n",
    "        prices.append(i.text)\n",
    "\n",
    "    data= driver.find_elements(By.XPATH,\"//div[@class='_3Ay6Sb']\")\n",
    "    for i in data:\n",
    "        discounts.append(i.text)\n",
    "\n",
    "# connecting to the webdriver.\n",
    "driver= webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "# opening the target website. \n",
    "driver.get(\"https://www.flipkart.com\")\n",
    "\n",
    "# finding the webelement for the close-button in the login form using absolute-xpath and clicking on it.\n",
    "button= driver.find_element(By.XPATH,\"/html/body/div[2]/div/div/button\")\n",
    "button.click()\n",
    "\n",
    "# finding the webelement for the search field using absolute-xpath and sending the required keys.\n",
    "srch_sunglasses= driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "srch_sunglasses.send_keys(\"sunglasses\")\n",
    "\n",
    "# finding the webelement for the search button using relative-xpath and clicking on it.\n",
    "search_btn= driver.find_element(By.XPATH,\"//button[@class='L0Z3Pu']\")\n",
    "search_btn.click()\n",
    "\n",
    "# defining the lists to be used.\n",
    "brands=[]\n",
    "descriptions=[]\n",
    "prices=[]\n",
    "discounts=[]\n",
    "\n",
    "# using the explicit wait method till the elements we want is loaded.\n",
    "wait= WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//div[@class='_2WkVRV']\")))\n",
    "\n",
    "# collect the necessary data using the function defined.\n",
    "datacollect()\n",
    "\n",
    "# finding the webelement for the next-page button using absolute-xpath and clicking on it.\n",
    "next_page_btn= driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[2]\")\n",
    "next_page_btn.click()\n",
    "\n",
    "# refreshing the page and then using the explicit wait method till the elements we want is loaded.\n",
    "driver.refresh()\n",
    "wait= WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//div[@class='_2WkVRV']\")))\n",
    "\n",
    "# collect the necessary data from the current page using the function defined.\n",
    "datacollect()\n",
    "\n",
    "# finding the webelement for the next-page button using absolute-xpath and clicking on it.\n",
    "next_page_btn= driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[4]\")\n",
    "next_page_btn.click()\n",
    "\n",
    "# refreshing the page and then using the explicit wait method till the elements we want is loaded.\n",
    "driver.refresh()\n",
    "wait= WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//div[@class='_1xHGtK _373qXS']\")))\n",
    "\n",
    "# collect the necessary data from the current page using the function defined.\n",
    "datacollect()\n",
    "\n",
    "# the final dataframe and the top100 results.\n",
    "sunglasses= pd.DataFrame({\"Brand\":brands, \"Price\":prices, \"Discount\":discounts, \"Description\":descriptions})\n",
    "sunglasses[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1ec0c7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>This is my first ever iPhone.\\nAnd I truly don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Nice value for money good and best price I pho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Undoubtedly Iphone 11 is the most successful m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Don’t expect much from front camera… especiall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>I purchased the iPhone 11 a month back. I must...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Review Summary  \\\n",
       "0       5       Simply awesome   \n",
       "1       5     Perfect product!   \n",
       "2       5  Best in the market!   \n",
       "3       5   Highly recommended   \n",
       "4       5    Worth every penny   \n",
       "..    ...                  ...   \n",
       "95      5               Super!   \n",
       "96      5            Wonderful   \n",
       "97      5    Worth every penny   \n",
       "98      5  Best in the market!   \n",
       "99      5            Fabulous!   \n",
       "\n",
       "                                          Full Review  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   What a camera .....just awesome ..you can feel...  \n",
       "4   Previously I was using one plus 3t it was a gr...  \n",
       "..                                                ...  \n",
       "95  This is my first ever iPhone.\\nAnd I truly don...  \n",
       "96  Nice value for money good and best price I pho...  \n",
       "97  Undoubtedly Iphone 11 is the most successful m...  \n",
       "98  Don’t expect much from front camera… especiall...  \n",
       "99  I purchased the iPhone 11 a month back. I must...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q5 Solution:\n",
    "\n",
    "# defining a function to collect the necessary webelements and making the respective lists out of them.\n",
    "def datacollect():\n",
    "    \n",
    "    data1= driver.find_elements(By.XPATH,\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "    data2= driver.find_elements(By.XPATH, \"//p[@class='_2-N8zT']\")\n",
    "    data3= driver.find_elements(By.XPATH,\"//div[@class='t-ZTKy']\")\n",
    "    data4= driver.find_elements(By.XPATH,\"//div[@class='col _2wzgFH K0kLPL']\")\n",
    "    \n",
    "    # data1 holds ratings webdata, data2 holds review-summary, data3 holds full-review.\n",
    "    # The tag and class name of poor-ratings(1 and 2 star) elements are different from\n",
    "    # the higher-ratings ones. Hence giving an if-else condition to treat pages having \n",
    "    # poor-ratings differently.\n",
    "    # data4 holds ratings, review-summary and full-review data together(for pages with\n",
    "    # poor-ratings) from which each type is extracted separately using split function.\n",
    "    \n",
    "    if (len(data1)==len(data2)):\n",
    "        for i in data1:\n",
    "            ratings.append(i.text)\n",
    "\n",
    "        for i in data2:\n",
    "            rvw_smry.append(i.text)\n",
    "\n",
    "        for i in data3:\n",
    "            full_rvw.append(i.text)\n",
    "            \n",
    "    else:\n",
    "        for i in data4:\n",
    "            contents= (i.text).split(\"\\n\")\n",
    "            ratings.append(contents[0])\n",
    "            rvw_smry.append(contents[1])\n",
    "            full_rvw.append(contents[2])\n",
    "\n",
    "# defining the lists to be used.          \n",
    "ratings=[]\n",
    "rvw_smry=[]\n",
    "full_rvw=[]\n",
    "\n",
    "# connecting to the firefox webdriver.\n",
    "driver= webdriver.Firefox()\n",
    "\n",
    "# opening the target website.\n",
    "driver.get(\"https://www.flipkart.com\")\n",
    "\n",
    "# finding the webelement for the close-button in the login form using absolute-xpath and clicking on it.\n",
    "button= driver.find_element(By.XPATH,\"/html/body/div[2]/div/div/button\")\n",
    "button.click()\n",
    "\n",
    "# finding the webelement for the search field using absolute-xpath and sending the required keys.\n",
    "srch_iphone= driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "srch_iphone.send_keys(\"iphone 11\")\n",
    "\n",
    "# finding the webelement for the search button using relative-xpath and clicking on it.\n",
    "search_btn= driver.find_element(By.XPATH,\"//button[@class='L0Z3Pu']\")\n",
    "search_btn.click()\n",
    "\n",
    "# using the explicit wait method till the element we want is loaded.\n",
    "wait= WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//div[@class='_4rR01T']\")))\n",
    "\n",
    "# finding the webelements for different variants of iphone11 and selecting the required one and clicking it.\n",
    "element= driver.find_elements(By.XPATH,\"//div[@class='_4rR01T']\")[3].click()\n",
    "\n",
    "# switching the tab to the newly opened one.\n",
    "driver.switch_to.window(driver.window_handles[1])\n",
    "\n",
    "# using the explicit wait method till the element we want is loaded.\n",
    "wait= WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH,\"//div[@class='_3UAT2v _16PBlm']\")))\n",
    "\n",
    "# finding the webelement for the \"all-reviews\" button using relative-xpath and clicking it.\n",
    "all_reviews_click= driver.find_element(By.XPATH,\"//div[@class='_3UAT2v _16PBlm']\").click()\n",
    "\n",
    "# putting the execution of the program on hold for 10 seconds so that the page gets time to load properly.\n",
    "time.sleep(10)\n",
    "\n",
    "# using the explicit wait method till the element we want is loaded.\n",
    "wait= WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH,\"//div[@class='_3LWZlK _1BLPMq']\")))\n",
    "\n",
    "# collect the required data using the function defined.\n",
    "datacollect()\n",
    "\n",
    "# using the explicit wait method till the element we want is loaded.\n",
    "wait= WebDriverWait(driver,10).until(EC.element_to_be_clickable((By.XPATH,\"//a[@class='_1LKTO3']\")))\n",
    "\n",
    "# finding the webelement for \"next\" button using relative-xpath and clicking it.\n",
    "nxt_btn= driver.find_element(By.XPATH,\"//a[@class='_1LKTO3']\").click()\n",
    "\n",
    "# putting the execution of the program on hold for 10 seconds so that the page gets time to load properly.\n",
    "time.sleep(10)\n",
    "\n",
    "# using the explicit wait method till the element we want is loaded.\n",
    "wait= WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH,\"//div[@class='_3LWZlK _1BLPMq']\")))\n",
    "\n",
    "# collect the required data from the current page using the function defined.\n",
    "datacollect()\n",
    "\n",
    "# since we already have collected data from 2 pages hence need to do for 8 more pages. Each page holds 10 reviews. \n",
    "for i in range(0,8):\n",
    "    \n",
    "    wait1= WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.XPATH,\"//a[@class='_1LKTO3']\")))\n",
    "    wait1= WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,\"//nav[@class='yFHi8N']\")))    \n",
    "    nxt_btn= driver.find_elements(By.XPATH,\"//a[@class='_1LKTO3']\")[1].click()\n",
    "    driver.refresh()\n",
    "    wait2= WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH,\"//div[@class='_3LWZlK _1BLPMq']\")))\n",
    "    datacollect()\n",
    "    time.sleep(10)\n",
    "\n",
    "# the final dataframe\n",
    "reviews= pd.DataFrame({\"Rating\":ratings, \"Review Summary\":rvw_smry, \"Full Review\":full_rvw})\n",
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "74e6f4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WOODLAND</td>\n",
       "      <td>₹2,096</td>\n",
       "      <td>30% off</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>₹284</td>\n",
       "      <td>78% off</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>₹299</td>\n",
       "      <td>76% off</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>URBANBOX</td>\n",
       "      <td>₹198</td>\n",
       "      <td>80% off</td>\n",
       "      <td>Sneakers Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>₹449</td>\n",
       "      <td>55% off</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>HOTSTYLE</td>\n",
       "      <td>₹295</td>\n",
       "      <td>40% off</td>\n",
       "      <td>CR-1 Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>BAUCHHAAR</td>\n",
       "      <td>₹449</td>\n",
       "      <td>55% off</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>KNIGHT WALKERS</td>\n",
       "      <td>₹648</td>\n",
       "      <td>56% off</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Bretton</td>\n",
       "      <td>₹251</td>\n",
       "      <td>74% off</td>\n",
       "      <td>Classy Stylish Ayasa Sneakers Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>₹299</td>\n",
       "      <td>76% off</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand   Price Discount  \\\n",
       "0         WOODLAND  ₹2,096  30% off   \n",
       "1           BRUTON    ₹284  78% off   \n",
       "2           BRUTON    ₹299  76% off   \n",
       "3         URBANBOX    ₹198  80% off   \n",
       "4         Magnolia    ₹449  55% off   \n",
       "..             ...     ...      ...   \n",
       "95        HOTSTYLE    ₹295  40% off   \n",
       "96       BAUCHHAAR    ₹449  55% off   \n",
       "97  KNIGHT WALKERS    ₹648  56% off   \n",
       "98         Bretton    ₹251  74% off   \n",
       "99          BRUTON    ₹299  76% off   \n",
       "\n",
       "                                       Description  \n",
       "0                                 Sneakers For Men  \n",
       "1    Modern Trendy Sneakers Shoes Sneakers For Men  \n",
       "2    Modern Trendy Sneakers Shoes Sneakers For Men  \n",
       "3                        Sneakers Sneakers For Men  \n",
       "4                                 Sneakers For Men  \n",
       "..                                             ...  \n",
       "95                           CR-1 Sneakers For Men  \n",
       "96                                Sneakers For Men  \n",
       "97                                Sneakers For Men  \n",
       "98  Classy Stylish Ayasa Sneakers Sneakers For Men  \n",
       "99   Modern Trendy Sneakers Shoes Sneakers For Men  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q6 Solution:\n",
    "\n",
    "# defining a function to collect the necessary webelements and making the respective lists out of them.\n",
    "def datacollect():\n",
    "    data= driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "    for i in data:\n",
    "        brands.append(i.text)\n",
    "\n",
    "    data= driver.find_elements(By.XPATH,\"//div[@class='_2B099V']\")\n",
    "    for i in data:\n",
    "        descriptions.append((i.text).split(\"\\n\")[1])\n",
    "\n",
    "    data= driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "    for i in data:\n",
    "        prices.append(i.text)\n",
    "\n",
    "    data= driver.find_elements(By.XPATH,\"//div[@class='_3Ay6Sb']\")\n",
    "    for i in data:\n",
    "        discounts.append(i.text)\n",
    "\n",
    "# connecting to the webdriver.\n",
    "driver= webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "# opening the target website. \n",
    "driver.get(\"https://www.flipkart.com\")\n",
    "\n",
    "# finding the webelement for the close-button in the login form using absolute-xpath and clicking on it.\n",
    "button= driver.find_element(By.XPATH,\"/html/body/div[2]/div/div/button\")\n",
    "button.click()\n",
    "\n",
    "# finding the webelement for the search field using absolute-xpath and sending the required keys.\n",
    "srch_sneakers= driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "srch_sneakers.send_keys(\"sneakers\")\n",
    "\n",
    "# finding the webelement for the search button using relative-xpath and clicking on it.\n",
    "search_btn= driver.find_element(By.XPATH,\"//button[@class='L0Z3Pu']\")\n",
    "search_btn.click()\n",
    "\n",
    "# defining the lists to be used.\n",
    "brands=[]\n",
    "descriptions=[]\n",
    "prices=[]\n",
    "discounts=[]\n",
    "\n",
    "# using the explicit wait method till the elements we want is loaded.\n",
    "wait= WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//div[@class='_2WkVRV']\")))\n",
    "\n",
    "# collect the necessary data using the function defined.\n",
    "datacollect()\n",
    "\n",
    "# finding the webelement for the next-page button using absolute-xpath and clicking on it.\n",
    "next_page_btn= driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[2]\")\n",
    "next_page_btn.click()\n",
    "\n",
    "# refreshing the page and then using the explicit wait method till the elements we want is loaded.\n",
    "driver.refresh()\n",
    "wait= WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//div[@class='_2WkVRV']\")))\n",
    "\n",
    "# collect the necessary data from the current page using the function defined.\n",
    "datacollect()\n",
    "\n",
    "# finding the webelement for the next-page button using absolute-xpath and clicking on it.\n",
    "next_page_btn= driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[4]\")\n",
    "next_page_btn.click()\n",
    "\n",
    "# refreshing the page and then using the explicit wait method till the elements we want is loaded.\n",
    "driver.refresh()\n",
    "wait= WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//div[@class='_1xHGtK _373qXS']\")))\n",
    "\n",
    "# collect the necessary data from the current page using the function defined.\n",
    "datacollect()\n",
    "\n",
    "# the final dataframe and the top100 results.\n",
    "sneakers= pd.DataFrame({\"Brand\":brands, \"Price\":prices, \"Discount\":discounts, \"Description\":descriptions})\n",
    "sneakers[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e48d00ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price(Rs)</th>\n",
       "      <th>Short Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>11895</td>\n",
       "      <td>Men React Infinity 3 Running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>8895</td>\n",
       "      <td>Men SRG 3 FK Training Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>7649</td>\n",
       "      <td>Men Solid Leather Formal Slip-Ons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>7560</td>\n",
       "      <td>Men Zoom C Pro HC Tennis Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>8920</td>\n",
       "      <td>Women React MR 3 Running Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>fitflop</td>\n",
       "      <td>7499</td>\n",
       "      <td>Embellished PU Comfort Pumps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>fitflop</td>\n",
       "      <td>7499</td>\n",
       "      <td>Embellished Leather Wedge Sandals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Geox</td>\n",
       "      <td>7693</td>\n",
       "      <td>Women Leather Slip-On Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Columbia</td>\n",
       "      <td>7999</td>\n",
       "      <td>Women REDMOND V2 TrekkingShoe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Clarks</td>\n",
       "      <td>7224</td>\n",
       "      <td>Women Solid Leather Sneakers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand Price(Rs)                  Short Description\n",
       "0           Nike     11895       Men React Infinity 3 Running\n",
       "1           Nike      8895        Men SRG 3 FK Training Shoes\n",
       "2   Hush Puppies      7649  Men Solid Leather Formal Slip-Ons\n",
       "3           Nike      7560     Men Zoom C Pro HC Tennis Shoes\n",
       "4           Nike      8920     Women React MR 3 Running Shoes\n",
       "..           ...       ...                                ...\n",
       "95       fitflop      7499       Embellished PU Comfort Pumps\n",
       "96       fitflop      7499  Embellished Leather Wedge Sandals\n",
       "97          Geox      7693     Women Leather Slip-On Sneakers\n",
       "98      Columbia      7999      Women REDMOND V2 TrekkingShoe\n",
       "99        Clarks      7224       Women Solid Leather Sneakers\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q7 Solution:\n",
    "\n",
    "# connecting to the webdriver.\n",
    "driver= webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "# opening the target website. \n",
    "driver.get(\"https://www.myntra.com/shoes\")\n",
    "\n",
    "# putting the execution of the program on hold for 10 seconds so that the website gets time to load properly.\n",
    "time.sleep(10)\n",
    "\n",
    "# using the explicit wait method till the elements we want is loaded.\n",
    "wait = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div\")))\n",
    "\n",
    "# finding the webelement for \"price-filter\" using absolute-xpath and clicking it.\n",
    "price_filter= driver.find_element(By.XPATH,\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div\")\n",
    "price_filter.click()\n",
    "\n",
    "# putting the execution of the program on hold for 10 seconds so that the website gets time to load properly after applying the filter.\n",
    "time.sleep(10)\n",
    "\n",
    "# using the explicit wait method till the elements we want is loaded.\n",
    "wait = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div\")))\n",
    "\n",
    "# finding the webelement for \"color-filter\" using absolute-xpath and clicking it.\n",
    "color_filter= driver.find_element(By.XPATH,\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div\")\n",
    "color_filter.click()\n",
    "\n",
    "# putting the execution of the program on hold for 10 seconds so that the website gets time to load properly after applying the filters.\n",
    "time.sleep(10)\n",
    "\n",
    "# defining the lists to be used.\n",
    "brands=[]\n",
    "prices=[]\n",
    "short_des=[]\n",
    "\n",
    "# finding the webelements of the shoes using relative-xpath. \n",
    "data= driver.find_elements(By.XPATH,\"//div[@class='product-productMetaInfo']\")\n",
    "\n",
    "# The text from each of the webelement is extracted and then split in such a way that we get the required piece-wise information.  \n",
    "# The information is then put into respective lists.\n",
    "for i in data:\n",
    "    content= i.text.split(\"\\n\")\n",
    "    brands.append(content[0])\n",
    "    short_des.append(content[1])\n",
    "    prices.append(content[2].split(\"Rs\")[1].split(\" \")[1])\n",
    "\n",
    "# finding the webelement for the next-page button using absolute-xpath and clicking on it.\n",
    "nxt_btn= driver.find_element(By.XPATH,\"/html/body/div[2]/div/div[1]/main/div[3]/div[2]/div/div[2]/section/div[2]/ul/li[12]/a\").click()\n",
    "\n",
    "# putting the execution of the program on hold for 10 seconds so that the website gets time to load properly\n",
    "time.sleep(10)\n",
    "\n",
    "# Getting the required information from the current page and putting it into the respective lists just like the above for loop. \n",
    "data= driver.find_elements(By.XPATH,\"//div[@class='product-productMetaInfo']\")\n",
    "for i in data:\n",
    "    content= i.text.split(\"\\n\")\n",
    "    brands.append(content[0])\n",
    "    short_des.append(content[1])\n",
    "    prices.append(content[2].split(\"Rs\")[1].split(\" \")[1])\n",
    "\n",
    "# the final dataframe\n",
    "shoes= pd.DataFrame({\"Brand\":brands, \"Price(Rs)\":prices,\"Short Description\":short_des})\n",
    "shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "23934dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 Pro Intel Core i7 11th G...</td>\n",
       "      <td>75,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel Core i7 13.3” FHD ...</td>\n",
       "      <td>84,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) ...</td>\n",
       "      <td>89,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...</td>\n",
       "      <td>57,890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Infinix INBook X1 Pro Core i7 10th Gen - (16 G...</td>\n",
       "      <td>53,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 Pro Intel Core i7 11th G...</td>\n",
       "      <td>75,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hp Pavilion 15 12Th Gen Intel Core I7 16Gb Sdr...</td>\n",
       "      <td>87,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ASUS Zenbook 14 OLED (2022), 14\" (35.56 cms) 2...</td>\n",
       "      <td>1,07,794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenovo ThinkPad E14 Intel Core i7 11th Gen 14-...</td>\n",
       "      <td>94,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hp Pavilion X360 11Th Gen Intel Core I7 14 Inc...</td>\n",
       "      <td>82,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title     Price\n",
       "0  Lenovo IdeaPad Slim 5 Pro Intel Core i7 11th G...    75,990\n",
       "1  Fujitsu UH-X 11th Gen Intel Core i7 13.3” FHD ...    84,990\n",
       "2  ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) ...    89,990\n",
       "3  ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...    57,890\n",
       "4  Infinix INBook X1 Pro Core i7 10th Gen - (16 G...    53,999\n",
       "5  Lenovo IdeaPad Slim 5 Pro Intel Core i7 11th G...    75,990\n",
       "6  Hp Pavilion 15 12Th Gen Intel Core I7 16Gb Sdr...    87,900\n",
       "7  ASUS Zenbook 14 OLED (2022), 14\" (35.56 cms) 2...  1,07,794\n",
       "8  Lenovo ThinkPad E14 Intel Core i7 11th Gen 14-...    94,990\n",
       "9  Hp Pavilion X360 11Th Gen Intel Core I7 14 Inc...    82,990"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q8 Solution:\n",
    "\n",
    "# connecting to the webdriver.\n",
    "driver= webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "# opening the target website. \n",
    "driver.get(\"https://www.amazon.in/\")\n",
    "\n",
    "# finding the webelement for search field using absolute-xpath and sending the necessary keys.\n",
    "srch_laptop= driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "srch_laptop.send_keys(\"Laptop\")\n",
    "\n",
    "# finding the webelement for search-button using absolute-xpath and clicking it.\n",
    "srch_button= driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input\")\n",
    "srch_button.click()\n",
    "\n",
    "# putting the execution of the program on hold for 15 seconds so that the website gets time to load properly.\n",
    "time.sleep(15)\n",
    "\n",
    "# finding the webelement for processor-filter using absolute-xpath and clicking it.\n",
    "filter_processor= driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[5]/ul[2]/li[13]/span/a/span\")\n",
    "filter_processor.click()\n",
    "\n",
    "# putting the execution of the program on hold for 10 seconds so that the website gets time to load properly after applying the filter.\n",
    "time.sleep(10)\n",
    "\n",
    "#refreshing the page.\n",
    "driver.refresh()\n",
    "\n",
    "# defining the lists to be used.\n",
    "titles=[]\n",
    "prices=[]\n",
    "\n",
    "# Getting the required webelements using relative-xpath and then extracting the text which is then put into a list.\n",
    "data= driver.find_elements(By.XPATH,\"//h2[@class='a-size-mini a-spacing-none a-color-base s-line-clamp-2']\")\n",
    "for i in data:\n",
    "    titles.append(i.text)\n",
    "\n",
    "# Getting the required webelements using relative-xpath and then extracting the text which is then put into a list.\n",
    "data= driver.find_elements(By.XPATH,\"//span[@class='a-price-whole']\")\n",
    "for i in data:\n",
    "    prices.append(i.text)\n",
    "\n",
    "#the final dataframe and top10 results.\n",
    "laptops= pd.DataFrame({\"Title\":titles, \"Price\":prices})\n",
    "laptops[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b6a455af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Posted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>4.1</td>\n",
       "      <td>8d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist- Forecasting and R or Python</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Machine Learning Algorithms (...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>6d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Machine Learning/Big Data (0-...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>13d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Info Edge - Data Scientist - Machine Learning/...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>14d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Info Edge - Senior Data Scientist - Machine Le...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>14d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LatentBridge - Data Scientist - Python/R (2-6 ...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>14d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Science Trainer | AI | Machine Learning |...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Principal Scientist - Machine Learning - IT (1...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>28d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - NLP</td>\n",
       "      <td>3.8</td>\n",
       "      <td>14d ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Company Rating   Posted\n",
       "0                              Senior Data Scientist    4.1   8d ago\n",
       "1        Data Scientist- Forecasting and R or Python    4.0  15d ago\n",
       "2  Data Scientist - Machine Learning Algorithms (...    4.3   6d ago\n",
       "3  Data Scientist - Machine Learning/Big Data (0-...    3.9  13d ago\n",
       "4  Info Edge - Data Scientist - Machine Learning/...    3.9  14d ago\n",
       "5  Info Edge - Senior Data Scientist - Machine Le...    3.9  14d ago\n",
       "6  LatentBridge - Data Scientist - Python/R (2-6 ...    4.5  14d ago\n",
       "7  Data Science Trainer | AI | Machine Learning |...    3.8   1d ago\n",
       "8  Principal Scientist - Machine Learning - IT (1...    3.9  28d ago\n",
       "9                               Data Scientist - NLP    3.8  14d ago"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q9 Solution:\n",
    "\n",
    "# connecting to the webdriver.\n",
    "driver= webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "# opening the target website. \n",
    "driver.get(\"https://www.ambitionbox.com/\")\n",
    "\n",
    "# finding the webelement for \"jobs\" button using absolute-xpath and clicking it.\n",
    "jobs_btn= driver.find_element(By.XPATH,\"/html/body/div[1]/nav/nav/a[6]\").click()\n",
    "\n",
    "# finding the webelement for search field using absolute-xpath and sending the necessary keys.\n",
    "srch_job= driver.find_element(By.XPATH,\"/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/div/span/input\")\n",
    "srch_job.send_keys(\"Data Scientist\")\n",
    "\n",
    "# finding the webelement for the search-button using absolute-xpath and clicking it.\n",
    "srch_btn= driver.find_element(By.XPATH,\"/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/button/span\").click()\n",
    "\n",
    "# putting the execution of the program on hold for 10 seconds so that the website gets time to load properly\n",
    "time.sleep(10)\n",
    "#driver.refresh()\n",
    "#wait= WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[1]/i\")))\n",
    "\n",
    "# finding the webelement for the location-dropdown-menu using absolute-xpath and clicking it.\n",
    "location_dropdown= driver.find_element(By.XPATH,\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[1]/i\").click()\n",
    "\n",
    "# putting the execution of the program on hold for 10 seconds so that the website gets time to load properly.\n",
    "time.sleep(10)\n",
    "\n",
    "# finding the webelement for the location-search-field in the dropdown menu using absolute-xpath and sending the necessary keys.\n",
    "location_key= driver.find_element(By.XPATH,\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input\")\n",
    "location_key.send_keys(\"Noida\")\n",
    "\n",
    "# putting the execution of the program on hold for 10 seconds so that the website gets time to load properly.\n",
    "time.sleep(10)\n",
    "\n",
    "# finding the webelement for the \"Noida\" option using absolute-xpath and clicking it.\n",
    "location_select= driver.find_element(By.XPATH,\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label\").click()\n",
    "\n",
    "# putting the execution of the program on hold for 10 seconds so that the website gets time to load properly after giving the location.\n",
    "time.sleep(10)\n",
    "\n",
    "# Getting the required webelements using relative-xpath and then extracting the text which is then put into a list.\n",
    "data= driver.find_elements(By.XPATH,\"//a[@class='title noclick']\")\n",
    "companies=[]\n",
    "for i in data:\n",
    "    companies.append(i.text)\n",
    "\n",
    "# Getting the required webelements using relative-xpath and then extracting the text which is then put into a list.\n",
    "data= driver.find_elements(By.XPATH,\"//span[@class='body-small']\")\n",
    "ratings=[]\n",
    "for i in data:\n",
    "    ratings.append(i.text)\n",
    "\n",
    "# Getting the required webelements using relative-xpath and then extracting the text which is then put into a list.\n",
    "data= driver.find_elements(By.XPATH,\"//span[@class='body-small-l']\")\n",
    "days= []\n",
    "for i in data:\n",
    "    days.append(i.text)\n",
    "\n",
    "# the final dataframe\n",
    "jobs= pd.DataFrame({\"Company\":companies, \"Rating\":ratings, \"Posted\": days[::2]})\n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8ef92a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience Required</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Maximum salary</th>\n",
       "      <th>Total Salary Record</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>3 yrs experience</td>\n",
       "      <td>₹ 30.6L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>₹ 36.0L</td>\n",
       "      <td>based on 12 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>3-4 yrs experience</td>\n",
       "      <td>₹ 20.8L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 26.2L</td>\n",
       "      <td>based on 33 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZS</td>\n",
       "      <td>2 yrs experience</td>\n",
       "      <td>₹ 16.7L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "      <td>based on 15 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Optum</td>\n",
       "      <td>3-4 yrs experience</td>\n",
       "      <td>₹ 15.9L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 22.5L</td>\n",
       "      <td>based on 32 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reliance Jio</td>\n",
       "      <td>3-4 yrs experience</td>\n",
       "      <td>₹ 15.7L</td>\n",
       "      <td>₹ 5.6L</td>\n",
       "      <td>₹ 26.2L</td>\n",
       "      <td>based on 21 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "      <td>₹ 15.5L</td>\n",
       "      <td>₹ 10.0L</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "      <td>based on 89 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "      <td>₹ 14.8L</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>based on 51 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UnitedHealth</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "      <td>₹ 14.0L</td>\n",
       "      <td>₹ 8.3L</td>\n",
       "      <td>₹ 21.1L</td>\n",
       "      <td>based on 57 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>3-4 yrs experience</td>\n",
       "      <td>₹ 13.2L</td>\n",
       "      <td>₹ 7.6L</td>\n",
       "      <td>₹ 21.0L</td>\n",
       "      <td>based on 21 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Deloitte</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "      <td>₹ 12.8L</td>\n",
       "      <td>₹ 7.0L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>based on 69 salaries</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Company  Experience Required Average Salary Minimum Salary  \\\n",
       "0            Walmart    3 yrs experience         ₹ 30.6L        ₹ 25.0L   \n",
       "1           Ab Inbev  3-4 yrs experience         ₹ 20.8L        ₹ 15.0L   \n",
       "2                 ZS    2 yrs experience         ₹ 16.7L        ₹ 11.0L   \n",
       "3              Optum  3-4 yrs experience         ₹ 15.9L        ₹ 11.0L   \n",
       "4       Reliance Jio  3-4 yrs experience         ₹ 15.7L         ₹ 5.6L   \n",
       "5  Fractal Analytics  2-4 yrs experience         ₹ 15.5L        ₹ 10.0L   \n",
       "6    Tiger Analytics  2-4 yrs experience         ₹ 14.8L         ₹ 9.0L   \n",
       "7       UnitedHealth  2-4 yrs experience         ₹ 14.0L         ₹ 8.3L   \n",
       "8        EXL Service  3-4 yrs experience         ₹ 13.2L         ₹ 7.6L   \n",
       "9           Deloitte  2-4 yrs experience         ₹ 12.8L         ₹ 7.0L   \n",
       "\n",
       "  Maximum salary   Total Salary Record  \n",
       "0        ₹ 36.0L  based on 12 salaries  \n",
       "1        ₹ 26.2L  based on 33 salaries  \n",
       "2        ₹ 22.0L  based on 15 salaries  \n",
       "3        ₹ 22.5L  based on 32 salaries  \n",
       "4        ₹ 26.2L  based on 21 salaries  \n",
       "5        ₹ 23.0L  based on 89 salaries  \n",
       "6        ₹ 20.0L  based on 51 salaries  \n",
       "7        ₹ 21.1L  based on 57 salaries  \n",
       "8        ₹ 21.0L  based on 21 salaries  \n",
       "9        ₹ 25.0L  based on 69 salaries  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q10 Solution.\n",
    "\n",
    "# connecting to the webdriver.\n",
    "driver= webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "# opening the target website. \n",
    "driver.get(\"https://www.ambitionbox.com/\")\n",
    "\n",
    "# finding the webelement for \"salaries\" button using absolute-xpath and clicking it.\n",
    "salaries_btn= driver.find_element(By.XPATH,\"/html/body/div[1]/nav/nav/a[4]\").click()\n",
    "\n",
    "# finding the webelement for search field using absolute-xpath and sending the necessary keys.\n",
    "srch_job= driver.find_element(By.XPATH,\"/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input\")\n",
    "srch_job.send_keys(\"Data Scientist\")\n",
    "\n",
    "# putting the execution of the program on hold for 10 seconds so that the website gets time to load properly.\n",
    "time.sleep(10)\n",
    "\n",
    "# finding the webelement for \"Data Scientist\" option using absolute-xpath and clicking it.\n",
    "ds_btn= driver.find_element(By.XPATH,\"/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/div/div/div[1]/div/div/p\").click()\n",
    "\n",
    "# putting the execution of the program on hold for 5 seconds so that the website gets time to load properly.\n",
    "time.sleep(5)\n",
    "\n",
    "# defining the lists to be used.\n",
    "companies=[]\n",
    "no_of_records=[]\n",
    "avg_sal=[]\n",
    "min_sal=[]\n",
    "max_sal=[]\n",
    "exp=[]\n",
    "content=[]\n",
    "\n",
    "# finding the webelements of the jobs listed using relative-xpath and then putting the elements in a list. \n",
    "data= driver.find_elements(By.XPATH,\"//div[@class='company-info']\")\n",
    "for i in data:\n",
    "    content.append(i.text)\n",
    "\n",
    "# The text from each of the above elements is extracted and then split in such a way that we get the required piece-wise information.  \n",
    "# The information is then put into respective lists.\n",
    "for i in content[:10]:\n",
    "    elements= i.split(\"\\n\")\n",
    "    companies.append(elements[0])\n",
    "    x= elements[2].split(\"(\")\n",
    "    exp.append(x[0])\n",
    "    no_of_records.append(x[1].split(\")\")[0])\n",
    "\n",
    "# finding the webelements for average-salary using relative-xpath and then extracting the text into a list.  \n",
    "data= driver.find_elements(By.XPATH,\"//p[@class='averageCtc']\")\n",
    "for i in data:\n",
    "    avg_sal.append(i.text)\n",
    "\n",
    "# finding the webelements for minimum-salary and maximum-salary using relative-xpath. \n",
    "data= driver.find_elements(By.XPATH,\"//div[@class='value body-medium']\")\n",
    "\n",
    "# extracting the minimum-salary data from the above webelements and putting into a list.\n",
    "min_data= data[::2]\n",
    "for i in min_data:\n",
    "    min_sal.append(i.text)\n",
    "\n",
    "# extracting the maximum-salary data from the above webelements and putting into a list.\n",
    "max_data= data[1::2]\n",
    "for i in max_data:\n",
    "    max_sal.append(i.text)\n",
    "\n",
    "# the final dataframe\n",
    "ds_jobs= pd.DataFrame({\"Company\": companies, \n",
    "                       \"Experience Required\": exp, \n",
    "                       \"Average Salary\": avg_sal,\n",
    "                       \"Minimum Salary\": min_sal,\n",
    "                       \"Maximum salary\": max_sal,\n",
    "                       \"Total Salary Record\": no_of_records})\n",
    "ds_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebd46db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
